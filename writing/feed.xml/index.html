<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
<title type="text">Andrey Kurenkov's Web World</title>
<generator uri="https://github.com/jekyll/jekyll">Jekyll</generator>
<link rel="self" type="application/atom+xml" href="/feed.xml" />
<link rel="alternate" type="text/html" href="" />
<updated>2016-01-13T23:32:56-08:00</updated>
<id>/</id>
<author>
  <name>Andrey Kurenkov</name>
  <uri>/</uri>
  <email>andreyvkurenkov@gmail.com</email>
</author>


  

<entry>
  <title type="html"><![CDATA[Organizing My Emails with a Neural Net]]></title>
  <link rel="alternate" type="text/html" href="/writing/organizing-my-emails-with-a-neural-net/" />
  <id>/writing/organizing-my-emails-with-a-neural-net</id>
  <published>2016-01-13T18:19:34-08:00</published>
  <updated>2016-01-13T18:19:34-08:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email>andreyvkurenkov@gmail.com</email>
  </author>
  <content type="html">
    &lt;figure&gt;
    &lt;img class=&quot;postimagesmaller&quot; src=&quot;/writing/images/2016-1-13-neural-net-categorize-my-email/18-conf_normalized2.png&quot; alt=&quot;Conf mat 0&quot; /&gt; 
    &lt;figcaption&gt;Or, how to make this happen with your gmail data. The entirety of the code used for this post &lt;b&gt;&lt;a href=&quot;https://github.com/andreykurenkov/emailinsight/tree/master/pyScripts&quot;&gt;can be found here&lt;/a&gt;&lt;/b&gt;. &lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;I have always been fond of school projects that actually trust me to have interest in what I am learning. Sadly, most undergraduate school assignments don’t, but there are those rare projects that require the student to engage with what they are learning by partially defining the problem they set out to solve.  At least for me, it is a shame that more projects do not do this, since almost invariably such projects results in me caring and learning much more. But, some do. One of my favorite assignments of this kind was part of the Georgia Tech Into to Machine Learning class, and resulted in one of my more fun projects: &lt;a href=&quot;http://www.andreykurenkov.com/projects/hacks/email-filer/&quot;&gt;EmailFiler&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;emailfiler-v1&quot;&gt;EmailFiler V1&lt;/h1&gt;
&lt;p&gt;Basically, the assignment was to pick some datasets, throw a bunch of supervised learning algorithms at them, and analyze the results. But here’s the thing: we could make our own datasets if we so chose. And so choose I did - to export my gmail data and explore the feasibility of machine-learned email categorization. See, I learned long ago that it’s often best to keep emails around in case there is randomly some need to refer back to them in the future. But, I also learned that I can’t help but strive for the ideal of the empty inbox (hopeless as that may be). So, years ago I started categorizing my emails into about a dozen folders within gmail, and by the point I took the machine learning class I had many thousands of emails spread across these categories. It seemed like a great application of ML to make a classifier that could suggest a single category for each email in the inbox for one-click organizing of it.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimageactual&quot; src=&quot;/writing/images/2016-1-13-neural-net-categorize-my-email/1-emailscategories.png&quot; alt=&quot;Emails categories&quot; /&gt; 
    &lt;figcaption&gt;The set of categories and email counts I worked with at the time&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;Well, you got your input data, the emails, and your labels, the categories, and even a nice button to export all the data in .mbox format - easy right? Not so fast. Though I was not exactly striving for full NLP text comprehension, I still wanted to learn using email text and metadata, and at first did not really know how to convert this data into nice a machine-learnable dataset. The simple answer to this, as any person who has taken NLP can quickly point out, is to use a Bag of Words approach - just finding what the most common 500 or so words in all the emails are, and then creating binary features for each word (features that have a value of 1 for an email if it contained the word, and 0 otherwise). I did the same for the sender of the email - picking out about the top 20, since in some cases the sender should correlate strongly with the category (for example the sender being my research adviser and the category ‘research’) - and for the domain the email was sent from (since a few like piazza and gatech.edu would be strongly indicative for categories like ‘TA’ and ‘academic’). So, after an hour or so of writing &lt;a href=&quot;https://github.com/andreykurenkov/emailinsight/blob/master/pyScripts/mboxConvert.py&quot;&gt;mbox parsing code&lt;/a&gt; I ended up with the function that output my actual dataset as a csv; looking over it may clarify how simple these features really were:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c&quot;&gt;#...bunch of parsing code above this&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mboxToBinaryCSV&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;folder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;csvfile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;data.csv&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;perLabel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;                  
    &lt;span class=&quot;n&quot;&gt;outputFile&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;folder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;csvfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                         
                                                                                
    &lt;span class=&quot;n&quot;&gt;emails&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parseEmails&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;folder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                                                
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topWords&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topSenders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topDomains&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getTopEmailCounts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emails&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;perLabel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;perLabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                                                                                
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sender&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;topSenders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;                                                   
        &lt;span class=&quot;n&quot;&gt;outputFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;Sender &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;,&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sender&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                                   
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;domain&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;topDomains&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;                                                   
        &lt;span class=&quot;n&quot;&gt;outputFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;From domain &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;,&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;domain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                              
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;topWords&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;                                                       
        &lt;span class=&quot;n&quot;&gt;outputFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;Has &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;,&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                                        
    &lt;span class=&quot;n&quot;&gt;outputFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;label&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                                                 
    &lt;span class=&quot;n&quot;&gt;labelMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;                                                                
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;email&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emails&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;                                                        
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sender&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;topSenders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;                                               
            &lt;span class=&quot;n&quot;&gt;outputFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;1, &amp;#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;email&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sender&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sender&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;0,&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;           
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;domain&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;topDomains&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;                                               
            &lt;span class=&quot;n&quot;&gt;outputFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;1, &amp;#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;email&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fromDomain&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;domain&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;0,&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;          
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;topWords&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;                                                   
            &lt;span class=&quot;n&quot;&gt;outputFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;1, &amp;#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;email&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;0,&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;So, how well did it work? Well, but not as well as I hoped. At the time I was fond of the Orange Python ML framework, and so as per the assignment tested how well a bunch of algorithms did against my dataset (the code for this &lt;a href=&quot;https://github.com/andreykurenkov/emailinsight/blob/master/pyScripts/code-learner.py&quot;&gt;can be found here&lt;/a&gt; - apparently I manually implemented cross validation and accuracy evaluation…). The best I got was about 75% accuracy on the test set, with the standouts being decision trees, as the best algorithm, and neural nets, as the worst:&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmaller&quot; src=&quot;/writing/images/2016-1-13-neural-net-categorize-my-email/2-emailsdtree.png&quot; alt=&quot;DTrees emails&quot; /&gt; 
    &lt;figcaption&gt;How Decision Trees fared on my little email dataset&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmaller&quot; src=&quot;/writing/images/2016-1-13-neural-net-categorize-my-email/3-emailsnn.png&quot; alt=&quot;NN emails&quot; /&gt; 
    &lt;figcaption&gt;... And now neural nets &lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;If you take a look at those beautiful OpenOffice Calc plots, you will soon see that the best Decision Trees managed to achieve on the test set is roughly 72%, and that neural nets could only get to a measly 65% - an F! Way better than random, considering there are 11 categories, but far from great. Why the disappointing result? Well, as stated the features created for the dataset are very simple - just selecting the 500 most frequent words will yield a few good indicators, but also many generic terms that just appear a lot in english such as ‘that’ or ‘is’. I understood this at the time and tried a few things - removing 3-character words entirely, and writing some annoying code to select the most frequent words in each category specifically rather than in all the emails - but ultimately did not manage to figure out how to get better results.&lt;/p&gt;

&lt;h1 id=&quot;enter-keras&quot;&gt;Enter Keras&lt;/h1&gt;
&lt;p&gt;So, why am I writing this if I did this years ago and got fairly lame results then (I did get a good grade, though!)? In short, to try again. Having just completed a &lt;a href=&quot;http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning/&quot;&gt;giant 4-part history of neural networks and Deep Learning&lt;/a&gt;, and in so doing learned what fancy modern terms like ‘dropout’ and ‘relu’ mean, it seemed only appropriate to dive into a modern machine learning framework and see what I could do.&lt;/p&gt;

&lt;p&gt;But, where to start? By picking the toys, of course! The framework I decided to try working with is &lt;a href=&quot;http://keras.io/&quot;&gt;Keras&lt;/a&gt;, both because it is in Python (which seems to be a favorite for data science and machine learning nowdays, and has the wonderful &lt;a href=&quot;http://www.numpy.org/&quot;&gt;numpy&lt;/a&gt;, &lt;a href=&quot;http://pandas.pydata.org/&quot;&gt;pandas&lt;/a&gt;, and &lt;a href=&quot;http://www.numpy.org/&quot;&gt;scikit-learn&lt;/a&gt; all playing nice with each other) and because it is backed by the well regarded Theano library. It also just so happenes that Keras also has several easy to copy-paste examples to get started with, including one with a &lt;a href=&quot;https://github.com/fchollet/keras/blob/master/examples/reuters_mlp.py&quot;&gt;multi-category text classification problem&lt;/a&gt; much as with my email problem. And, here’s the interesting thing - the example uses just about the same features as I did for my class project. It finds the 1000 most frequent words in the documents, makes those into binary features, and trains a neural net with one hidden layer to predict the category of input text based solely of those features.&lt;/p&gt;

&lt;p&gt;So, the obvious first thing to try is exactly this, but with my own data - see if doing feature extraction with Keras will work better. My data is not exactly in the Keras data format, but luckily using my mbox parsing code it is easy to write a short function to create an equivalent to the dataset in the example:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_keras_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;folder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nb_words&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_split&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;totalWordsCount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fromCount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;domainCount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;getEmailStats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emails&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;      
    &lt;span class=&quot;c&quot;&gt;#...Some boring filtering in between code &lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;texts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;                                                                 
    &lt;span class=&quot;n&quot;&gt;emailLabels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;                                                            
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;email&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emails&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;                                                        
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;email&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;                                           
            &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;                                                            
        &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;email&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sender&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;email&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subject&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                              
        &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;email&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fromDomain&lt;/span&gt;                                                 
        &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;email&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;                                                     
        &lt;span class=&quot;n&quot;&gt;texts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\r&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;                    
        &lt;span class=&quot;n&quot;&gt;emailLabels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labelNums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;email&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nb_words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_on_texts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;texts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sequences&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;texts_to_sequences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;texts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;random_order&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;permutation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;texts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;index_split&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_split&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emails&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_order&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test_indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_order&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;                                       
    &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emailLabels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emailLabels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In essence, this is doing exactly what I did to generate my old features, except I letting Keras do the heavy lifting this time.
This code indeed worked, and even gave me a little update as to the contents of my email:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Using Theano backend.
Label email count breakdown:
	Personal:440
	Group work:150
	Financial:118
	Academic:1088
	Professional:388
	Group work/SolarJackets:1535
	Personal/Programming:229
	Professional/Research:1066
	Professional/TA:1801
	Sent:513
	Unread:146
	Professional/EPFL:234
	Important:142
	Professional/RISS:173
Total emails: 8023
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Eight thousand emails - not a giant dataset by any stretch, but nevertheless enough to do some serious machine learning. 
So, I can generate the data in the correct format, and now it is just a matter of seeing if training a neural net with it works. 
So, at this point all I have is really a small python file with the above and a basically a copy of the Keras example:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;max_words&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;nb_epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mboxToNumpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nb_words&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_split&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;nb_classes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#Vectorizing sequence data...&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nb_words&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sequences_to_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;binary&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sequences_to_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;binary&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#Convert class vector to binary class matrix (for use with categorical_crossentropy)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np_utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nb_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np_utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nb_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;Building model...&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,)))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nb_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;categorical_crossentropy&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;adam&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;history&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nb_epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nb_epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                    &lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;show_accuracy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;validation_split&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;evaluate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;show_accuracy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;Test score:&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;Test accuracy:&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Before long that file will grow to be over 500 lines of code, but let’s not get ahead of ourselves… As you can see, there are a
whole bunch of parameters here, and it’s hard to say if they are all correct. But let’s just run with it and see what happens:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;7221 train sequences
802 test sequences
Building model...
Train on 6498 samples, validate on 723 samples
Epoch 1/5
6498/6498 [==============================] - 2s - loss: 1.3182 - acc: 0.6320 - val_loss: 0.8166 - val_acc: 0.7718
Epoch 2/5
6498/6498 [==============================] - 2s - loss: 0.6201 - acc: 0.8316 - val_loss: 0.6598 - val_acc: 0.8285
Epoch 3/5
6498/6498 [==============================] - 2s - loss: 0.4102 - acc: 0.8883 - val_loss: 0.6214 - val_acc: 0.8216
Epoch 4/5
6498/6498 [==============================] - 2s - loss: 0.2960 - acc: 0.9214 - val_loss: 0.6178 - val_acc: 0.8202
Epoch 5/5
6498/6498 [==============================] - 2s - loss: 0.2294 - acc: 0.9372 - val_loss: 0.6031 - val_acc: 0.8326
802/802 [==============================] - 0s     
Test score: 0.585222780162
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Test accuracy: 0.847880299252&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Hell yeah 85% test accuracy! That handily beats the measly 65% score of my old neural net. Awesome. Except… why?&lt;br /&gt;
I mean, my old code was doing basically exactly this - finding the most frequest words, creating a binary matrix of 
features, and training a neural net with one hidden layer to be the classifier. Perhaps, it is because of this fancy new 
‘relu’ neuron, and dropout, and using a non-sgd optimizer? Let’s find out! Since my old features were indeed binary and in 
a matrix, it takes very little work to make those be the dataset this neural net is trained with. And so, the  results:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Epoch 1/5
6546/6546 [==============================] - 1s - loss: 1.8417 - acc: 0.4551 - val_loss: 1.4071 - val_acc: 0.5659
Epoch 2/5
6546/6546 [==============================] - 1s - loss: 1.2317 - acc: 0.6150 - val_loss: 1.1837 - val_acc: 0.6291
Epoch 3/5
6546/6546 [==============================] - 1s - loss: 1.0417 - acc: 0.6661 - val_loss: 1.1216 - val_acc: 0.6360
Epoch 4/5
6546/6546 [==============================] - 1s - loss: 0.9372 - acc: 0.6968 - val_loss: 1.0689 - val_acc: 0.6635
Epoch 5/5
6546/6546 [==============================] - 2s - loss: 0.8547 - acc: 0.7215 - val_loss: 1.0564 - val_acc: 0.6690
808/808 [==============================] - 0s     
Test score: 1.03195088158
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Test accuracy: 0.64603960396&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Ouch. So yes, my old email-categorizing solution was fairly flawed. I can’t say for sure, but I think it is a mix of overcontstraining the features
(forcing the top senders, domains, and words from each category to be there). The Keras example just throws the top 1000 words into a big matrix without
any more intelligent filtering, and lets the neural net have at it. Not limiting what the features can be lets better ones be discovered, and so the 
overall accuracy is better. Well, that, or my code just sucks and has mistakes in it - modifying it to be less restrictive still only nets a 70% accuracy. 
In any case, it’s clear that I was able to beat my old result by leveraging a modern Deep Learning library, so the question now clearly is - can I do better?&lt;/p&gt;

&lt;h1 id=&quot;doing-better&quot;&gt;Doing Better&lt;/h1&gt;

&lt;p&gt;When I first started looking at the Keras code, I was briefly excited by the mistaken notion that it would use the actual sequence of text (switched to numbers,
but still in the correct order). It turned out that this was not the case - as we saw that first example just used an example with binary features indicating the 
presence of the word anywhere in the text - but that does not mean that it can’t be. Indeed, a very cool recent phenomena in machine learning is the resurgence of 
recurrent neural nets, which are well suited for dealing with long sequences of data. So, instead of changing the emails into matrices of binary features it’s possible to
just change the words into numbers with the wordss frequency and feed in the entire sequence into a LSTM or GRU neural net. And, guess what? There is also a nice easy to copy-paste example of machine
learning with these types of neural nets, so it is easy to fire up and see what happens:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Epoch 1/15
7264/7264 [===========================] - 1330s - loss: 2.3454 - acc: 0.2411 - val_loss: 2.0348 - val_acc: 0.3594
Epoch 2/15
7264/7264 [===========================] - 1333s - loss: 1.9242 - acc: 0.4062 - val_loss: 1.5605 - val_acc: 0.5502
Epoch 3/15
7264/7264 [===========================] - 1337s - loss: 1.3903 - acc: 0.6039 - val_loss: 1.1995 - val_acc: 0.6568
...
Epoch 14/15
7264/7264 [===========================] - 1350s - loss: 0.3547 - acc: 0.9031 - val_loss: 0.8497 - val_acc: 0.7980
Epoch 15/15
7264/7264 [===========================] - 1352s - loss: 0.3190 - acc: 0.9126 - val_loss: 0.8617 - val_acc: 0.7869
Test score: 0.861739277323
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Test accuracy: 0.786864931846&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Darn it. Not only did the LSTM take FOREVER, but the results at the end were not that good. Presumably the reason for this is that my emails are just not that much data, 
and in general sequences are not that useful for categorizing them. Okay, well, what now? Well, remember how I just sort of used the defaults of the example without thinking 
too hard about it? Let’s see if I can figure out a better approach. To start with, it&lt;/p&gt;

&lt;p&gt;Sadly, Keras itself does not have much in the way of visualization or inspection tools - but that does not mean we cannot jerry rig some together!
To start with, of course, I google for what is already out there. And what I promptly find is an &lt;a href=&quot;https://github.com/fchollet/keras/issues/254&quot;&gt;ongoing discussion&lt;/a&gt; concerning  visualization,
with no resolution in sight. Bummer, but not entirely - there exists &lt;a href=&quot;https://github.com/aleju/keras&quot;&gt;a fork of Keras&lt;/a&gt; with at least a nice way to graph the training progress. Not very useful,
but fun, so let’s do it! After hacking it a bit to plot batches instead of epochs, here is our first taste of sweet visuals:&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimage&quot; src=&quot;/writing/images/2016-1-13-neural-net-categorize-my-email/4-graph.png&quot; alt=&quot;NN training&quot; /&gt; 
    &lt;figcaption&gt;The progression of neural net training for a slightly modified version of the example (with more words included) &lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;Interesting - the cross validation between epochs results in big jumps in training accuracy, not something I’d expect. But, more pertinently, it’s easy to see the training accuracy
just about reaches 1.0 and definitely plateaus. Okay, good, but the harder problem is increasing the test accuracy. As before, the first question is whether I can quickly alter the 
feature representation to help the neural net out. The Keras module that converts the text into matrices has several options besides making a binary matrix: matrices with word counts,
frequencies, or tfidf values. It is also very easy to alter the amount of words kept in the matrices as features, and so being the amazing programmer that I am I manage to write a few
loops to evaluate how varying the feature type and word count affects the test accuracy. Not only that, but I even make a pretty plot of the results with python:&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagehalf&quot; src=&quot;/writing/images/2016-1-13-neural-net-categorize-my-email/5-word_accs.png&quot; alt=&quot;Word accs&quot; /&gt; 
    &lt;img class=&quot;postimagehalf&quot; src=&quot;/writing/images/2016-1-13-neural-net-categorize-my-email/6-word_baseline_accs.png&quot; alt=&quot;Baseline accs&quot; /&gt; 
    &lt;figcaption&gt;Test accuracy based on feature type and how many words are kept as features (baseline being k nearest neighbors)&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;Again, interesting. The most basic and least information dense feature type, binary 1s or 0s indicating word presence, is about as good or better than the other features that convey more 
about the original data. This is not too unexpected, though - most likely more interesting words like ‘code’ or ‘grade’ are helpful for categorization, and having a single occurance in
an email is likely almost as informative as more than one. No doubt the more exact features help somewhat, but also lead to worse performance due to more potential for overfitting. All in all,
what we see is that the binary feature type is clearly the best one, and that increasing the number of words helps out quite a bit to get accuracies of about 87%-88%. 
Okay, so I can stick with the binary features, and want to use at least 2500 words since the accuracy seems to plateau around point.&lt;/p&gt;

&lt;p&gt;A good question to ask at this point is whether having all these words is actually what’s important, and a simpler algorithm could do just fine if I just use these features. To answer, we also have a simple baseline algorithm with the k nearest neighbors (&lt;a href=&quot;http://scikit-learn.org/stable/modules/neighbors.html&quot;&gt;from scikit&lt;/a&gt;), which clearly performs much worse than the neural net but benefits from the more specific features. Linear regression performed even worse, so it seems my use of neural nets is justified.&lt;/p&gt;

&lt;p&gt;By the way, all this word increasing is not cheap. Even with cached versions of the dataset such that I did not have to parse the emails and extract features each time, running all these tests
took a hefty amount of time:&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmaller&quot; src=&quot;/writing/images/2016-1-13-neural-net-categorize-my-email/8-word_times.png&quot; alt=&quot;Word times&quot; /&gt; 
    &lt;figcaption&gt;Linear increase in time as word count is increased. Not bad, really; linear regression was far worse&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;Okay, so increasing the number of words helps, but I am still not cracking the 90% mark - and I want to get an A here! So the next logical thing is to stick with 2500 words and look at varying the neural net size; 
the default size of 512 seems more than sufficient for my small dataset, but it’s worth seeing if altering this can help. Also, the example Keras model happens to have 50% dropout on the hidden layer and it 
would be interesting to see if this actually meaningfully helps the performance. So, time to spin up another set of loops and get another pretty graph:&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmaller&quot; src=&quot;/writing/images/2016-1-13-neural-net-categorize-my-email/9-hidden_accs_zoomed.png&quot; alt=&quot;Hidden accs&quot; /&gt; 
    &lt;figcaption&gt;Zoomed in view of accuracies for different dropouts and hidden layer sizes&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;Well, this is somewhat surprising - we don’t need very many hidden layer units at all to do well! With lower dropout (less regularization), as few as 64 and 124 hidden neurons can do just about as well as
the default of 512. These results are averaged across five runs, by the way, so mere variation in the outcomes does not account for the ability of small hidden layer to do well. This suggests that the large 
word counts are helpful for just including the helpful features, but that there are not really that many helpful features to pick up - otherwise more neurons would be necessary to do better. This is good to know,
since we can save quite a bit of time by using the smaller hidden layers:&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmaller&quot; src=&quot;/writing/images/2016-1-13-neural-net-categorize-my-email/10-hidden_times.png&quot; alt=&quot;Hidden times&quot; /&gt; 
    &lt;figcaption&gt;Again, linear growth as we increase the hidden layer (as we'd hope since they are independnent of each other) &lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;Well, hmm, that did not get me that coveted 90% test accuracy… Time to try being a little smarter about this. See, the current approach of making features out of the top 2500 frequent words is rather silly, in 
that it includes common english words such as ‘i’ or ‘that’ along with useful category specific words such as ‘homework’ or ‘due’. But, it’s tricky to just guess a cutoff of most frequent words, or blacklist some
number of words - you never know what turns out to be useful for features, since it is possible I happen to use one plain word more in one category than the others (such as ‘Personal’). So, let’s avoid the guesswork
and instead rely on good ol’ feature selection to pick out features that are actually good and filter out silly ones like ‘i’. Again, this is easy using scikit and its &lt;a href=&quot;http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html&quot;&gt;SelectKBest&lt;/a&gt; class, and is fast enough that it barely takes any time compared to running the neural net. So, does this work?&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmaller&quot; src=&quot;/writing/images/2016-1-13-neural-net-categorize-my-email/11-select_accs_zoomed_512.png&quot; alt=&quot;Select accs&quot; /&gt; 
    &lt;figcaption&gt;Yes, it works, 90%! &lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;Very nice! Though there is still variance in the performance, more words to start with is clearly better, but this set of words can be cut down rather heavily with feature selection and still work well. Apparently the neural net has no problem with undefitting if all the words are kept around - probably because as we saw with the small hidden layers there are not really that many features that need to be picked up - but doing feature selection does help out with speed.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmaller&quot; src=&quot;/writing/images/2016-1-13-neural-net-categorize-my-email/12-select_accs_zoomed_32.png&quot; alt=&quot;Select accs 32&quot; /&gt; 
    &lt;figcaption&gt;The same test with only 32 hidden layer units, with the previous one having 512 - still quite good performance &lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;h1 id=&quot;final-thoughts&quot;&gt;Final Thoughts&lt;/h1&gt;

&lt;p&gt;Having achieved my goal of 90% test set accuracy and been unsuccesful with other ideas (increasing the number of layers, for example), it’s about this point that I decide this is good enough and about time for me to start feeiling self satisfied. But, then I get distracted again and do a few more things. Namely, this stuff still takes forever to run in large part because I have yet to make use of the now standard trick of doing machine learning with a GPU. So, following a &lt;a href=&quot;http://deeplearning.net/software/theano/install_ubuntu.html&quot;&gt;very nice tutorial&lt;/a&gt; I do just that, and smile with satisfaction:&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagehalf&quot; src=&quot;/writing/images/2016-1-13-neural-net-categorize-my-email/13-select_times_512.png&quot; alt=&quot;Select times&quot; /&gt; 
    &lt;img class=&quot;postimagehalf&quot; src=&quot;/writing/images/2016-1-13-neural-net-categorize-my-email/14-select_times_512_gpu.png&quot; alt=&quot;Select times GPU&quot; /&gt; 
    &lt;figcaption&gt;The times taken to achieve that 90% plot above, without vs with GPU&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;YEAH! Now that is a significant speedup, and combined with feature selection and small hidden layer suggests this could all be done in tiny amounts of time. 
Having run out of ideas on how to improve this performance or speed it up, why not just spend a bit of time looking a bit deeper into the results. It would
be quite interesting to see what the feature selector actually finds to be good words to use, so let’s go ahead and see what the best and worst ones are for
just one run of the neural net:&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;/writing/images/2016-1-13-neural-net-categorize-my-email/15-scores_best.png&quot; alt=&quot;Select times&quot; /&gt; 
    &lt;img class=&quot;postimagesmall&quot; src=&quot;/writing/images/2016-1-13-neural-net-categorize-my-email/16-scores_worst.png&quot; alt=&quot;Select times GPU&quot; /&gt; 
    &lt;figcaption&gt;Best and worst words according to chi squared feature selection &lt;a href=&quot;http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html&quot;&gt;(loosely based on Scikit sample code)&lt;/a&gt;&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;Quite curious. A lot of the best ones are names or refer to specific things (the ‘controller’ is from ‘motor controller’), as could be expected, but other ones
such as ‘remember’ or ‘total’ would not strike me as very good features. The worst ones, on the other hand, are fairly predictable being either overly generic or overly
specific words. Another interesting thing to look at is what mistakes the neural net makes, with a &lt;a href=&quot;http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#example-model-selection-plot-confusion-matrix-py&quot;&gt;confusion matrix again from scikit learn&lt;/a&gt;:&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmaller&quot; src=&quot;/writing/images/2016-1-13-neural-net-categorize-my-email/17-conf_normalized.png&quot; alt=&quot;Conf mat&quot; /&gt; 
    &lt;figcaption&gt;The confusion matrix for the neural net results&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;The visualization here implies the ‘Unread’ and ‘Important’ categories are problem makers. But wait! I did not even create those, I don’t really care about things working correctly with those, nor with ‘Sent’.  Clearly I should take those out and see if the neural net can do a good job specifically with the categories I created for myself. So, let’s wrap up with a final experiment in which those irrelevant categories are removed and we use the most features of any run so far - 10000 words with selection of the 4000 best:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Epoch 1/5
Epoch 1/5
5850/5850 [==============================] - 2s - loss: 0.8013 - acc: 0.7879 - val_loss: 0.2976 - val_acc: 0.9369
Epoch 2/5
5850/5850 [==============================] - 1s - loss: 0.1953 - acc: 0.9557 - val_loss: 0.2322 - val_acc: 0.9508
Epoch 3/5
5850/5850 [==============================] - 1s - loss: 0.0988 - acc: 0.9795 - val_loss: 0.2418 - val_acc: 0.9338
Epoch 4/5
5850/5850 [==============================] - 1s - loss: 0.0609 - acc: 0.9865 - val_loss: 0.2275 - val_acc: 0.9462
Epoch 5/5
5850/5850 [==============================] - 1s - loss: 0.0406 - acc: 0.9925 - val_loss: 0.2326 - val_acc: 0.9462
722/722 [==============================] - 0s     
Test score: 0.243211859068
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Test accuracy: 0.940443213296&lt;/strong&gt;&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmaller&quot; src=&quot;/writing/images/2016-1-13-neural-net-categorize-my-email/18-conf_normalized2.png&quot; alt=&quot;Conf mat 2&quot; /&gt; 
    &lt;figcaption&gt;The confusion matrix for the updated neural net results&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;How about that! After all that, the neural net can predict categories that are right 94% of the time. I don’t know if not many people use categories in gmail, but if it really is this easy to make a classifier that is right most of the time, I would really like it if gmail indeed had such a machine-learned approach to one-click email organizing. But, for now, I can just feel nice knowing I managed to get a 20% improvement over my last attempt at this, and improve neural net performance from the F it got last time I tried to the A it receives now.&lt;/p&gt;


    &lt;p&gt;&lt;a href=&quot;/writing/organizing-my-emails-with-a-neural-net/&quot;&gt;Organizing My Emails with a Neural Net&lt;/a&gt; was originally published by Andrey Kurenkov at &lt;a href=&quot;&quot;&gt;Andrey Kurenkov's Web World&lt;/a&gt; on January 13, 2016.&lt;/p&gt;
  </content>
</entry>


  

<entry>
  <title type="html"><![CDATA[A 'Brief' History of Neural Nets and Deep Learning, Part 4]]></title>
  <link rel="alternate" type="text/html" href="/writing/a-brief-history-of-neural-nets-and-deep-learning-part-4/" />
  <id>/writing/a-brief-history-of-neural-nets-and-deep-learning-part-4</id>
  <published>2015-12-24T18:19:34-08:00</published>
  <updated>2015-12-24T18:19:34-08:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email>andreyvkurenkov@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;This is the fourth part in ‘A Brief History of Neural Nets and Deep Learning’. Parts 1-3 &lt;a href=&quot;http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning&quot;&gt;here&lt;/a&gt;, &lt;a href=&quot;http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning-part-2&quot;&gt;here&lt;/a&gt;, and &lt;a href=&quot;http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning-part-3&quot;&gt;here&lt;/a&gt;. In this part, we will get to the end of our story and see how Deep Learning emerged from the slump neural nets found themselves in by the late 90s, and the amazing state of the art results it has achieved since.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Ask anyone in machine learning what kept neural network research alive and they will probably mention one or all of these three names: Geoffrey Hinton, fellow Canadian Yoshua Bengio and Yann LeCun, of Facebook and New York University.”&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;the-deep-learning-conspiracy&quot;&gt;The Deep Learning Conspiracy&lt;/h1&gt;

&lt;p&gt;When you want a revolution, start with a conspiracy. With the ascent of Support Vector Machines and the failure of backpropagation, the early 2000s were a dark time for neural net research. LeCun and Hinton variously mention how in this period their papers or the papers of their students were routinely rejected from publication due to their subject being Neural Nets. The above quote is probably an exaggeration - certainly research in Machine Learning and AI was still very active, and other people such as Juergen Schmidhuber were also working with neural nets - but citation counts from the time make it clear that the excitement had leveled off, even if it did not completely evaporate. Still, they persevered. And they found a strong ally outside the research realm: The Canadian government. Funding from the Canadian Institute for Advanced Research (CIFAR), which encourages basic research without direct application, first encouraged Hinton to move to Canada in 1987, and funded his work until the mid 90s. … Rather than relenting and switching his focus, Hinton fought to continue work on neural nets, and managed to secure more funding from CIFAR as told well in &lt;a href=&quot;http://www.thestar.com/news/world/2015/04/17/how-a-toronto-professors-research-revolutionized-artificial-intelligence.html&quot;&gt;this exemplary piece&lt;/a&gt;&lt;sup id=&quot;fnref:1:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“But in 2004, Hinton asked to lead a new program on neural computation. The mainstream machine learning community could not have been less interested in neural nets.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;“It was the worst possible time,” says Bengio, a professor at the Université de Montréal and co-director of the CIFAR program since it was renewed last year. “Everyone else was doing something different. Somehow, Geoff convinced them.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;“We should give (CIFAR) a lot of credit for making that gamble.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;CIFAR “had a huge impact in forming a community around deep learning,” adds LeCun, the CIFAR program’s other co-director. “We were outcast a little bit in the broader machine learning community: we couldn’t get our papers published. This gave us a place where we could exchange ideas.””&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The funding was modest, but sufficient to enable a small group of researchers to keep working on the topic. And with this group, Hinton hatched a conspiracy: “rebrand” the frowned-upon filed of neural nets with the moniker “Deep Learning”. Then, what every researcher must dream of actually happened: Hinton, Simon Osindero, and Yee-Whye Teh published a paper in 2006 that was seen as a breakthrough, a breakthrough significant enough to rekindle interest in neural nets: &lt;a href=&quot;https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf&quot;&gt;&lt;strong&gt;A fast learning algorithm for deep belief nets&lt;/strong&gt;&lt;/a&gt;&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;. Though, as we’ll see, the ideas involved were all quite old, the movement that is ‘Deep Learning’ can very persuasively be said to have started precisely with this paper. But, more important than the name was the idea - that neural networks with many layers really could be trained well, if the weights are initialized in a clever way rather than randomly. Hinton &lt;a href=&quot;https://youtu.be/vShMxxqtDDs?t=6m59s&quot;&gt;once expressed&lt;/a&gt; the need for such an advance at the time:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Historically, this was very important in overcoming the belief that these deep neural networks were no good and could never be trained. And that was a very strong belief. A friend of mine sent a paper to ICML [International Conference on Machine Learning], not that long ago, and the referee said it should not accepted by ICML, because it was about neural networks and it was not appropriate for ICML. In fact if you look at ICML last year, there were no papers with ‘neural’ in the title accepted, so ICML should not accept papers about neural networks. That was only a few years ago. And one of the IEEE journals actually had an official policy of [not accepting your papers]. So, it was a strong belief.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34953?token=zHc69el3bU7qKD0PwPBDHVLSVQsc0nyufUrpCEm9164_1Alk9kBBHkl5ymeS-6xNRoN3bPMo-J1VV5llJxc5k3M&quot; alt=&quot;RBM&quot; /&gt; 
    &lt;figcaption&gt;A Restricted Boltzmann Machine. &lt;a href=&quot;http://deeplearning.net/tutorial/rbm.html&quot;&gt;(Source)&lt;/a&gt;&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;So what was the clever way of initializing weights? Well, the basic idea is to train each layer one by one with unsupervised training, which starts off the weights much better than just giving them random values, and then finishing with a round of supervised learning just as is normal for neural nets. Each layer starts out as a Restricted Boltzmann Machine (RBM), which is just a Boltzmann Machine without connections between hidden and visible units as illustrated above (really the same as in a Helmholtz machines), and is taught a generative model of data in an unsupervised fashion. It turns out that this form of Boltzmann machine can be trained in an efficient manner introduced by Hinton in the 2002 &lt;a href=&quot;http://www.cs.toronto.edu/~fritz/absps/tr00-004.pdf&quot;&gt;“Training Products of Experts by Minimizing Contrastive Divergence”&lt;/a&gt;&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;. Basically, this algorithm maximizes something other than the probability of the units generating the training data, which allows for a nice approximation and turns out to still work well. So, using this method, the algorithm is as such:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Train an RBM on the training data using contrastive-divergence. This is the first layer of the belief net.&lt;/li&gt;
  &lt;li&gt;Generate the hidden values of the trained RBM for the data, and train another RBM using model those hidden values. This is the second layer - ‘stack’ it on top of the first and keep weights in just one direction to form a belief net.&lt;/li&gt;
  &lt;li&gt;Keep doing step 2 for as many layers as are desired for the belief net.&lt;/li&gt;
  &lt;li&gt;If classification is desired, add a small set of hidden units that correspond to the classification labels and do a variation on the wake-sleep algorithm to ‘fine-tune’ the weights. Such combinations of unsupervised and supervised learning are often called &lt;strong&gt;semi-supervised&lt;/strong&gt; learning.&lt;/li&gt;
&lt;/ol&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34836?token=eme-iIQe7-0La4-L2TE4ho9Fmj3Hlx4z8dP0khGimjihi31RDYtsPPjHTB5TpCYPlH-I8xFqce5jrbln-lMwokE&quot; alt=&quot;From http://www.iro.umontreal.ca/~lisa/twiki/bin/view.cgi/Public/DeepVsShallowComparisonICML2007&quot; /&gt; 
    &lt;figcaption&gt;The layerwise pre-training that Hinton introduced. &lt;a href=&quot;http://deeplearning.net/tutorial/rbm.html&quot;&gt;(Source)&lt;/a&gt;&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;The paper concluded by showing that deep belief networks (DBNs) had state of the art performance on the standard MNIST character recognition dataset, significantly outperforming normal neural nets with only a few layers. Yoshua Bengio et al. followed up on this work in 2007 with &lt;a href=&quot;http://papers.nips.cc/paper/3048-greedy-layer-wise-training-of-deep-networks.pdf&quot;&gt;“Greedy Layer-Wise Training of Deep Networks”&lt;/a&gt;&lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;, in which they present a strong argument that deep machine learning methods (that is, methods with many processing steps, or equivalently with hierarchical feature representations of the data) are more efficient for difficult problems than shallow methods (which two-layer ANNs or support vector machines are examples of).&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34966?token=ylFbLB-4cILErX48_1I24s32Oz1uTA-Kr0HzMcF4MKvfhfTS-IG4ybsb8PGouGYxE5uZvVRoHjG_3W2AHs6xMWI&quot; alt=&quot;Autoencoder pre-supverised traning&quot; /&gt; 
    &lt;figcaption&gt;Another view of unsupervised pre-training, using autoencoders instead of RBMs. &lt;a href=&quot;https://commons.wikimedia.org/wiki/File:Stacked_Autoencoders.png?uselang=ru&quot;&gt;(Source)&lt;/a&gt;&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;They also present reasons for why the addition of unsupervised pre-training works, and conclude that this not only initializes the weights in a more optimal way, but perhaps more importantly leads to more useful learned representations of the data that enable the algorithm to end up with a more generalized model. In fact, using RBMs is not that important - unsupervised pre-training of normal neural net layers using backpropagation with plain Autoencoders layers proved to also work well. Likewise, at the same time another approach called Sparse Coding also showed that unsupervised feature learning was a powerful approach for improving supervised learning performance.&lt;/p&gt;

&lt;p&gt;So, the key really was having many layers of representation so that good high-level representation of data could be learned - in complete disagreement with the traditional approach of hand-designing some nice feature extraction steps and only then doing machine learning with the extracted features. Hinton and Bengio’s work had empirically demonstrated that fact, but more importantly, showed the premise that deep neural nets could not be trained well to be false. This, LeCun had already demonstrated with CNNs throughout the 90s, yet the research community largely refused to accept. Bengio, in collaboration with Yann LeCun, reiterated this on &lt;a href=&quot;http://yann.lecun.com/exdb/publis/pdf/bengio-lecun-07.pdf&quot;&gt;“Scaling Algorithms Towards AI”&lt;/a&gt;&lt;sup id=&quot;fnref:5&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Until recently, many believed that training deep architectures was too difficult an optimization problem. However, at least two different approaches have worked well in training such architectures: simple gradient descent applied to convolutional networks [LeCun et al., 1989, LeCun et al., 1998] (for signals and images), and more recently, layer-by-layer unsupervised learning followed by gradient descent [Hinton et al., 2006, Bengio et al., 2007, Ranzato et al., 2006]. Research on deep architectures is in its infancy, and better learning algorithms for deep architectures remain to be discovered. Taking a larger perspective on the objective of discovering learning principles that can lead to AI has been a guiding perspective of this work. We hope to have helped inspire others to seek a solution to the problem of scaling machine learning towards AI.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And inspire they did. Or at least, they started; though deep learning had not yet gained the tsumani momentum that it has today, the wave had unmistakably begun. Still, the results at that point were not that impressive - most of the demonstrated performance in the papers up to this point was for the MNIST dataset, a classic machine learning task that had been the standard benchmark for algorithms for about a decade. Hinton’s 2006 publication demonstrated a very impressive error rate of only 1.25% on the test set, but SVMs had already gotten an error rate of 1.4%, and even simple algorithms could get error rates in the low single digits. And, as was pointed out in the paper, Yann LeCun already demonstrated error rates of 0.95% in 1998 using CNNs.&lt;/p&gt;

&lt;p&gt;So, doing well on MNIST was not necessarily that big a deal. Aware of this and confident that it was time for Deep Learning to take the stage, Hinton and two of his graduate students, Abdel-rahman Mohamed and George Dahl, demonstrated their effectiveness at a far more challenging AI task: &lt;a href=&quot;http://www.cs.toronto.edu/~gdahl/papers/dbnPhoneRec.pdf&quot;&gt;Speech Recognition&lt;/a&gt;&lt;sup id=&quot;fnref:6&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;. Using DBNs, the two students and Hinton managed to improve on a decade-old performance record on a standard speech recognition dataset. This was an impressive achievement, but in retrospect seems like only a hint at what was coming - in short, many more broken records.&lt;/p&gt;

&lt;h1 id=&quot;the-importance-of-brute-force&quot;&gt;The Importance of Brute Force&lt;/h1&gt;

&lt;p&gt;The algorithmic advances described above were undoubtedly important to the emergence of deep learning, but there was another essential component that had emerged in the decade since the 1990s: pure computational speed. Following Moore’s law, computers got dozens of times faster since the slow days of the 90s, making learning with large datasets and many layers much more tractable. But even this was not enough - CPUs were starting to hit a ceiling in terms of speed growth, and computer power was starting to increase mainly through  weakly parallel computations by using several CPUs. To learn the millions of weights typical in deep models, the limitations of weak CPU parallelism had to be left behind and replaced with the massively parallel computing powers of GPUs. Realizing this is, in part, how Abdel-rahman Mohamed, George Dahl, and Geoff Hinton accomplished their record breaking speech recognition performance&lt;sup id=&quot;fnref:7&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Inspired by one of Hinton’s lectures on deep neural networks, Mohamed began applying them to speech - but deep neural networks required too much computing power for conventional computers – so Hinton and Mohamed enlisted Dahl. A student in Hinton’s lab, Dahl had discovered how to train and simulate neural networks efficiently using the same high-end graphics cards which make vivid computer games feasible on personal computers.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;They applied the same method to the problem of recognizing fragments of phonemes in very short windows of speech,” said Hinton. “They got significantly better results than previous methods on a standard three-hour benchmark.””&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It’s hard to say just how much faster using GPUs over CPUs was in this case, but the paper &lt;a href=&quot;http://www.machinelearning.org/archive/icml2009/papers/218.pdf&quot;&gt;“Large-scale Deep Unsupervised Learning using Graphics Processors”&lt;/a&gt;&lt;sup id=&quot;fnref:8&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt; of the same year suggests a number: 70 times faster. Yes, 70 times - reducing weeks of work into days, even a single day. The authors, who had previously developed Sparse Coding, included the prolific Machine Learning researcher Andrew Ng, who increasingly realized that making use of a lots of training data and of fast computation had been greatly undervalued by researchers in favor of incremental changes in learning algorithms. This idea was strongly supported by 2010’s &lt;a href=&quot;http://arxiv.org/pdf/1003.0358.pdf&quot;&gt;“Deep Big Simple Neural Nets Excel on Handwritten Digit Recognition”&lt;/a&gt;&lt;sup id=&quot;fnref:9&quot;&gt;&lt;a href=&quot;#fn:9&quot; class=&quot;footnote&quot;&gt;9&lt;/a&gt;&lt;/sup&gt; (notably co-written by J. Schmidhuber, one of the inventors of the recurrent LTSM networks), which showed a whopping %0.35 error rate could be achieved on the MNIST dataset without anything more special than really big neural nets, a lot of variations on the input, and efficient GPU implementations of backpropagation. These ideas had existed for decades, so although it could not be said that algorithmic advancements did not matter, this result did strongly support the notion that the brute force approach of big training sets and fast palatalized computations were also crucial.&lt;/p&gt;

&lt;p&gt;Dahl and Mohamed’s use of a GPU to improve get record breaking results was an early and relatively modest success, but it was sufficient to incite excitement and for the two to be invited to intern at Microsoft Research&lt;sup id=&quot;fnref:1:2&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. Here, the two would have the benefit from another trend in computing that had emerged by then: Big Data. That loosest of terms, which in the context of machine learning is easy to understand - lots of training data. And lots of training data is important, because without it neural nets still did not do great - they tended to overfit (perfectly work on the training data, but not generalize to new test data). This makes sense - the complexity of what large neural nets can compute is such that a lot of data is needed to avoid them learning every little unimportant aspect of the training set - but was a major challenge for researchers in the past. So now, the computing and data gathering powers of large companies proved invaluable. The two students handily proved the power of deep learning during their three month internship, and Microsoft Research has been at the forefront of deep learning speech recognition ever since.&lt;/p&gt;

&lt;p&gt;Microsoft was not the only BigCompany to recognize the power of deep learning (though it was handily the first). Navdeep Jaitly, another student of Hinton’s, went off to a summer internship at Google in 2011. There, he worked on Google’s speech recognition, and showed their existing setup could be much improved by incorporating deep learning. The revised approach soon powered Android’s speech recognition, replacing much of Google’s carefully crafted prior solution &lt;sup id=&quot;fnref:1:3&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;Besides the impressive effects of humble PhD interns on these gigantic companies’ products, what is notable here is that both companies were making use of the same ideas - ideas that were out in the open for anyone to work with. And in fact, the work by Microsoft and Google, as well as IBM and Hinton’s lab, resulted in the impressively titled &lt;a href=&quot;http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/38131.pdf&quot;&gt;“Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups”&lt;/a&gt;&lt;sup id=&quot;fnref:10&quot;&gt;&lt;a href=&quot;#fn:10&quot; class=&quot;footnote&quot;&gt;10&lt;/a&gt;&lt;/sup&gt; in 2012. Four research groups - three from companies that could certainly benefit from a briefcase full of patents on the emerging wonder technology of deep learning, and the university research group that popularized that technology - working together and publishing their results to the broader research community. If there was ever an ideal scenario for industry adopting an idea from research, this seems like it.&lt;/p&gt;

&lt;p&gt;Not to say the companies were doing this for charity. This was the beginning of all of them exploring how to commercialize the technology, and most of all Google. But it was perhaps not Hinton, but Andrew Ng who incited the company to become likely the world’s biggest commercial adopter and proponent of the technology. In 2011, Ng &lt;a href=&quot;https://medium.com/backchannel/google-search-will-be-your-next-brain-5207c26e4523#.b3x9b7ods&quot;&gt;incidentally met&lt;/a&gt; with the legendary Googler Jeff Dean while visiting the company, and chatted about his efforts to train neural nets with Google’s fantastic computational resources. This intrigued Dean, and together with Ng they formed Google Brain - an effort to build truly giant neural nets and explore what they could do. The work resulted in unsupervised neural net learning of an unprecedented scale - 16,000 CPU cores powering the learning of a whopping 1 billion weights (for comparison, Hinton’s breakthrough 2006 DBN had about 1 million weights). The neural net was trained on Youtube videos, entirely without labels, and learned to recognize the most common objects in those videos - leading of course to the internet’s collective glee over the net’s discovery of cats:&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34978?token=5YYsfXB4l7NfgnQSV-PHB3ctZ5NVQU0oc5W8MnG1LIDiO6wBW_f9C_hUixutvqV7N4fRH_P0W3ALuOdZbIGf_L4&quot; alt=&quot;cat&quot; /&gt; 
    &lt;figcaption&gt;Google's famous neural-net learned cat. This is the optimal input to one of the neurons. &lt;a href=&quot;https://googleblog.blogspot.com/2012/06/using-large-scale-brain-simulations-for.html&quot;&gt;(Source)&lt;/a&gt;&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;Cute as that was, it was also useful. As they reported in a regularly published paper, the features learned by the model could be used for record setting performance on a standard computer vision benchmark&lt;sup id=&quot;fnref:11&quot;&gt;&lt;a href=&quot;#fn:11&quot; class=&quot;footnote&quot;&gt;11&lt;/a&gt;&lt;/sup&gt;. With that, Google’s internal tools for training massive neural nets were born, and they have only continued to evolve since. The wave of Deep Learning research that began in 2006 had now undeniably made it into industry.&lt;/p&gt;

&lt;h1 id=&quot;the-ascendance-of-deep-learning&quot;&gt;The Ascendance of Deep Learning&lt;/h1&gt;

&lt;p&gt;While deep learning was making it into industry, the research community was hardly keeping still. The discovery that efficient use of GPUs and computing power in general was so important made people examine long-held assumptions and ask questions that should have perhaps been asked long ago - namely, why exactly does backpropagation not work well? The insight to ask why the old approaches did not work, rather than why the new approaches did, led Xavier Glort and Yoshua Bengio to write &lt;a href=&quot;http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf&quot;&gt;“Understanding the difficulty of training deep feedforward neural networks”&lt;/a&gt; in 2010&lt;sup id=&quot;fnref:12&quot;&gt;&lt;a href=&quot;#fn:12&quot; class=&quot;footnote&quot;&gt;12&lt;/a&gt;&lt;/sup&gt;. In it, they discussed two incredibly meaningful findings:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The particular non-linear activation function chosen for neurons in a neural net makes a big impact on performance, and the one often used by default is not a good choice.&lt;/li&gt;
  &lt;li&gt;It was not so much choosing random weights that was problematic, as choosing random weights without consideration for which layer the weights are for. The old vanishing gradient problem happens, basically, because backpropagation involves a sequence of multiplications that invariably result in smaller derivatives for earlier layers. That is, unless weights are chosen with difference scales according to the layer they are in - making this simple change results in significant&lt;/li&gt;
&lt;/ol&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34990?token=EsjkMeAXQXbIbaniAeVd0nqCOnwpl2PLo2SLnmkePeWbCSSBB0CG1lTOu_JDP2aDIqCWbB_rfGPuUm_A7MXj2wg&quot; alt=&quot;ReLU&quot; /&gt; 
    &lt;figcaption&gt;Different activation functions. The ReLU is the **rectified linear unit**. &lt;a href=&quot;https://imiloainf.wordpress.com/2013/11/06/rectifier-nonlinearities/&quot;&gt;(Source)&lt;/a&gt;&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;The second point is quite clear as to the conclusion, but the first opens the question: ‘what, then, is the best activation function’? Three different groups explored the question (a group with LeCun, with &lt;a href=&quot;http://yann.lecun.com/exdb/publis/pdf/jarrett-iccv-09.pdf&quot;&gt;“What is the best multi-stage architecture for object recognition?”&lt;/a&gt;&lt;sup id=&quot;fnref:13&quot;&gt;&lt;a href=&quot;#fn:13&quot; class=&quot;footnote&quot;&gt;13&lt;/a&gt;&lt;/sup&gt;, a group with Hinton, in &lt;a href=&quot;http://www.cs.toronto.edu/~fritz/absps/reluICML.pdf&quot;&gt;“Rectified linear units improve restricted boltzmann machines”&lt;/a&gt;&lt;sup id=&quot;fnref:14&quot;&gt;&lt;a href=&quot;#fn:14&quot; class=&quot;footnote&quot;&gt;14&lt;/a&gt;&lt;/sup&gt;, and a group with Bengio -&lt;a href=&quot;https://www.utc.fr/~bordesan/dokuwiki/_media/en/glorot10nipsworkshop.pdf&quot;&gt;“Deep Sparse Rectifier Neural Networks”&lt;/a&gt;&lt;sup id=&quot;fnref:15&quot;&gt;&lt;a href=&quot;#fn:15&quot; class=&quot;footnote&quot;&gt;15&lt;/a&gt;&lt;/sup&gt;), and they all found the same surprising answer: the very much non-differentiable and very simple function f(x)=max(0,x) tends to be the best. Surprising, because the function is kind of weird - it is not strictly differentiable, or rather is not differentiable precisely at zero, so on paper as far as math goes it looks pretty ugly. But, clearly the zero case is a pretty small mathemtical quibble - a bigger question is why such a simple functions, with constant derivatives on either side of 0, is so good. The answer is not precisely known, but a few ideas seem pretty well established:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Rectified activation leads to &lt;strong&gt;sparse&lt;/strong&gt; representations, meaning not that many neurons actually end up needing to output non-zero values for any given input. In the years leading up to this point sparsity was shown to be beneficial for deep learning, both because it represents information in a more robust manner and because it leads to significant computational efficiency (if most of your neurons are outputting zero, you can in effect ignore most of them and compute things much faster). Incidentally, researchers in computational neuroscience first introduced the importance of sparse computation in the context of the brain’s visual system, a decade before it was explored in the context of machine learning.&lt;/li&gt;
  &lt;li&gt;The simplicity of the function, and its derivatives, makes it much faster to work with than the exponential sigmoid or the trigonometric tanh. As with the use of GPUs, this turns out to not just be a small boost but really important for being able to scale neural nets to the point where they perform well on challenging problems.&lt;/li&gt;
  &lt;li&gt;A later analysis titled &lt;a href=&quot;http://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf&quot;&gt;“Rectifier Nonlinearities Improve Neural Network Acoustic Models”&lt;/a&gt;&lt;sup id=&quot;fnref:16&quot;&gt;&lt;a href=&quot;#fn:16&quot; class=&quot;footnote&quot;&gt;16&lt;/a&gt;&lt;/sup&gt;, co-written by Andrew Ng, also showed the constant 0 or 1 derivative of the ReLU not to detrimental to learning. In fact, it helps avoid the vanishing gradient problem that was the bane of backpropagation. Furthermore, beside producing more sparse representations, and it also produces more distributed representations - meaning is derived from the combination of multiple values of different neurons, rather than being localized to individual neurons.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;At this point, with all these discoveries since 2006, it had become clear that unsupervised pre-traning is not essential to deep learning. It was helpful, no doubt, but it was also shown that in some cases well done purely supervised training  (with the correct starting weight scales and activation function) could outperform training that included the unsupervised step. So, why indeed, did purely supervised learning with backpropagation not work well in the past? Geoffrey Hinton &lt;a href=&quot;https://youtu.be/IcOMKXAw5VA?t=21m29s&quot;&gt;summarized the finding up to today in these four points&lt;/a&gt;:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Our labeled datasets were thousands of times too small.&lt;/li&gt;
  &lt;li&gt;Our computers were millions of times too slow.&lt;/li&gt;
  &lt;li&gt;We initialized the weights in a stupid way.&lt;/li&gt;
  &lt;li&gt;We used the wrong type of non-linearity.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;So here we are. Deep learning. The culmination of decades of research, all leading to this:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Deep Learning =&lt;br /&gt;
        Lots of training data + Parallel Computation + Scalable, smart algorithms&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34968?token=mNMoQEOZRbbIXdXVDFZry4exMhFX-S9L8PH5MM1ADWxHdSgOcgwn-zp89AaoIoAT3_BqeE4V2XiXD7haXwqklP8&quot; alt=&quot;Equation&quot; /&gt; 
    &lt;figcaption&gt;I wish I was first to come up with this delightful equation, but it seems others came up with it before me. &lt;a href=&quot;http://www.computervisionblog.com/2015/05/deep-learning-vs-big-data-who-owns-what.html&quot;&gt;(Source)&lt;/a&gt;&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;Not to say that all that there was to figure out was figured out by this point. Far from it. What had been figured out is exactly the opposite: that people’s intuition was often wrong, and in particular unquestioned decisions and assumptions were often very unfounded. Asking simple questions, trying simple things - these had the power to greatly improve state of the art techniques. And precisely that has been happening, with many more ideas and approaches being explored and shared in deep learning since. An example: &lt;a href=&quot;http://arxiv.org/pdf/1207.0580.pdf&quot;&gt;“Improving neural networks by preventing co-adaptation of feature detectors”&lt;/a&gt;&lt;sup id=&quot;fnref:17&quot;&gt;&lt;a href=&quot;#fn:17&quot; class=&quot;footnote&quot;&gt;17&lt;/a&gt;&lt;/sup&gt; by G. E. Hinton et al. The idea is very simple: to prevent overfitting, randomly pretend some neurons are not there while training. Although incredibly simple, this idea - called &lt;strong&gt;Dropout&lt;/strong&gt; - is a very efficient means of implementing the hugely powerful approach of ensemble learning, which just means learning in many different ways from the training data. Random Forests, a dominating technique in machine learning to this day, is chiefly effective due to this ensemble learning. Training many different neural nets is possible but is far too computationally expensive, yet this very simple idea in essence achieves the same thing and indeed significantly improves performance.&lt;/p&gt;

&lt;p&gt;Still, having all these research discoveries since 2006 is not what made the computer vision or other research communities again respect neural nets. What did do it was something somewhat less noble: completely destroying non-deep learning methods on a modern competitive benchmark. Geoffrey Hinton enlisted two of his Dropout co-writers, Alex Krizhevsky and Ilya Sutskever, to apply the ideas discovered to create an entry to the ILSVRC-2012 computer vision competition. To me, it is very striking to now understand that their work, described in &lt;a href=&quot;&quot;&gt;“ImageNet Classification with deep convolutional neural networks”&lt;/a&gt;&lt;sup id=&quot;fnref:18&quot;&gt;&lt;a href=&quot;#fn:18&quot; class=&quot;footnote&quot;&gt;18&lt;/a&gt;&lt;/sup&gt;, is the combination of very old concepts (a CNN with pooling and convolution layers, variations on the input data) with several new key insight (very efficient GPU implementation, ReLU neurons, dropout), and that this, precisely this, is what modern deep learning is. So, how did they do? Far, far better than the next closest entry: their error rate was %15.3, whereas the second closest was %26.2. This, the first and only CNN entry in that competition, was an undisputed sign that CNNs, and deep learning in general, had to be taken seriously for computer vision. Now, almost all entries to the competition are CNNs - a neural net model Yann LeCun was working with since 1989. And, remember LTSM recurrent neural nets, devised in the 90s by by Sepp Hochreiter and Jürgen Schmidhuber to solve the backpropagation problem? Those, too, are now state of the art for sequential tasks such as speech processing.&lt;/p&gt;

&lt;p&gt;This was the turning point. A mounting wave of excitement about possible progress has culminated in undeniable achievements, that far surpassed what other known techniques could manage. The tsunami metaphor that we started with in part 1, this is where it began, and it has been growing and intensifying to this day. Deep learning is here, and no winter is in sight.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34991?token=qzrUAAJqtenu9pNK9CtttT7LRBHwKlOr7udYaUSBRoKNhJjnTJJhUYBGmkUcZVqVvm_D3UwK23d-yTj1ni-clhU&quot; alt=&quot;From Google Scholar&quot; /&gt; 
    &lt;figcaption&gt;The citation counts for some of the key people we have seen develop deep learning. I believe I don't need to point out the exponential trends since 2012. From Google Scholar. &lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;h1 id=&quot;epilogue-state-of-the-art&quot;&gt;Epilogue: state of the art&lt;/h1&gt;

&lt;p&gt;If this were a movie, the 2012 ImageNet competition would likely have been the climax, and now we would have a progression of text describing ‘where are they now’. Yann Lecun - Facebook. Geoffrey Hinton - Google. Andrew Ng - Coursera, Google, Baidu. Bengio, Schmidhuber, and Hochreiter actually still in academia - but presumably with many more citations and/or grad students&lt;sup id=&quot;fnref:19&quot;&gt;&lt;a href=&quot;#fn:19&quot; class=&quot;footnote&quot;&gt;19&lt;/a&gt;&lt;/sup&gt;.  Though the ideas and achievements of deep learning are definitely exciting, while writing this I was inevitably also moved that these people, who worked in this field for decades and even as most abandoned it, are now rich, successful, and most of all better situated to do research than ever. All these peoples’ ideas are still very much out in the open, and in fact basically all these companies are open sourcing their deep learning frameworks, like some sort of utopian vision of industry-led research. What a story.&lt;/p&gt;

&lt;p&gt;I was foolish enough to hope I could fit a summary of the most impressive results of the past several years in this part, but at this point it is clear I will not have the space to do so. Perhaps one day there will be a part five of this that can finish out the tale by describing these things, but for now let me provide a brief list:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The resurgence of LTSM RNNs + representing ‘ideas’ with &lt;a href=&quot;http://machinelearning.wustl.edu/mlpapers/paper_files/BengioDVJ03.pdf&quot;&gt;distributed representations&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34992?token=BfZWKt2mBMH5H3j82QmADSH7i1sKJemavojs6daR5fbgqsxTIpTXn47ji7ChiCqCrkp8jJS7nPpRZhRKlNh9L2E&quot; alt=&quot;From Google, taken at https://gigaom.com/2014/11/18/google-stanford-build-hybrid-neural-networks-that-can-explain-photos/&quot; /&gt; 
    &lt;figcaption&gt;A result from last year. Just look at that! &lt;a href=&quot;https://gigaom.com/2014/11/18/google-stanford-build-hybrid-neural-networks-that-can-explain-photos/&quot;&gt;(Source)&lt;/a&gt;&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;&lt;a href=&quot;http://blogs.microsoft.com/blog/2014/05/27/microsoft-demos-breakthrough-in-real-time-translated-conversations/&quot;&gt;Skype real time translation&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Using deep learning for reinforcement learning (again, but better)&lt;/li&gt;
&lt;/ol&gt;

&lt;figure&gt;
&lt;iframe width=&quot;420&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/V1eYniJ0Rnk&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;a href=&quot;Schmidhuber&quot;&gt;Chess playing!&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Adding external memory writable and readable to by the neural net&lt;/li&gt;
&lt;/ol&gt;

&lt;figure&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/U_Wgc1JOsBk&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;Kate Allen. How a Toronto professor’s research revolutionized artificial intelligence Science and Technology reporter, Apr 17 2015 http://www.thestar.com/news/world/2015/04/17/how-a-toronto-professors-research-revolutionized-artificial-intelligence.html &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:1:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; &lt;a href=&quot;#fnref:1:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; &lt;a href=&quot;#fnref:1:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;Hinton, G. E., Osindero, S., &amp;amp; Teh, Y. W. (2006). A fast learning algorithm for deep belief nets. Neural computation, 18(7), 1527-1554. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;Hinton, G. E. (2002). Training products of experts by minimizing contrastive divergence. Neural computation, 14(8), 1771-1800. &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot;&gt;
      &lt;p&gt;Bengio, Y., Lamblin, P., Popovici, D., &amp;amp; Larochelle, H. (2007). Greedy layer-wise training of deep networks. Advances in neural information processing systems, 19, 153. &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot;&gt;
      &lt;p&gt;Bengio, Y., &amp;amp; LeCun, Y. (2007). Scaling learning algorithms towards AI. Large-scale kernel machines, 34(5). &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot;&gt;
      &lt;p&gt;Mohamed, A. R., Sainath, T. N., Dahl, G., Ramabhadran, B., Hinton, G. E., &amp;amp; Picheny, M. (2011, May). Deep belief networks using discriminative features for phone recognition. In Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on (pp. 5060-5063). IEEE. &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:7&quot;&gt;
      &lt;p&gt;November 26, 2012. Leading breakthroughs in speech recognition software at Microsoft, Google, IBM  Source: http://news.utoronto.ca/leading-breakthroughs-speech-recognition-software-microsoft-google-ibm &lt;a href=&quot;#fnref:7&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:8&quot;&gt;
      &lt;p&gt;Raina, R., Madhavan, A., &amp;amp; Ng, A. Y. (2009, June). Large-scale deep unsupervised learning using graphics processors. In Proceedings of the 26th annual international conference on machine learning (pp. 873-880). ACM. &lt;a href=&quot;#fnref:8&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:9&quot;&gt;
      &lt;p&gt;Claudiu Ciresan, D., Meier, U., Gambardella, L. M., &amp;amp; Schmidhuber, J. (2010). Deep big simple neural nets excel on handwritten digit recognition. arXiv preprint arXiv:1003.0358. &lt;a href=&quot;#fnref:9&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:10&quot;&gt;
      &lt;p&gt;Hinton, G., Deng, L., Yu, D., Dahl, G. E., Mohamed, A. R., Jaitly, N., … &amp;amp; Kingsbury, B. (2012). Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups. Signal Processing Magazine, IEEE, 29(6), 82-97. &lt;a href=&quot;#fnref:10&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:11&quot;&gt;
      &lt;p&gt;Le, Q. V. (2013, May). Building high-level features using large scale unsupervised learning. In Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on (pp. 8595-8598). IEEE. &lt;a href=&quot;#fnref:11&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:12&quot;&gt;
      &lt;p&gt;Glorot, X., &amp;amp; Bengio, Y. (2010). Understanding the difficulty of training deep feedforward neural networks. In International conference on artificial intelligence and statistics (pp. 249-256). &lt;a href=&quot;#fnref:12&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:13&quot;&gt;
      &lt;p&gt;Jarrett, K., Kavukcuoglu, K., Ranzato, M. A., &amp;amp; LeCun, Y. (2009, September). What is the best multi-stage architecture for object recognition?. In Computer Vision, 2009 IEEE 12th International Conference on (pp. 2146-2153). IEEE. &lt;a href=&quot;#fnref:13&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:14&quot;&gt;
      &lt;p&gt;Nair, V., &amp;amp; Hinton, G. E. (2010). Rectified linear units improve restricted boltzmann machines. In Proceedings of the 27th International Conference on Machine Learning (ICML-10) (pp. 807-814). &lt;a href=&quot;#fnref:14&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:15&quot;&gt;
      &lt;p&gt;Glorot, X., Bordes, A., &amp;amp; Bengio, Y. (2011). Deep sparse rectifier neural networks. In International Conference on Artificial Intelligence and Statistics (pp. 315-323). &lt;a href=&quot;#fnref:15&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:16&quot;&gt;
      &lt;p&gt;Maas, A. L., Hannun, A. Y., &amp;amp; Ng, A. Y. (2013, June). Rectifier nonlinearities improve neural network acoustic models. In Proc. ICML (Vol. 30). &lt;a href=&quot;#fnref:16&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:17&quot;&gt;
      &lt;p&gt;Hinton, G. E., Srivastava, N., Krizhevsky, A., Sutskever, I., &amp;amp; Salakhutdinov, R. R. (2012). Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint arXiv:1207.0580. &lt;a href=&quot;#fnref:17&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:18&quot;&gt;
      &lt;p&gt;Krizhevsky, A., Sutskever, I., &amp;amp; Hinton, G. E. (2012). Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems (pp. 1097-1105). &lt;a href=&quot;#fnref:18&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:19&quot;&gt;
      &lt;p&gt;http://www.technologyreview.com/news/524026/is-google-cornering-the-market-on-deep-learning/ &lt;a href=&quot;#fnref:19&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;

    &lt;p&gt;&lt;a href=&quot;/writing/a-brief-history-of-neural-nets-and-deep-learning-part-4/&quot;&gt;A 'Brief' History of Neural Nets and Deep Learning, Part 4&lt;/a&gt; was originally published by Andrey Kurenkov at &lt;a href=&quot;&quot;&gt;Andrey Kurenkov's Web World&lt;/a&gt; on December 24, 2015.&lt;/p&gt;
  </content>
</entry>


  

<entry>
  <title type="html"><![CDATA[A 'Brief' History of Neural Nets and Deep Learning, Part 3]]></title>
  <link rel="alternate" type="text/html" href="/writing/a-brief-history-of-neural-nets-and-deep-learning-part-3/" />
  <id>/writing/a-brief-history-of-neural-nets-and-deep-learning-part-3</id>
  <published>2015-12-24T17:19:34-08:00</published>
  <updated>2015-12-24T17:19:34-08:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email>andreyvkurenkov@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;This is the third part of ‘A Brief History of Neural Nets and Deep Learning’. Parts 1 and 2 are &lt;a href=&quot;http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning-part-2&quot;&gt;here&lt;/a&gt;, and part 4 is &lt;a href=&quot;http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning-part-4&quot;&gt;here&lt;/a&gt;. In this part, we will continue to see the swift pace of research in the 90s, and see why neural nets ultimately lost favor much as they did in the late 60s.&lt;/p&gt;

&lt;h1 id=&quot;neural-nets-make-decisions&quot;&gt;Neural Nets Make Decisions&lt;/h1&gt;

&lt;p&gt;Having discovered the application of neural nets to unsupervised learning, let us also quickly see how they were used in the third branch of machine learning: &lt;strong&gt;reinforcement learning&lt;/strong&gt;. This one requires the most mathy notation to explain formally, but also has a goal that is very easy to describe informally: learn to make good decisions. Given some theoretical agent (a little software program, for instance), the idea is to make that agent able to decide on an &lt;strong&gt;action&lt;/strong&gt; based on its current &lt;strong&gt;state&lt;/strong&gt;, with the reception of some &lt;strong&gt;reward&lt;/strong&gt; for each action and the intent of getting the maximum &lt;strong&gt;utility&lt;/strong&gt; in the long term. So, whereas supervised learning tells the learning algorithm exactly what it should learn to output, reinforcement learning provides ‘rewards’ as a by-product of making good decisions over time, and does not directly tell the algorithm the correct decisions to choose.  From the outset it was a very abstracted decision making model - there was a finite number of states, and a known set of actions with known rewards for each state. This made it easy to write very elegant equations for finding the optimal set of actions, but hard to apply to real problems -  problems with continuous states or hard to define reward.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34985?token=8S98i7brY2iTusq7B68-OHsvSS-ND9Kc5F_-XnppdoNFt6hyAbhhxRZ5W4ipFEaF-N4XX9yjAMyDdKx0QKL4--Q&quot; alt=&quot;RL&quot; /&gt; 
    &lt;figcaption&gt;Reinforcement learning. &lt;a href=&quot;http://www2.hawaii.edu/~chenx/ics699rl/grid/rl.html&quot;&gt;(Source)&lt;/a&gt;&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;This is where neural nets come in. Machine learning in general, and neural nets in particular, are good at dealing with messy continuous data or dealing with hard to define functions by learning them from examples. Although classification is the bread and butter of neural nets, they are general enough to be useful for many types of problems - the descendants of Bernard Widrow’s and Ted Hoff’s Adaline were used for adaptive filters in the context of electrical circuits, for instance. And so, following the resurgence of research caused by backpropagation people soon devised ways of leveraging the power of neural nets to perform reinforcement learning. One of the early examples of this was solving a simple yet classic problem: the balancing of a stick on a moving platform, known to students in control classes everywhere as the inverted pendulum problem &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34982?token=k1WhSbXvaWX6oxEe7C_ChtP_n-ypQHY9JsSZc1Q8gwFlTKGjUaW0wuou46Um2KbDryXEKXnZqcThjIJX2MyDXmY&quot; alt=&quot;pendulum &quot; /&gt; 
    &lt;figcaption&gt;The double pendulum control problem - a step up from the single pendulum version, which is a classic control and reinforcement learning task. &lt;a href=&quot;hhttp://www.pdx.edu/biomedical-signal-processing-lab/inverted-double-pendulum&quot;&gt;(Source)&lt;/a&gt;&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;As with adaptive filtering, this research was strongly relevant to the field of Electrical Engineering, where the control theory had been a major subfield for many decades prior to neural nets’ arrival. Though the field had devised ways to deal with many problems through direct analysis, having a means to deal with more complex situations through learning proved useful - as evidenced by the hefty 7000 (!) citations of the 1990 “Identification and control of dynamical systems using neural networks”&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;. Perhaps predictably, there was another field separate from Machine Learning where neural nets were useful - robotics. And, perhaps predictably, a major research initiative in the field was having robots learn to solve various problems rather than being manually programmed to do so, as exemplified by the 1993 PhD thesis &lt;a href=&quot;http://www.dtic.mil/dtic/tr/fulltext/u2/a261434.pdf&quot;&gt;“Reinforcement learning for robots using neural networks”&lt;/a&gt;&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;. The thesis showed that robots could be taught behaviors such as wall following and door passing in reasonable amounts of time, which was a good thing considering the prior inverted pendulum work requires impractical lengths of training.&lt;/p&gt;

&lt;p&gt;These disparate applications in other fields are certainly cool, but of course the most research on reinforcement learning and neural nets was happening within AI and Machine Learning. And here, one of the most significant results in the history of reinforcement learning was achieved: a neural net that learned to be a world class backgammon player.  Dubbed &lt;a href=&quot;http://courses.cs.washington.edu/courses/cse590hk/01sp/Readings/tesauro95cacm.pdf&quot;&gt;TD-Gammon&lt;/a&gt;, , the neural net was trained using a standard reinforcement learning algorithm and was one of the first demonstrations of reinforcement learning being able to outperform humans on relatively complicated tasks &lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;. And it was specifically a reinforcement learning approach that worked here, as the same research showed&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34983?token=iTl1pbpNKoeqgLWOC7YNBJYTYokPCrYeH8WhMh6Pn7a2Ie9y3zigQjMDiD55r_ZQLzmxgaf_NxWmls9cNMkAw50&quot; alt=&quot;TDGammon&quot; /&gt; 
    &lt;figcaption&gt;The neural net that learned to play expert-level Backgammon. &lt;a href=&quot;https://webdocs.cs.ualberta.ca/~sutton/book/ebook/node108.html&quot;&gt;(Source)&lt;/a&gt;&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;But, as we have seen happen before and will see happen again in AI, research hit a dead end. The predictable next problem to tackle using the TD-Gammon approach was investigated by Sebastian Thrun in the 1995 &lt;a href=&quot;http://www-preview.ri.cmu.edu/pub_files/pub1/thrun_sebastian_1995_8/thrun_sebastian_1995_8.pdf&quot;&gt;“Learning To Play the Game of Chess”&lt;/a&gt;, and the results were not good &lt;sup id=&quot;fnref:5&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;. Though the neural net learned decent play, certainly better than a complete novice at the game, it was still far worse than a standard computer program (GNU-Chess) implemented long before. The same was true for the other perennial challenge of AI, Go &lt;sup id=&quot;fnref:6&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;. See, TD-Gammon sort of cheated - it learned to evaluate positions quite well, and so could get away with not doing any ‘search’ over multiple future moves and instead just picking what the one that led to the best next position. But the same is simply not possible in chess or Go, games which are a challenge to AI precisely because of needing to look many moves ahead and having so many possible move combinations. Besides, even if the algorithm was smarter, the hardware of the time just was not up to the task - Thrun reported that “NeuroChess does a poor job, because it spends most of its time computing board evaluations. Computing a large neural network function takes two orders of magnitude longer than evaluating an optimized linear evaluation function (like that of GNU-Chess).” The weakness of computers of the time relative to the needs of the neural nets was a very real issue, and as we shall see not the only one…&lt;/p&gt;

&lt;h1 id=&quot;neural-nets-get-loopy&quot;&gt;Neural Nets Get Loopy&lt;/h1&gt;

&lt;p&gt;As neat as unsupervised and reinforcement learning are, I think supervised learning is still my favorite use case for neural nets. Sure, learning probabilistic models of data is cool, but it’s simply much easier to get excited for the sorts of concrete problems solved by backpropagation. We already saw how Yann Lecun achieved quite good recognition of handwritten text (a technology which went on to be nationally deployed for check-reading, and much more a while later…), but there was another obvious and greatly important task being worked on at the same time: understanding human speech.&lt;/p&gt;

&lt;p&gt;As with writing, understanding human speech is quite difficult due to the practically infinite variation in how the same word can be spoken. But, here there is an extra challenge: long sequences of input. See, for images it’s fairly simple to crop out a single letter from an image and have a neural net tell you what letter that is, input-&amp;gt;output style. But with audio it’s not so simple - separating out speech into characters is completely impractical, and even  finding individual words within speech is less simple. Plus, if you think about human speech, generally hearing words in context makes them easier to understand than being separated. While this structure works quite well for processing things such as images one at a time, input-&amp;gt;output style, it is not at all well suited to long streams of information such as audio or text. The neural net has no ‘memory’ with which an input can affect another input processed afterward, but this is precisely how we humans process audio or text - a string of word or sound inputs, rather than a single large input. Point being: to tackle the problem of understanding speech, researchers sought to modify neural nets to process input as a stream of input as in speech rather than one batch as with an image.&lt;/p&gt;

&lt;p&gt;One approach to this, by Alexander Waibel et. al  (including Hinton), was introduced in the 1989 &lt;a href=&quot;http://www.cs.toronto.edu/~fritz/absps/waibelTDNN.pdf&quot;&gt;“Phoneme recognition using &lt;strong&gt;time-delay neural networks&lt;/strong&gt;”&lt;/a&gt;&lt;sup id=&quot;fnref:7&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;. These time-delay neural networks (TDNN) were very similar to normal neural networks, except each neuron processed only a subset of the input and had several sets of weights for different delays of the input data. In other words, for a sequence of audio input, a ‘moving window’ of the audio is input into the network and as the window moves the same bits of audio are processed by each neuron with different sets of weights based on where in the window the bit of audio is. This is best understood with a quick illustration:&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34902?token=I-gRSza-SJchfi0jbeWtZxR7YaGXvDHCdJ7YyQx6h_hFxJotY8-jgChVwcwbP9hGCl-YKm36PUgvsCtS9pDhDZI&quot; alt=&quot;TDNN&quot; /&gt; 
    &lt;figcaption&gt;Time delay neural networks. &lt;a href=&quot;https://electroviees.wordpress.com/tag/chacha/&quot;&gt;(Source)&lt;/a&gt;&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;In a sense, this is quite similar to what CNNs do - instead of looking at the whole input at once, each unit looks at just a subset of the input at a time and does the same computation for each small subset. The main difference here is that there is no idea of time in a CNN, and the ‘window’ of input for each neuron is always moved across the whole input image to compute a result, whereas in a TDNN there actually is sequential input and output of data. Fun fact: &lt;a href=&quot;https://youtu.be/vShMxxqtDDs?t=26m4s&quot;&gt;according to Hinton&lt;/a&gt;, the idea of TDNNs is what inspired LeCun to develop convolutional neural nets. But, funnily enough CNNs became essential for image processing, whereas in speech recognition TDNNs have been surpassed to another approach - &lt;strong&gt;recurrent neural nets&lt;/strong&gt; (RNNs). See, all the networks that have been discussed so far have been &lt;strong&gt;feedforward&lt;/strong&gt; networks, meaning that the output of neurons in a given layer acts as input to only neuron in a next layer. But, it does not have to be so - there is nothing prohibiting us brave computer scientists from connecting output of the last layer act as an input to the first layer, or just connecting the output of a neuron to itself. By having the output of the network ‘loop’ back into the network, the problem of giving the network memory as to past inputs is solved so elegantly!&lt;/p&gt;

&lt;div&gt;&lt;button class=&quot;btn&quot; data-toggle=&quot;collapse&quot; data-target=&quot;#rnnvs&quot;&gt;
Aside: more on RNNs vs TDNNs &amp;raquo;
&lt;/button&gt;&lt;/div&gt;
&lt;blockquote class=&quot;aside&quot;&gt;&lt;p id=&quot;rnnvs&quot; class=&quot;boltzmann&quot; style=&quot;height: 0px;&quot;&gt;
Again, those seeking greater insight into the distinctions between different neural nets would do well to just go back to the actual papers. Here is a nice summation of why RNNs are cooler than TDNNs for sequential data:
&quot;A recurrent network has cycles in its graph that allow it to store
information about past inputs for an amount of time that is not fixed a priori but rather depends on its weights and on the input data. The type of recurrent networks considered here can be used either for sequence recognition production or prediction units are not clamped and we are not interested in convergence to a fixed point. Instead the recurrent network
is used to transform an input sequence eg speech spectra into an output sequence eg degrees of evidence for phonemes. The main advantage of such recurrent networks is that the relevant past context can be represented in the activity of the hidden units and then used to produce to compute the output at each time step. In theory the network can learn how
to extract the relevant context information from the input sequence In contrast in network with time delays such as TDNNs the designer of the network must decide a priori by the choice of delay connections which part of the past input sequence should be used to predict the next output. According to the terminology introduced in the memory is static in the case of TDNNs but it is adaptive in the case of recurrent networks.&quot;
&lt;/p&gt;&lt;/blockquote&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34568?token=osHGQ5vZmlKI8wvUQDodyNnTzHvIIucFK6U0Z1ynSkEKrMZy1FEdoBrizZ7fujKpEWiYaC1-1fm8lMLh7GKKVuc&quot; alt=&quot;RNN&quot; /&gt; 
    &lt;figcaption&gt;Diagram of a Recurrent Neural Net. Recall Boltzmann Machines from before? Surprise! Those were recurrent neural nets. &lt;a href=&quot;http://www.wolframalpha.com/docs/timeline/computable-knowledge-history-6.html&quot;&gt;(Source)&lt;/a&gt;&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;Well, it’s not quite so simple. Notice the problem - if backpropagation relies on ‘propagating’ the error from the output layer backward, how do things work if the first layer connects back to the output layer? The error would go ahead and propagate from the first layer back to the output layer, and could just keep looping through the network, infinitely. The solution, independently derived by multiple groups, is &lt;strong&gt;backpropagation through time&lt;/strong&gt;. Basically, the idea is to ‘unroll’ the recurrent neural network by treating each loop through the neural network as an input to another neural network, and looping only a limited number of times.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/35004?token=GxHCevxXTmakxvF9U8WazhEAPyVJK-uWNzaDfqra756dhTkvCVM2ElBUQNhmf6pL7U4_9boMOFGQ58mZRmm_jCo&quot; alt=&quot;The wonders of public domain images from Wikipedia!&quot; /&gt; 
    &lt;figcaption&gt;The wonderfully intuitive backpropagation through time concept. &lt;a href=&quot;https://upload.wikimedia.org/wikipedia/en/e/ee/Unfold_through_time.png&quot;&gt;(Source)&lt;/a&gt;&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;This fairly simple idea actually worked - it was possible to train recurrent neural nets. And indeed, multiple people explored the application of RNNs to speech recognition. But, here is a twist you should now be able to predict: this approach did not work very well. To find out why, let’s meet another modern giant of Deep Learning: Yoshua Bengio. Starting work on speech recognition with neural nets around 1986, he co-wrote many papers on using ANNs and RNNs for speech recognition, and ended up working at the AT&amp;amp;T Bell Labs on the problem just as Yann LeCun was working with CNNs there. In fact, in 1995 they co-wrote the summary paper &lt;a href=&quot;http://yann.lecun.com/exdb/publis/pdf/lecun-bengio-95a.pdf&quot;&gt;“Convolutional Networks for Images, Speech, and Time-Series”&lt;/a&gt;&lt;sup id=&quot;fnref:8&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt;, the first of many collaborations among them. But, before then Bengio wrote the 1993 &lt;a href=&quot;http://www.iro.umontreal.ca/~lisa/publications2/index.php/attachments/single/161&quot;&gt;“A Connectionist Approach to Speech Recognition”&lt;/a&gt;&lt;sup id=&quot;fnref:9&quot;&gt;&lt;a href=&quot;#fn:9&quot; class=&quot;footnote&quot;&gt;9&lt;/a&gt;&lt;/sup&gt;.  Here, he summarized the general failure of effectively teaching RNNs:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Although recurrent networks can in many instances outperform static networks, they appear more difficult to train optimally. Our experiments tended to indicate that their parameters settle in a suboptimal solution which takes into account short term dependencies but not long term dependencies. For example in experiments described in we found that simple duration constraints on phonemes had not at all been captured by the recurrent network. 
…
Although this is a negative result, a better understanding of this problem could help in designing alternative systems for learning to map input sequences to output sequences with
long term dependencies eg for learning finite state machines, grammars, and other language related tasks. Since gradient based methods appear inadequate for this kind of problem we want to consider alternative optimization methods that give acceptable results even when the criterion function is not smooth.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;a-new-winter-dawns&quot;&gt;A New Winter Dawns&lt;/h1&gt;

&lt;p&gt;So, there was a problem. A big problem. And the problem, basically, was what so recently was a huge advance: backpropagation. See, convolutional neural nets were important in part because backpropagation just did not work well normal neural nets with many layers. And that’s the real key to deep-learning - having many layers, in today’s systems as many as 20 or more. But already by the late 1980’s, it was known that deep neural nets trained with backpropagation just did not work very well, and particularly did not work as well as nets with fewer layers. The reason, in basic terms, is that backpropagation relies on finding the error at the output layer and successively splitting up blame for it for prior layers. Well, with many layers this calculus-based splitting of blame ends up with either huge or tiny numbers and the resulting neural net just does not work very well - the ‘vanishing or exploding gradient problem’. Jurgen Schmidhuber, another Deep Learning luminary, summarizes the more formal explanation well&lt;sup id=&quot;fnref:10&quot;&gt;&lt;a href=&quot;#fn:10&quot; class=&quot;footnote&quot;&gt;10&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“A diploma thesis (Hochreiter, 1991) represented a milestone of explicit DL research. As mentioned in Sec. 5.6, by the late 1980s, experiments had indicated that traditional deep feedforward or recurrent networks are hard to train by backpropagation (BP) (Sec. 5.5). Hochreiter’s work formally identified a major reason: Typical deep NNs suffer from the now famous problem of vanishing or exploding gradients. With standard activation functions (Sec. 1), cumulative backpropagated error signals (Sec. 5.5.1) either shrink rapidly, or grow out of bounds. In fact, they decay exponentially in the number of layers or CAP depth (Sec. 3), or they explode. “&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Backpropagation through time is essentially equivalent to a neural net with a whole lot of layers, so RNNs were particularly difficult to train with Backpropagation. Both Sepp Hochreiter, advised by Schmidhuber, and Yoshua Bengio published papers on the inability of learning long-term information due to limitations of backpropagation &lt;sup id=&quot;fnref:11&quot;&gt;&lt;a href=&quot;#fn:11&quot; class=&quot;footnote&quot;&gt;11&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&quot;fnref:12&quot;&gt;&lt;a href=&quot;#fn:12&quot; class=&quot;footnote&quot;&gt;12&lt;/a&gt;&lt;/sup&gt;. The analysis of the problem did reveal a solution - Schmidhuber and Hochreiter introduced a very important concept in 1997 that essentially solved the problem of how to train recurrent neural nets, much as CNNs did for feedforward neural nets - &lt;a href=&quot;http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf&quot;&gt;&lt;strong&gt;Long Short Term Memory&lt;/strong&gt;&lt;/a&gt; (LTSM)&lt;sup id=&quot;fnref:13&quot;&gt;&lt;a href=&quot;#fn:13&quot; class=&quot;footnote&quot;&gt;13&lt;/a&gt;&lt;/sup&gt;. In simple terms, as with CNNs the LTSM breakthrough ended up being a small alteration to the normal neural net model &lt;sup id=&quot;fnref:10:1&quot;&gt;&lt;a href=&quot;#fn:10&quot; class=&quot;footnote&quot;&gt;10&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“The basic LSTM idea is very simple. Some of the units are called Constant Error Carousels (CECs). Each CEC uses as an activation function f, the identity function, and has a connection to itself with ﬁxed weight of 1.0. Due to f’s constant derivative of 1.0, errors backpropagated through a CEC cannot vanish or explode (Sec. 5.9) but stay as they are (unless they “ﬂow out” of the CEC to other, typically adaptive parts of the NN). CECs are connected to several nonlinear adaptive units (some with multiplicative activation functions) needed for learning nonlinear behavior. Weight changes of these units often proﬁt from error signals propagated far back in time through CECs. CECs are the main reason why LSTM nets can learn to discover the importance of (and memorize) events that happened thousands of discrete time steps ago, while previous RNNs already failed in case of minimal time lags of 10 steps.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But, this did little to fix the larger perception problem that neural nets were janky and did not work very well. They were seen as a hassle to work with - the computers were not fast enough, the algorithms were not smart enough, and people were not happy. So, around the mid 90s, a new AI Winter for neural nets began to emerge - the community once again lost faith in them. A new method called Support Vector Machines, which in the very simplest terms could be described as a mathematically optimal way of training an equivalent to a two layer neural net, was developed and started to be seen as superior to the difficult to work with neural nets. In fact, the 1995 &lt;a href=&quot;http://yann.lecun.com/exdb/publis/pdf/lecun-95b.pdf&quot;&gt;“Comparison of Learning Algorithms For Handwritten Digit Recognition”&lt;/a&gt;&lt;sup id=&quot;fnref:14&quot;&gt;&lt;a href=&quot;#fn:14&quot; class=&quot;footnote&quot;&gt;14&lt;/a&gt;&lt;/sup&gt; by LeCun et al. found that this new approach worked better or the same as all but the best designed neural nets:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“The [support vector machine] classifier has excellent accuracy, which is most remarkable, because unlike the other high performance classifiers, it does not include &lt;em&gt;a priori&lt;/em&gt; knowledge about the problem. In fact, this classifier would do just as well if the image pixels were permuted with a fixed mapping. It is still much slower and memory hungry than the convolutional nets. However, improvements are expected as the technique is relatively new.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Other new methods, notably Random Forests, also proved to be very effective and with lovely mathematical theory behind them. So, despite the fact that CNNs consistently had state of the art performance, enthusiasm for neural nets dissipated and the machine learning community at large once again disavowed them. Winter was back. In &lt;a href=&quot;http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning-part-4&quot;&gt;part 4&lt;/a&gt;, we shall see how a small group of researchers persevered in this research climate and ultimately made Deep Learning what it is today.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;Anderson, C. W. (1989). Learning to control an inverted pendulum using neural networks. Control Systems Magazine, IEEE, 9(3), 31-37. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;Narendra, K. S., &amp;amp; Parthasarathy, K. (1990). Identification and control of dynamical systems using neural networks. Neural Networks, IEEE Transactions on, 1(1), 4-27. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;Lin, L. J. (1993). Reinforcement learning for robots using neural networks (No. CMU-CS-93-103). Carnegie-Mellon Univ Pittsburgh PA School of Computer Science. &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot;&gt;
      &lt;p&gt;Tesauro, G. (1995). Temporal difference learning and TD-Gammon. Communications of the ACM, 38(3), 58-68. &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot;&gt;
      &lt;p&gt;Thrun, S. (1995). Learning to play the game of chess. Advances in neural information processing systems, 7. &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot;&gt;
      &lt;p&gt;Schraudolph, N. N., Dayan, P., &amp;amp; Sejnowski, T. J. (1994). Temporal difference learning of position evaluation in the game of Go. Advances in Neural Information Processing Systems, 817-817. &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:7&quot;&gt;
      &lt;p&gt;Waibel, A., Hanazawa, T., Hinton, G., Shikano, K., &amp;amp; Lang, K. J. (1989). Phoneme recognition using time-delay neural networks. Acoustics, Speech and Signal Processing, IEEE Transactions on, 37(3), 328-339. &lt;a href=&quot;#fnref:7&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:8&quot;&gt;
      &lt;p&gt;Yann LeCun and Yoshua Bengio. 1998. Convolutional networks for images, speech, and time series. In The handbook of brain theory and neural networks, Michael A. Arbib (E()d.). MIT Press, Cambridge, MA, USA 255-258. &lt;a href=&quot;#fnref:8&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:9&quot;&gt;
      &lt;p&gt;Yoshua Bengio, A Connectionist Approach To Speech Recognition Int. J. Patt. Recogn. Artif. Intell., 07, 647 (1993). &lt;a href=&quot;#fnref:9&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:10&quot;&gt;
      &lt;p&gt;J. Schmidhuber. “Deep Learning in Neural Networks: An Overview”. “Neural Networks”, “61”, “85-117”. http://arxiv.org/abs/1404.7828 &lt;a href=&quot;#fnref:10&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:10:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:11&quot;&gt;
      &lt;p&gt;Hochreiter, S. (1991).  Untersuchungen zu dynamischen neuronalen Netzen. Diploma thesis, Institutfur Informatik, Lehrstuhl Prof. Brauer, Technische Universitat Munchen. Advisor: J. Schmidhuber. &lt;a href=&quot;#fnref:11&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:12&quot;&gt;
      &lt;p&gt;Bengio, Y.; Simard, P.; Frasconi, P., “Learning long-term dependencies with gradient descent is difficult,” in Neural Networks, IEEE Transactions on , vol.5, no.2, pp.157-166, Mar 1994 &lt;a href=&quot;#fnref:12&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:13&quot;&gt;
      &lt;p&gt;Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long Short-Term Memory. Neural Comput. 9, 8 (November 1997), 1735-1780. DOI=http://dx.doi.org/10.1162/neco.1997.9.8.1735. &lt;a href=&quot;#fnref:13&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:14&quot;&gt;
      &lt;p&gt;Y. LeCun, L. D. Jackel, L. Bottou, A. Brunot, C. Cortes, J. S. Denker, H. Drucker, I. Guyon, U. A. Muller, E. Sackinger, P. Simard and V. Vapnik: Comparison of learning algorithms for handwritten digit recognition, in Fogelman, F. and Gallinari, P. (Eds), International Conference on Artificial Neural Networks, 53-60, EC2 &amp;amp; Cie, Paris, 1995 &lt;a href=&quot;#fnref:14&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;

    &lt;p&gt;&lt;a href=&quot;/writing/a-brief-history-of-neural-nets-and-deep-learning-part-3/&quot;&gt;A 'Brief' History of Neural Nets and Deep Learning, Part 3&lt;/a&gt; was originally published by Andrey Kurenkov at &lt;a href=&quot;&quot;&gt;Andrey Kurenkov's Web World&lt;/a&gt; on December 24, 2015.&lt;/p&gt;
  </content>
</entry>


  

<entry>
  <title type="html"><![CDATA[A 'Brief' History of Neural Nets and Deep Learning, Part 2]]></title>
  <link rel="alternate" type="text/html" href="/writing/a-brief-history-of-neural-nets-and-deep-learning-part-2/" />
  <id>/writing/a-brief-history-of-neural-nets-and-deep-learning-part-2</id>
  <published>2015-12-24T16:19:34-08:00</published>
  <updated>2015-12-24T16:19:34-08:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email>andreyvkurenkov@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;This is the second part of ‘A Brief History of Neural Nets and Deep Learning’. Part 1 is &lt;a href=&quot;http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning&quot;&gt;here&lt;/a&gt;, and Parts 3 and 4 are &lt;a href=&quot;http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning-part-3&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning-part-4&quot;&gt;here&lt;/a&gt;. In this part, we will look into several strains of research that made rapid progress following the development of backpropagation and until the late 90s, which we shall see later are the essential foundations of Deep Learning.&lt;/p&gt;

&lt;h1 id=&quot;neural-nets-gain-vision&quot;&gt;Neural Nets Gain Vision&lt;/h1&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;http://yann.lecun.com/exdb/lenet/gifs/asamples.gif&quot; alt=&quot;LeNet&quot; /&gt; 
    &lt;figcaption&gt;Yann LeCun's LeNet demonstrated.&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;With the secret to training multilayer neural nets uncovered, the topic was once again ember-hot and the lofty ambitions of Rosenblatt seemed to perhaps be in reach. It took only until 1989 for another key finding now universally cited in textbooks and lectures to be &lt;a href=&quot;http://www.sciencedirect.com/science/article/pii/0893608089900208&quot;&gt;published&lt;/a&gt;&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;: “Multilayer feedforward networks are universal approximators”. Essentially, it mathematically proved that multiple layers allow neural nets to theoretically implement any function, and certainly XOR.&lt;/p&gt;

&lt;p&gt;But, this is mathematics, where you could imagine having endless memory and computation power should it be needed - did backpropagation allow neural nets to be used for anything in the real world? Oh yes. Also in 1989, Yann LeCunn et al. at the AT&amp;amp;T Bell Labs demonstrated a very significant real-world application of backpropagation in &lt;a href=&quot;http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf&quot;&gt;&quot;”Backpropagation Applied to Handwritten Zip Code Recognition”&lt;/a&gt; &lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;. You may think it fairly unimpressive for a computer to be able to correctly understand handwritten digits, and nowdays it is indeed quite quaint, but prior to the publication the messy and inconsistent scrawls of us humans proved a major challenge to the much more tidy minds of computers. The publication, working with a large dataset from the US Postal Service, showed neural nets were entirely capable of this task. And much more importantly, it was first to highlight the practical need for a key modifications of neural nets beyond plain backpropagation toward modern deep learning:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Classical work in visual pattern recognition has demonstrated the advantage of extracting local features and combining them to form higher order features. Such knowledge can be easily built into the network by forcing the hidden units to combine only local sources of information. Distinctive features of an object can appear at various location on the input image. Therefore it seems judicious to have a set of feature detectors that can detect a particular instance of a feature anywhere on the input place. Since the &lt;em&gt;precise&lt;/em&gt; location of a feature is not relevant to the classification, we can afford to lose some position information in the process. Nevertheless, &lt;em&gt;approximate&lt;/em&gt; position information must be preserved, to allow the next levels to detect higher order, more complex features (Fukushima 1980; Mozer 1987).”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/35003?token=pRZiRNO5tZB3uHSXV0bjIdzsP2tAUr9jpXUUChNI20Dwk0Y9JOMcGwtmmlgHGVzgJRGhXsr998Ogpxbl3K1Vn_8&quot; alt=&quot;CNN&quot; /&gt; 
    &lt;figcaption&gt;A visualization of how this neural net works. &lt;a href=&quot;http://image.slidesharecdn.com/bp2slides-090922011749-phpapp02/95/the-back-propagation-learning-algorithm-10-728.jpg?cb=1253582278&quot;&gt;(Source)&lt;/a&gt;&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;Or, more concretely: the first hidden layer of the neural net was &lt;strong&gt;convolutional&lt;/strong&gt; - instead of having each neuron have a different weight for each pixel of the input image (40x60=2400 weights), the neurons only had a small set of weights (5x5=25) that were applied a whole bunch of small subsets of the image of the same size. So, for instance instead of having 4 different neurons learn to detect 45 degree lines in each of the 4 corners of the input image, a single neuron could learn to detect 45 degree lines on subsets of the image and do that everywhere within it. Layers past the first work in a similar way, but take in the ‘local’ features locations found in the previous hidden layer rather than pixel images, and so ‘see’ successively larger portions of the image since they are combining information about increasingly larger subsets of the image. Finally, the last two layers are just plain normal neural net layers that use the higher-order larger features generated by the convolutional layers to determine which digit the input image corresponds to. The method proposed in this 1989 paper went on to be the basis of nationally deployed check-reading systems, as demonstrated by LeCun in this gem of a video:&lt;/p&gt;

&lt;figure&gt;
&lt;iframe width=&quot;420&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/FwFduRA_L6Q&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/figure&gt;

&lt;p&gt;The reason for why this is helpful is intuitively if not mathematically clear: without such constraints the network would have to learn the same simple things (such as detecting 45 degree lines, small circles, etc) a whole bunch of times for each portion of the image. But with the constraint there, only one neuron would need to learn each simple feature - and with far fewer weights overall, it could do so much faster! Moreover, since the pixel-exact location of such features does not matter it could basically skip neighboring subsets of the image - &lt;strong&gt;subsampling&lt;/strong&gt;, now known as a type of &lt;strong&gt;pooling&lt;/strong&gt; - when applying the weights, further reducing the training time. The addition of these two types of layers - convolutional and pooling layers - are the primary distinctions of &lt;strong&gt;Convolutional Neural Nets&lt;/strong&gt; (&lt;strong&gt;CNNs/ConvNets&lt;/strong&gt;) from plain old neural nets.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34967?token=cmXwbZkJ53nKUhEFA3zCrtdFDF1cVgfhGFBv1lD8Z7TPCqZpKRwR0Ht-vE-894hZyaWbYxUX8wak0QjMXvNq8P4&quot; alt=&quot;CNN 2&quot; /&gt; 
    &lt;figcaption&gt;A nice visualization of CNN operation &lt;a href=&quot;https://sites.google.com/site/5kk73gpu2013/assignment/cnn&quot;&gt;(Source)&lt;/a&gt;&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;At that time, the convolution idea was called ‘weight sharing’, and it was actually discussed in the 1986 extended analysis of backpropagation by Rumelhart, Hinton, and Williams&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;. Remarkably, Minsky and Papert’s 1969 analysis of Perceptrons was thorough enough to pose a problem that motivated this idea. But, as before, others have also independently explored the concept - namely, Kunihiko Fukushima in 1980 with his notion of the &lt;a href=&quot;http://www.cs.princeton.edu/courses/archive/spr08/cos598B/Readings/Fukushima1980.pdf&quot;&gt;Neurocognitron&lt;/a&gt;&lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;. And, as before, the ideas behind it drew inspiration from studies of the brain:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“According to the hierarchy model by Hubel and Wiesel, the neural network in the visual cortex has a hierarchy structure: LGB (lateral geniculate body)-&amp;gt;simple cells-&amp;gt;complex cells-&amp;gt;lower order hypercomplex cells-&amp;gt;higher order hypercomplex cells. It is also suggested that the neural network between lower order hypercomplex cells and higher order hypercomplex cells has a structure similar to the network between simple cells and complex cells. In this hierarchy, a cell in a higher stage generally has a tendency to respond selectively to a more complicated feature of the stimulus pattern, and, at the same time, has a larger receptive field, and is more insensitive to the shift in position of the stimulus pattern. 
… Hence, a structure similar to the hierarchy model is introduced in our model.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;LeCun continued to be a major proponent of CNNs at Bell Labs, and his work on them resulted in major commercial use for check-reading in the mid 90s - his talks and interviews often include &lt;a href=&quot;http://www.kdnuggets.com/2014/02/exclusive-yann-lecun-deep-learning-facebook-ai-lab.html&quot;&gt;the fact that&lt;/a&gt; “At some point in the late 1990s, one of these systems was reading 10 to 20% of all the checks in the US.”&lt;sup id=&quot;fnref:5&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;h1 id=&quot;neural-nets-go-unsupervised&quot;&gt;Neural Nets Go Unsupervised&lt;/h1&gt;

&lt;p&gt;Automating the rote and utterly uninteresting task of reading checks is a great instance of what Machine Learning can be used for. Perhaps a less predictable application? Compression. Meaning, of course, finding a smaller representation of some data from which the original data can be reconstructed. Learned compression may very well outperform stock compression schemes, in the case the learning algorithm can find features within the data stock methods would miss. And it is very easy to do - just train a neural net with a small hidden layer to just output the input:&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34875?token=N8kgwOTY2SLYiUmyWgp6q_SUr2lq1VZRCsqjuEcUzhSyxukW8SaukGh2U-PdFABd3WIkZlgtOr9pbVX_kGGUfnM&quot; alt=&quot;Autoencode&quot; /&gt; 
    &lt;figcaption&gt;An autoencoder neural net. &lt;a href=&quot;http://research.chtsai.org/papers/iml-bkp.html&quot;&gt;(Source)&lt;/a&gt;&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;This is an &lt;strong&gt;autoencoder&lt;/strong&gt; neural net, and is a method for learning compression - efficiently translating (encoding) data to a compact format and back to itself (auto). See, the output layer computes its outputs, which ideally are the same as the input to the neural net, using only the hidden layer’s outputs. Since the hidden layer has fewer outputs than does the input layer, the output of the hidden layer is the compressed representation of the input data, which can be reconstructed with the output layer.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34939?token=mIbhFk3rVIyx-Byzt6TXV1hGzMH7_w5sjy5OzeYM0qex33WDiI1PhspANLICVpp53PZyysX8yR9YahhXtBVkV6M&quot; alt=&quot;RBM&quot; /&gt; 
    &lt;figcaption&gt;A more explicit view of an autoencoder compression. &lt;a href=&quot;http://stats.stackexchange.com/questions/114385/what-is-the-difference-between-convolutional-neural-networks-restricted-boltzma&quot;&gt;(Source)&lt;/a&gt;&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;Notice a neat thing here: the only thing we need for training is some input data. This is in contrast to the requirement of supervised machine learning, which needs a training set of input-output pairs (&lt;strong&gt;labeled data&lt;/strong&gt;) in order to approximate a function that generalizes can compute such outputs from such inputs. And indeed, autoencoders are not a form of supervised learning; they are a form of &lt;strong&gt;unsupervised learning&lt;/strong&gt;, which only needs a set of input data (&lt;strong&gt;unlabeled data&lt;/strong&gt;) in order to find some hidden structure within that data. In other words, unsupervised learning does not approximate a function so much as it derives one from the input data to another useful representation of that data. In this case, this representation is just a smaller one from which the original data can still be reconstructed, but it can also be used for finding groups of similar data (&lt;strong&gt;clustering&lt;/strong&gt;) or other inference of &lt;strong&gt;latent variables&lt;/strong&gt; (some aspect that is known to exist for the data but the value of which is not known).&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34886?token=iEm6_7c5iGDJPTSNZ-amHkQyb3_f4G3657WBTHcyJJL87dQx8xTMxiJES68Mj0YhbbLx5YWkkaOR4QDkJHiG3-0&quot; alt=&quot;Clustering, from good ol' public domain wikipedia&quot; /&gt; 
    &lt;figcaption&gt;Clustering, a very common unsupervised learning application. &lt;a href=&quot;https://en.wikipedia.org/wiki/K-means_clustering&quot;&gt;(Source)&lt;/a&gt;&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;There were other unsupervised applications of neural networks explored prior to and after the discovery of backpropagation, most notably Self Organizing Maps &lt;sup id=&quot;fnref:6&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;, which produce a low-dimensional representation of data good for visualization, and Adapative Resonance Theory&lt;sup id=&quot;fnref:7&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;, which can learn to classify arbitrary input data without being told correct classifications. If you think about it, it is intuitive that quite a lot can be learned from unlabeled data. Say you have a dataset of a bunch of images of handwritten digits, without labels of which digit each image corresponds to. Well, an image with some digit in that dataset most likely looks most like all the other images with that same digit, and so though a computer may not know which digit all those images correspond to, it should still be able to find that they all correspond to the same one. This, &lt;strong&gt;pattern recognition&lt;/strong&gt;, is really what most of machine learning is all about, and arguably also is the basis for the great powers of the human brain. But, let us not digress from our exciting deep learning journey, and get back to autoencoders.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34887?token=rWIBfCstMS8Y3OsonIyWAOPNHnc9NZIGHs5JesWlo01UCpYKKcMbhJOCj-AvZuDS8VeENeNo35Z1BxQhkOexbHM&quot; alt=&quot;SOM&quot; /&gt; 
    &lt;figcaption&gt;Self Organizing Maps - mapping a large vector of inputs into a grid of neuron outputs, where each output is a cluster. Nearby neurons represent similar clusters. &lt;a href=&quot;http://lcdm.astro.illinois.edu/static/code/mlz/MLZ-1.0/doc/html/somz.html&quot;&gt;(Source)&lt;/a&gt;&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;As with weight-sharing, the idea of autoencoders was first discussed in the aforementioned extensive 1986 analysis of backpropagation &lt;sup id=&quot;fnref:3:1&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;, and as with weight-sharing it resurfaced in more research in the following years&lt;sup id=&quot;fnref:8&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&quot;fnref:9&quot;&gt;&lt;a href=&quot;#fn:9&quot; class=&quot;footnote&quot;&gt;9&lt;/a&gt;&lt;/sup&gt;, including by Hinton himself &lt;sup id=&quot;fnref:10&quot;&gt;&lt;a href=&quot;#fn:10&quot; class=&quot;footnote&quot;&gt;10&lt;/a&gt;&lt;/sup&gt;. This paper, with the fun title &lt;a href=&quot;http://www.cs.toronto.edu/~fritz/absps/cvq.pdf&quot;&gt;“Autoencoders, Minimum Description Length, and Helmholts Free Energy”&lt;/a&gt;, posits that “A natural approach to unsupervised learning is to use a model that defines probability distribution over observable vectors” and uses a neural net to learn such a model. So here’s another neat thing you can do with neural nets: approximate probability distributions.&lt;/p&gt;

&lt;h1 id=&quot;neural-nets-gain-beliefs&quot;&gt;Neural Nets Gain Beliefs&lt;/h1&gt;

&lt;p&gt;In fact, before being co-author of the seminal 1986 paper on backpropagation learning algorithm, Hinton worked on a neural-net approach for learning probability distributions in the 1985 &lt;a href=&quot;http://www.cs.toronto.edu/~fritz/absps/cogscibm.pdf&quot;&gt;“A Learning Algorithm for Boltzmann Machines”&lt;/a&gt; &lt;sup id=&quot;fnref:11&quot;&gt;&lt;a href=&quot;#fn:11&quot; class=&quot;footnote&quot;&gt;11&lt;/a&gt;&lt;/sup&gt;. Boltzmann Machines are networks just like neural nets and have units that are very similar to Perceptrons, but instead of computing an output based on inputs and weights, each unit in the network can compute a probability of it having a value of 1 or 0 given the values of connected units and weights. The units are therefore &lt;strong&gt;stochastic&lt;/strong&gt; - they behave according to a probability distribution, rather than in a known deterministic way. The Boltzmann part refers &lt;a href=&quot;https://en.wikipedia.org/wiki/Boltzmann_distribution&quot;&gt;to a probability distribution&lt;/a&gt; that has to do with the states of particles in a system based the particles’ energy and on the thermodynamic temperature of that system. This distribution defines not only the mathematics of the Boltzmann machines, but also the interpretation - the units in the network themselves have energies and states, and learning is done by minimizing the energy of the system and with direct inspirartion from thermodynamics. Though a bit unintuitive, this energy-based interpretation is actually just one example of an &lt;strong&gt;energy-based model&lt;/strong&gt;, and fits in the &lt;strong&gt;energy-based learning&lt;/strong&gt; theoretical framework with which many learning algorithms can be expressed&lt;sup id=&quot;fnref:ebm&quot;&gt;&lt;a href=&quot;#fn:ebm&quot; class=&quot;footnote&quot;&gt;12&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;div&gt;&lt;button class=&quot;btn&quot; data-toggle=&quot;collapse&quot; data-target=&quot;#ebm&quot;&gt;
Aside: a bit more Energy Based Models &amp;raquo;
&lt;/button&gt;&lt;/div&gt;
&lt;blockquote class=&quot;aside&quot;&gt;&lt;p id=&quot;ebm&quot; class=&quot;collapse&quot; style=&quot;height: 0px;&quot;&gt;
That there is a common theoretical framework for a bunch of learning methods is not too surprising, since at the end of the day all of learning boils down to optimization. Quoting from the above cited tutorial: 
&lt;br /&gt;&lt;br /&gt;
&quot;Training an EBM consists in finding an energy function that produces the best Y for any X ... The architecture of the EBM is the internal structure of the parameterized energy function E(W, Y, X) ... This quality measure is called the loss functional (i.e.  a function of function) and denoted L(E,S). ... In order to find the best energy function [] we need a way to assess the quality of any particular energy function, based solely on two elements: the training set, and our prior knowledge about the task. For simplicity, we often denote it L(W,S) and simply call it the loss function. The learning problem is simply to find the W that minimizes the loss.&quot; 
&lt;br /&gt;&lt;br /&gt;
So, the key to energy based models is recognizing all these algorithms are essentially different ways to optimize a pair of functions, that can be called the energy function E and loss function L, by finding a set of good values to a bunch of variables that can be denoted W using data denoted X for input and Y for the output. It's really a very broad definition for a framework, but still nicely encapsulates what a lot of algorithms fundamentally do.
&lt;/p&gt;&lt;/blockquote&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34928?token=uZt9tR3PMJ7XcI0pscNEF0hgpiGBmAWdxlT-mXi88-6jI1VKnv5eRXDeX2soiwQ2MJJuq1QeKvSOb1JiviyiZl8&quot; alt=&quot;Public domain from wikipedia&quot; /&gt; 
    &lt;figcaption&gt;A simple belief, or bayesian, network - a Boltzmann machine is basically this but with undirected/symmetric connections and trainable weights to learn the probabilities in a particular fashion. &lt;a href=&quot;https://commons.wikimedia.org/wiki/File:SimpleBayesNet.svg&quot;&gt;(Source)&lt;/a&gt; 
     &lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;Back to Boltzmann Machines. When such units are put together into a network, they form a graph, and so are a &lt;strong&gt;graphical model&lt;/strong&gt; of data. Essentially, they can do something very similar to normal neural nets: some &lt;strong&gt;hidden units&lt;/strong&gt; compute the probability of some &lt;strong&gt;hidden variables&lt;/strong&gt; (the outputs - classifications or features for data) given known values of &lt;strong&gt;visible units&lt;/strong&gt; that represent &lt;strong&gt;visible variables&lt;/strong&gt; (the inputs - pixels of images, characters in text, etc.). In the nice known example of classifying images of digits, the hidden variables are the actual digit values, and the visible variables are the pixels of the image; given an image of the digit ‘1’ as input, the value of visible units is known and the hidden unit modeling the probability of the image representing a ‘1’ should have a high output probability.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34944?token=wt8jYAmcmFL7nUvwusO-SYCwcXyM0_jECFgyhTNKc5OI7gyImufruQFh98267EgUTNKXFRmZqqPP9ia4OdaOhrQ&quot; alt=&quot;BM&quot; /&gt; 
    &lt;figcaption&gt;An example Boltzmann machine. Each line has an associated weight, as with a neural net. Notice there are no layers here - everything can sort of be connected to everything. We'll talk about this variation on neural net in a little bit... &lt;a href=&quot;https://en.wikipedia.org/wiki/File:Boltzmannexamplev1.png&quot;&gt;(Source)&lt;/a&gt;
     &lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;So, for the classification task, there is now a nice way of computing the probability of each category. This is very analogous to actually computing the output values of a normal classification neural net, but these nets have another neat trick: they can generate plausible looking input data. This follows from the probability equations involved - not only does the net learn the probabilities of values for the hidden variables given known values for the visible variables, but it also the inverse of that - visible probabilities given known hidden values. So, if we want to generate a ‘1’ digit image, the units corresponding to the pixel variables have known probabilities of outputting a 1 and an image can be probabilistically generated - these networks are &lt;strong&gt;generative graphical models&lt;/strong&gt;. Though it is possible to do supervised learning with very similar goals as normal neural nets, the unsupervised learning task of learning a good generative model - probabilistically learning the hidden structure of some data - is commonly what these nets are used for. Most of this was not really that novel, but the learning algorithm presented and the particular formulation that enabled it were, as stated in the paper itself:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Perhaps the most interesting aspect of the Boltzmann Machine formulation is that it leads to a domain-independent learning algorithm that modifies the connection strengths between units in such a way that the whole network develops an internal model which captures the underlying structure of its environment. There has been a long history of failure in the search for such algorithms (Newell, 1982), and many people (particularly in Artificial Intelligence)
now believe that no such algorithms exist.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div&gt;&lt;button class=&quot;btn&quot; data-toggle=&quot;collapse&quot; data-target=&quot;#boltzmann&quot;&gt;
Aside: more explanation of Boltzmann Machines &amp;raquo;
&lt;/button&gt;&lt;/div&gt;
&lt;blockquote class=&quot;aside&quot;&gt;&lt;p id=&quot;boltzmann&quot; class=&quot;aside&quot; style=&quot;height: 0px;&quot;&gt;
Having learned the classical neural net models first, it took me a while to understand the notion behind these probabilistic nets. To elaborate, let me present a quote from the paper itself that restates all that I have said above quite well:
&lt;br /&gt;&lt;br /&gt;
&quot;The network modifies the strengths of its connections so as to construct an internal generative model that produces examples with the same probability distribution as the examples it is shown. Then, when shown any particular example, the network can “interpret” it by finding values of the variables in the internal model that would generate the example.
&lt;br /&gt;
...
&lt;br /&gt;
The machine is composed of primitive computing elements called units that are connected to each other by bidirectional links. A unit is always in one of two states, on or off, and it adopts these states as a probabilistic function of the states of its neighboring units and the weights on its links to them. The weights can take on real values of either sign. A unit being on or
off is taken to mean that the system currently accepts or rejects some elemental hypothesis about the domain. The weight on a link represents a weak pairwise constraint between two hypotheses. A positive weight indicates that the two hypotheses tend to support one another; if one is currently accepted, accepting the other should be more likely. Conversely, a negative weight suggests, other things being equal, that the two hypotheses should not both be accepted. Link weights are symmetric, having the same strength in both directions (Hinton &amp;amp; Sejnowski, 1983).&quot;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Without delving into the full details of the algorithm, here are some highlights: it is a variant on &lt;strong&gt;maximum-likelihood&lt;/strong&gt; algorithms, which simply means that it seeks to maximize the probability of the net’s visible unit values matching with their known correct values. Computing the actual most likely value for each unit turns all at the same time out to be much too computationally expensive, so in training &lt;strong&gt;Gibbs Sampling&lt;/strong&gt; - starting the net with random unit values and iteratively reassigning values to units given their connections’ values - is used to give some actual known values. When learning using a training set, the visible units are just set to have the value of the current training example, so sampling is done to get values for the hidden units. Once some ‘real’ values are sampled, we can do something similar to backpropagation - take a derivative for each weight to see how we can change so as to increase the probability of the net doing the right thing.&lt;/p&gt;

&lt;p&gt;As with neural net, the algorithm can be done both in a supervised fashion (with known values for the hidden units) or in an unsupervised fashion. Though the algorithm was demonstrated to work (notably, with the same ‘encoding’ problem that autoencoder neural nets solve), it was soon apparent that it just did not work very well - Redford M. Neal’s 1992 &lt;a href=&quot;http://www.zabaras.com/Courses/BayesianComputing/Papers/1-s2.0-0004370292900656-main.pdf&quot;&gt;“Connectionist learning of belief networks”&lt;/a&gt;&lt;sup id=&quot;fnref:12&quot;&gt;&lt;a href=&quot;#fn:12&quot; class=&quot;footnote&quot;&gt;13&lt;/a&gt;&lt;/sup&gt; justified a need for a faster approach by stating that: “These capabilities would make the Boltzmann machine attractive in many applications, were it not that its learning procedure is generally seen as being painfully slow”. And so Neal introduced a similar idea in the &lt;strong&gt;belief net&lt;/strong&gt;, which is essentially like a Boltzmann machine with directed, forward connections (so that there are again layers, as with the the neural nets we have seen before, and unlike the Boltzmann machine image above). Without getting into mucky probability math, this change allowed the nets to be trained with a faster learning algorithm. We actually saw a ‘belief net’ just above with the sprinkler and rain variables, and the term was chosen precisely because this sort of probability-based modeling has a close relationship to idea from the mathematical field of probability, in addition to its link to the field of Machine Learning.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34893?token=vvO-2350CpV8LNjOLn8Tmcd2EFeZYCmgNj1GsYxzisrm0tqe2AF_FfynWcppZQdQ9823HTw9E2i8SC7XposnH0w&quot; alt=&quot;belief nets&quot; /&gt; 
    &lt;figcaption&gt;An explanation of belief nets. &lt;a href=&quot;http://www.slideserve.com/Leo/restricted-boltzmann-machines-and-deep-belief-networks&quot;&gt;(Source)&lt;/a&gt;&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;Though this approach was an advance upon Boltzmann machines, it was still just too slow - the math for correctly deriving probabilistic relations between variables is such that a ton of computation is typically required without some simplifying tricks. And so Hinton, along with Neal and two other co-authors, soon came up with extra tricks in the 1995 &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.82.804&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;“The &lt;strong&gt;wake-sleep algorithm&lt;/strong&gt; for unsupervised neural networks”&lt;/a&gt;&lt;sup id=&quot;fnref:13&quot;&gt;&lt;a href=&quot;#fn:13&quot; class=&quot;footnote&quot;&gt;14&lt;/a&gt;&lt;/sup&gt;. These tricks were such that they once again such that they called for a slightly different belief net setup, which was now deemed &lt;a href=&quot;http://www.gatsby.ucl.ac.uk/~dayan/papers/hm95.pdf&quot;&gt;“The Helmholtz Machine”&lt;/a&gt;&lt;sup id=&quot;fnref:14&quot;&gt;&lt;a href=&quot;#fn:14&quot; class=&quot;footnote&quot;&gt;15&lt;/a&gt;&lt;/sup&gt;. Skirting the details once again, the key idea was to have separate sets of weights for inferring hidden variables from visible variables (&lt;strong&gt;recognition weights&lt;/strong&gt;) and for vice versa (&lt;strong&gt;generative weights&lt;/strong&gt;), and to keep the directed aspect of Neal’s belief nets. This allows the training to be done much faster, while being applicable to the same unsupervised and supervised learning problems of Boltzmann Machines.&lt;/p&gt;

&lt;div&gt;&lt;button class=&quot;btn&quot; data-toggle=&quot;collapse&quot; data-target=&quot;#wakesleep&quot;&gt;
Aside: the gross simplifying assumption of the wake-sleep algorithm &amp;raquo;
&lt;/button&gt;&lt;/div&gt;
&lt;blockquote class=&quot;aside&quot;&gt;&lt;p id=&quot;wakesleep&quot; class=&quot;aside&quot; style=&quot;height: 0px;&quot;&gt;
When Hinton talks of the Wake Sleep algorithm, he often notes how gross the simplifying assumption being made is, and that despite that the algorithm just works. Again I will quote as the paper itself explains the assumption well:
&lt;br /&gt;&lt;br /&gt;
&quot;The key simplifying assumption is that the recognition distribution for a particular example  d, Q is factorial (separable) in each layer. If there are h stochastic binary units in a layer B, the portion of the distribution P(B,d) due to that layer is determined by 2^(h - 1) probabilities. However, Q makes the assumption that the actual activity of any one unit in layer P is independent of the activities of all the other units in that layer, given the activities of all the units in the lower layer, l - 1, so the recognition model needs only specify h probabilities rather than 2&quot; - 1. The independence assumption allows F(d; 8.4) to be evaluated efficiently, but this computational tractability is bought at a price, since the true posterior is unlikely to be factorial 
&lt;br /&gt;
...
&lt;br /&gt; 
The generative model is taken to be factorial in the same way, although one should note that factorial generative models rarely have recognition distributions that are themselves exactly factorial.&quot;
&lt;br /&gt;&lt;br /&gt;
Note the Neal's belief nets also implicitly made the probabilities factorize by having layers of units with only forward-facing directed connections.
&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Finally, belief nets could be trained somewhat fast! Though not quite as influential, this algorithmic advance was a significant enough forward step for unsupervised training of belief nets that it could be seen as a companion to the now almost decade-old breakthrough that was backpropagation. But, by this point new machine learning methods had begun to also emerge, and people were again beginning to be skeptical of neural nets since so much of their ideas seemed intuition-based and since computers were still barely able to meet their computational needs. As we’ll see in &lt;a href=&quot;http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning-part-3&quot;&gt;part 3&lt;/a&gt;, a new AI Winter for neural nets began just a few years later…&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;Kurt Hornik, Maxwell Stinchcombe, Halbert White, Multilayer feedforward networks are universal approximators, Neural Networks, Volume 2, Issue 5, 1989, Pages 359-366, ISSN 0893-6080, http://dx.doi.org/10.1016/0893-6080(89)90020-8. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;LeCun, Y; Boser, B; Denker, J; Henderson, D; Howard, R; Hubbard, W; Jackel, L, “Backpropagation Applied to Handwritten Zip Code Recognition,” in Neural Computation , vol.1, no.4, pp.541-551, Dec. 1989 89 &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;D. E. Rumelhart, G. E. Hinton, and R. J. Williams. 1986. Learning internal representations by error propagation. In Parallel distributed processing: explorations in the microstructure of cognition, vol. 1, David E. Rumelhart, James L. McClelland, and CORPORATE PDP Research Group (Eds.). MIT Press, Cambridge, MA, USA 318-362 &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:3:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot;&gt;
      &lt;p&gt;Fukushima, K. (1980), ‘Neocognitron: A Self-Organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position’, Biological Cybernetics 36 , 193–202 . &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot;&gt;
      &lt;p&gt;Gregory Piatetsky, ‘KDnuggets Exclusive: Interview with Yann LeCun, Deep Learning Expert, Director of Facebook AI Lab’ Feb 20, 2014. http://www.kdnuggets.com/2014/02/exclusive-yann-lecun-deep-learning-facebook-ai-lab.html &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot;&gt;
      &lt;p&gt;Teuvo Kohonen. 1988. Self-organized formation of topologically correct feature maps. In Neurocomputing: foundations of research, James A. Anderson and Edward Rosenfeld (Eds.). MIT Press, Cambridge, MA, USA 509-521. &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:7&quot;&gt;
      &lt;p&gt;Gail A. Carpenter and Stephen Grossberg. 1988. The ART of Adaptive Pattern Recognition by a Self-Organizing Neural Network. Computer 21, 3 (March 1988), 77-88. &lt;a href=&quot;#fnref:7&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:8&quot;&gt;
      &lt;p&gt;H. Bourlard and Y. Kamp. 1988. Auto-association by multilayer perceptrons and singular value decomposition. Biol. Cybern. 59, 4-5 (September 1988), 291-294. &lt;a href=&quot;#fnref:8&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:9&quot;&gt;
      &lt;p&gt;P. Baldi and K. Hornik. 1989. Neural networks and principal component analysis: learning from examples without local minima. Neural Netw. 2, 1 (January 1989), 53-58. &lt;a href=&quot;#fnref:9&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:10&quot;&gt;
      &lt;p&gt;Hinton, G. E. &amp;amp; Zemel, R. S. (1993), Autoencoders, Minimum Description Length and Helmholtz Free Energy., in Jack D. Cowan; Gerald Tesauro &amp;amp; Joshua Alspector, ed., ‘NIPS’ , Morgan Kaufmann, , pp. 3-10 . &lt;a href=&quot;#fnref:10&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:11&quot;&gt;
      &lt;p&gt;Ackley, D. H., Hinton, G. E., &amp;amp; Sejnowski, T. J. (1985). A learning algorithm for boltzmann machines*. Cognitive science, 9(1), 147-169. &lt;a href=&quot;#fnref:11&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:ebm&quot;&gt;
      &lt;p&gt;LeCun, Y., Chopra, S., Hadsell, R., Ranzato, M., &amp;amp; Huang, F. (2006). A tutorial on energy-based learning. Predicting structured data, 1, 0. &lt;a href=&quot;#fnref:ebm&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:12&quot;&gt;
      &lt;p&gt;Neal, R. M. (1992). Connectionist learning of belief networks. Artificial intelligence, 56(1), 71-113. &lt;a href=&quot;#fnref:12&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:13&quot;&gt;
      &lt;p&gt;Hinton, G. E., Dayan, P., Frey, B. J., &amp;amp; Neal, R. M. (1995). The” wake-sleep” algorithm for unsupervised neural networks. Science, 268(5214), 1158-1161. &lt;a href=&quot;#fnref:13&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:14&quot;&gt;
      &lt;p&gt;Dayan, P., Hinton, G. E., Neal, R. M., &amp;amp; Zemel, R. S. (1995). The helmholtz machine. Neural computation, 7(5), 889-904. &lt;a href=&quot;#fnref:14&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;

    &lt;p&gt;&lt;a href=&quot;/writing/a-brief-history-of-neural-nets-and-deep-learning-part-2/&quot;&gt;A 'Brief' History of Neural Nets and Deep Learning, Part 2&lt;/a&gt; was originally published by Andrey Kurenkov at &lt;a href=&quot;&quot;&gt;Andrey Kurenkov's Web World&lt;/a&gt; on December 24, 2015.&lt;/p&gt;
  </content>
</entry>


  

<entry>
  <title type="html"><![CDATA[A 'Brief' History of Neural Nets and Deep Learning, Part 1]]></title>
  <link rel="alternate" type="text/html" href="/writing/a-brief-history-of-neural-nets-and-deep-learning/" />
  <id>/writing/a-brief-history-of-neural-nets-and-deep-learning</id>
  <published>2015-12-24T15:19:34-08:00</published>
  <updated>2015-12-24T15:19:34-08:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email>andreyvkurenkov@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;This is the first part of ‘A Brief History of Neural Nets and Deep Learning’. Part 2 is &lt;a href=&quot;http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning-part-2&quot;&gt;here&lt;/a&gt;, and parts 3 and 4 are &lt;a href=&quot;http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning-part-3&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning-part-4&quot;&gt;here&lt;/a&gt;. In this part, we shall cover the birth of neural nets with the Perceptron in 1958, the AI Winter of the 70s, and neural nets’ return to popularity with backpropagation in 1986.&lt;/p&gt;

&lt;h1 id=&quot;prologue-the-deep-learning-tsunami&quot;&gt;Prologue: The Deep Learning Tsunami&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Deep Learning waves have lapped at the shores of computational linguistics for several years now, but 2015 seems like the year when the full force of the tsunami hit the major Natural Language Processing (NLP) conferences.” -&lt;a href=&quot;http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00239&quot;&gt;Dr. Christopher D. Manning, Dec 2015&lt;/a&gt; &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This may sound hyperbolic - to say the established methods of an entire field of research are quickly being superseded by a new discovery, as if hit by a research ‘tsunami’. But, this catastrophic language is appropriate for describing the meteoric rise of Deep Learning over the last several years - a rise characterized by drastic improvements over reigning approaches towards the hardest problems in AI, massive investments from industry giants such as Google, and exponential growth in research publications (and Machine Learning graduate students). Having taken several classes on Machine Learning, and even used it in undergraduate research, I could not help but wonder if this new ‘Deep Learning’ was anything fancy or just a scaled up version of the ‘artificial neural nets’ that were already developed by the late 80s. And let me tell you, the answer is quite a story - the story of not just neural nets, not just of a sequence of research breakthroughs that make Deep Learning somewhat more interesting than ‘big neural nets’  (that I will attempt to explain in a way that just about anyone can understand), but most of all of how several unyielding researchers made it through dark decades of banishment to finally redeem neural nets and achieve the dream of Deep Learning.&lt;/p&gt;

&lt;div&gt;&lt;button class=&quot;btn&quot; data-toggle=&quot;collapse&quot; data-target=&quot;#sources&quot;&gt;
Disclaimer: not an expert, more in depth sources, corrections &amp;raquo;
&lt;/button&gt;&lt;/div&gt;
&lt;blockquote class=&quot;aside&quot;&gt;&lt;p id=&quot;sources&quot; class=&quot;collapse&quot; style=&quot;height: 0px;&quot;&gt;
I am in no capacity an expert on this topic. In depth technical overviews with long lists of references written by those who actually made the field what it is include Yoshua Bengio's &lt;a href=&quot;http://www.iro.umontreal.ca/~lisa/pointeurs/TR1312.pdf&quot;&gt;&quot;Learning Deep Architectures for AI&quot;&lt;/a&gt;, Jürgen Schmidhuber's &lt;a href=&quot;http://arxiv.org/pdf/1404.7828v4.pdf&quot;&gt;&quot;Deep Learning in Neural Networks: An Overview&quot;&lt;/a&gt; and LeCun et al.s' &lt;a href=&quot;http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf&quot;&gt;&quot;Deep learning&quot;&lt;/a&gt;. In particular, this is mostly a history of research in the US/Canada AI community, and even there will not mention many researchers; a particularly in depth history of the field that covers these omissions is Jürgen Schmidhuber's &lt;a href=&quot;http://people.idsia.ch/~juergen/deep-learning-overview.html&quot;&gt;&quot;Deep Learning in Neural Networks: An Overview&quot;&lt;/a&gt;. I am also most certainly not a professional writer, and will cop to there being shorter and much less technical overviews written by professional writers such as Paul Voosen's &lt;a href=&quot;http://chronicle.com/article/The-Believers/190147&quot;&gt;&quot;The Believers&quot;&lt;/a&gt;, John Markoff's &lt;a href=&quot;http://www.nytimes.com/2012/11/24/science/scientists-see-advances-in-deep-learning-a-part-of-artificial-intelligence.html&quot;&gt;&quot;Scientists See Promise in Deep-Learning Programs&quot;&lt;/a&gt; and Gary Marcus's &lt;a href=&quot;http://www.newyorker.com/news/news-desk/is-deep-learning-a-revolution-in-artificial-intelligence&quot;&gt;&quot;Is “Deep Learning” a Revolution in Artificial Intelligence?&quot;&lt;/a&gt;. I also will stay away from getting too technical here, but there is a plethora of tutorials on the internet on all the major topics covered in brief by me.
&lt;br /&gt;
Any corrections would be greatly appreciated, though I will note some ommisions are intentional since I want to try and keep this 'brief' and a good mix of simple technical explanations and storytelling.
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;the-centuries-old-machine-learning-algorithm&quot;&gt;The Centuries Old Machine Learning Algorithm&lt;/h1&gt;
&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/3/3a/Linear_regression.svg&quot; alt=&quot;Linear Regression&quot; /&gt;     
    &lt;figcaption&gt;Linear regression &lt;a href=&quot;ttps://upload.wikimedia.org/wikipedia/commons/3/3a/Linear_regression.svg&quot;&gt;(Source)&lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Let’s start with a brief primer on what Machine Learning is. Take some points on a 2D graph, and draw a line that fits them as well as possible. What you have just done is generalized from a few example of pairs of input values (x) and output values (y) to a general function that can map any input value to an output value. This is known as linear regression, and it is a wonderful little &lt;a href=&quot;https://en.wikipedia.org/wiki/Linear_regression#cite_note-4&quot;&gt;200 year old&lt;/a&gt; technique for extrapolating a general function from some set of input-output pairs. And here’s why having such a technique is wonderful: there is an incalculable number of functions that are hard to develop equations for directly, but are easy to collect examples of input and output pairs for in the real world - for instance, the function mapping an input of recorded audio of a spoken word to an output of what that spoken word is.&lt;/p&gt;

&lt;p&gt;Linear regression is a bit too wimpy a technique to solve the problem of speech recognition, but what it does is essentially what &lt;strong&gt;supervised Machine Learning&lt;/strong&gt; is all about: ‘learning’ a function given a &lt;strong&gt;training set&lt;/strong&gt; of &lt;strong&gt;examples&lt;/strong&gt;, where each example is a pair of an input and output from the function (we shall touch on the unsupervised flavor in a little while). In particular, machine learning methods should derive a function that can generalize well to inputs not in the training set, since then we can actually apply it to inputs for which we do not have an output. For instance, Google’s current speech recognition technology is powered by Machine Learning with a massive training set, but not nearly as big a training set as all the possible speech inputs you might task your phone with understanding.&lt;/p&gt;

&lt;p&gt;This generalization principle is so important that there is almost always a &lt;strong&gt;test set&lt;/strong&gt; of data (more examples of inputs and outputs) that is not part of the training set. The separate set can be used to evaluate the effectiveness of the machine learning technique by seeing how many of the examples the method correctly computes outputs for given the inputs. The nemesis of generalization is &lt;strong&gt;overfitting&lt;/strong&gt; - learning a function that works really well for the training set but badly on the test set. Since machine learning researchers needed means to compare the effectiveness of their methods, over time there appeared standard &lt;strong&gt;datasets&lt;/strong&gt; of training and testing sets that could be used to evaluate machine learning algorithms.&lt;/p&gt;

&lt;p&gt;Okay okay, enough definitions. Point is - our line drawing exercise is a very simple example of supervised machine learning: the points are the training set (X is input and Y is output), the line is the approximated function, and we can use the line to find Y values for X values that don’t match any of the points we started with. Don’t worry, the rest of this history will not be nearly so dry as all this. Here we go.&lt;/p&gt;

&lt;h1 id=&quot;the-folly-of-false-promises&quot;&gt;The Folly of False Promises&lt;/h1&gt;

&lt;p&gt;Why have all this prologue with linear regression, since the topic here is ostensibly neural nets? Well, in fact linear regression bears some resemblance to the first idea conceived specifically as a method to make machines learn: &lt;a href=&quot;http://psycnet.apa.org/index.cfm?fa=buy.optionToBuy&amp;amp;id=1959-09865-001
morehttps://www.pearsonhighered.com/assets/hip/us/hip_us_pearsonhighered/samplechapter/0131471392.pdf&quot;&gt;Frank Rosenblatt’s &lt;strong&gt;Perceptron&lt;/strong&gt;&lt;/a&gt;&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34998?token=eP9x7J-SbQvC30KjZ23yt38XOWoU6_d0JVo72rZF-EHtWcLW-zNPyZU2ZYJu4VPm7Fxs20Gd7mPoRylRtNFigXs&quot; alt=&quot;Perceptron&quot; /&gt;     
   &lt;figcaption&gt;A diagram showing how the Perceptron works. &lt;a href=&quot;http://cse-wiki.unl.edu/wiki/images/0/0f/Perceptron.jpg&quot;&gt;(Source)&lt;/a&gt;&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;A psychologist, Rosenblatt conceived of the Percetron as a simplified mathematical model of how the neurons in our brains operate: it takes a set of binary inputs (nearby neurons), multiplies each input by a continuous valued weight (the synapse strength to each nearby neuron), and thresholds the sum of these weighted inputs to output a 1 if the sum is big enough and otherwise a 0 (in the same way neurons either fire or do not). Most of the inputs to a Perceptron are either some data or the output of another Perceptron, but an extra detail is that Perceptrons also have one special ‘bias’ input, which just has a value of 1 and basically ensures the more functions are computable with the same input by being able to offset the summed value. This model of the neuron built on the work of Warren McCulloch and Walter Pitts &lt;a href=&quot;http://www.minicomplexity.org/pubs/1943-mcculloch-pitts-bmb.pdf&quot;&gt;Mcculoch-Pitts&lt;/a&gt;&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;, who showed that a neuron model that sums binary inputs and outputs a 1 if the sum exceeds a certain threshold value, and otherwise outputs a 0, can model the basic OR/AND/NOT functions. This, in the early days of AI, was a big deal - the predominant thought at the time was that making computers able to do formal logical reasoning would essentially solve AI.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34832?token=vQiHNdPnUSPiPJcJcgobMGedDJRvgguccVapCN76gZnxqVQIKczfq4BqUQ06bWdVXnabb3tScv_04nigKqMZjS4&quot; alt=&quot;Perceptron 2&quot; /&gt; 
    &lt;figcaption&gt;Another diagram, showing the biological inspiration. The &lt;b&gt;activation function&lt;/b&gt; is what people nowdays call the non-linear function applied to the weighted input sum to produce the output of the artificla neuron - in the case of Rosenblatt's Perceptron, the function was just output a thresholding operation.  &lt;a href=&quot;http://cs231n.github.io/neural-networks-1/&quot;&gt;(Source)&lt;/a&gt; &lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;However, the Mcculoch-Pitts model lacked a mechanism for learning, which was crucial for it to be usable for AI. This is where the Perceptron excelled - Rosenblatt came up with a way to make such artificial neurons learn, inspired by the &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1002/cne.900930310/abstract&quot;&gt;foundational work&lt;/a&gt;&lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt; of Donald Hebb. Hebb put forth the unexpected and hugely influential idea that knowledge and learning occurs in the brain primarily through the formation and change of synapses between neurons - concisely stated as Hebb’s Rule:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“When an axon of cell A is near enough to excite a cell B and repeatedly or persistently takes part in firing it, some growth process or metabolic change takes place in one or both cells such that A’s efficiency, as one of the cells firing B, is increased.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The Perceptron did not follow this idea exactly, but having weights on the inputs allowed for a very simple and intuitive learning scheme: given a &lt;strong&gt;training set&lt;/strong&gt; of input-output examples the Perceptron should ‘learn’ a function for, for each example increase the weights if the Perceptron output for that example’s input is too low compared to the example, and decrease the weights if the output is too high. Stated ever so slightly more formally, the algorithm is as follows:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Start off with a Perceptron having random weights and a training set&lt;/li&gt;
  &lt;li&gt;For the inputs of an example in the training set, compute the Perceptron’s output&lt;/li&gt;
  &lt;li&gt;If the output of the Perceptron does not match the output that is known to be correct for the example:
    &lt;ul&gt;
      &lt;li&gt;If the output should have been 0 but was 1, decrease the weights that had an input of 1.&lt;/li&gt;
      &lt;li&gt;If the output should have been 1 but was 0, increase the weights that had an input of 1.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Go to the next example in the training set and repeat steps 2-4 until the Perceptron makes no more mistakes&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This procedure is simple, and produces a simple result: an input linear function (the weighted sum), just as with linear regression, ‘squashed’ by a non-linear &lt;strong&gt;activation function&lt;/strong&gt; (the thresholding of the sum). It’s fine to threshold the sum when the function can only have a finite set of outputs values (as with logical functions, in which case there are only two - True/1 and False/0) and so the problem is not so much to generate a continuous-numbered output for any set of inputs - regression - as to categorize the inputs with a correct label - &lt;strong&gt;classification&lt;/strong&gt;.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://upload.wikimedia.org/wikipedia/en/5/52/Mark_I_perceptron.jpeg&quot; alt=&quot;.&quot; /&gt; 
    &lt;figcaption&gt;'Mark I Perceptron at the Cornell Aeronautical Laboratory', hardware implementation of the first Perceptron (Source: Wikipedia / Cornell Library)&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;Rosenblatt implemented the idea of the Perceptron in custom hardware (this being before fancy programming languages were in common use), and showed it could be used to learn to classify simple shapes correctly with 20x20 pixel-like inputs. And so, machine learning was born - a computer was built that could approximate a function given known input and output pairs from it. In this case it learned a little toy function, but it was not difficult to envision useful applications such as converting the mess that is human handwriting into machine-readable text.&lt;/p&gt;

&lt;p&gt;Crucially, this approach could also work for functions with multiple output values, or classifications tasks with many categories. This is impossible for one Perceptron, since it has only one output, but functions with multiple outputs can be learned by having multiple Perceptrons in a &lt;strong&gt;layer&lt;/strong&gt;, such that all these Perceptrons receive the same input and each one is responsible for one output of the function. Indeed, neural nets (or, formally, ‘Artificial Neural Networks’ - ANNs) are nothing more than layers of Perceptrons - or neurons, as they are usually called today - and at this stage there was just one layer - the &lt;strong&gt;output layer&lt;/strong&gt;. So, a prototypical example of neural net use is to classify an image of a handwritten digit. The inputs are the pixels of the image , and there are 10 output neurons with each one corresponding to one of the 10 possible digit values. In this case only one of the 10 neurons output 1, the highest weighted sum is taken to be the correct output, and the rest output 0.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34466?token=YFsmpDuQfD3DDylinRD8F4sLOgjCFm4Aow1gIWoCY5KED3bnQKs17RaTja95OIQQWdr25dqS2fxq_6mDwwdcs9Y&quot; alt=&quot;Neural net with an output layer.&quot; /&gt; 
    &lt;figcaption&gt;A neural net with multiple outputs.&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;It is also possible to conceive of neural nets with artificial neurons different from the Perceptron. For instance, the thresholding activation function is not strictly necessary; Bernard Widrow and Tedd Hoff soon explored the option of just outputting the weight input in 1960 with &lt;a href=&quot;http://www-isl.stanford.edu/~widrow/papers/t1960anadaptive.pdf&quot;&gt;“An adaptive “ADALINE” neuron using chemical “memistors”&lt;/a&gt;&lt;sup id=&quot;fnref:5&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;, and showed how these ‘Adaptive Linear Neurons’ could be incorporated into electrical circuits with ‘memistors’ - resistors with memory. They also showed that not having the threshold activation function is mathematically nice, because the neuron’s learning mechanism can be formally based on minimizing the error through good ol’ calculus. See, with the neuron’s function not being made weird by this sharp thresholding jump from 0 to 1, a measure of how much the error changes when each weight is changed (the derivative) can be used to drive the error down and find the optimal weight values. As we shall see, finding the right weights using the derivatives of the training error with respect to each weight - &lt;strong&gt;stochastic gradient descent&lt;/strong&gt; - is exactly how neural nets are typically trained.&lt;/p&gt;

&lt;div&gt;&lt;button class=&quot;btn&quot; data-toggle=&quot;collapse&quot; data-target=&quot;#maths&quot;&gt;
Aside: a bit more on the math &amp;raquo;
&lt;/button&gt;&lt;/div&gt;
&lt;blockquote class=&quot;aside&quot;&gt;&lt;p id=&quot;maths&quot; class=&quot;collapse&quot; style=&quot;height: 0px;&quot;&gt;
In short a function is differentiable if it is a nice smooth line - Rosenblatt's Perceptron computed the output in such a way that the output abruptly jumped from 0 to 1 if the input exceeded some number, whereas Adaline simply output the input which was a nice non-jumpy line. For a much more in depth explanation of all this math you can read &lt;a href=&quot;http://sebastianraschka.com/Articles/2015_singlelayer_neurons.html&quot;&gt;this tutorial&lt;/a&gt;, or any resource from Google - let us focus on the fun high-level concepts and story here.
&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If we think about ADALINE a bit more we will come up with a further insight: finding a set of weights for a number of inputs is really just a form of linear regression. And again, as with linear regression, this would not be enough to solve the complex AI problems of Speech Recognition or Computer Vision. What McCullough and Pitts and Rosenblatt were really excited about is the broad idea of Connectionism: that networks of such simple computational units can be vastly more powerful and solve the hard problems of AI. And, Rosenblatt said as much, as in this frankly ridiculous New York Times quote &lt;a href=&quot;http://query.nytimes.com/gst/abstract.html?res=9D01E4D8173DE53BBC4053DFB1668383649EDE&quot;&gt;from the time&lt;/a&gt;&lt;sup id=&quot;fnref:6&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“The Navy revealed the embryo of an electronic computer today hat it expects will be able to walk, talk, see, write, reproduce itself an be conscious of its existence … Dr. Frank Rosenblatt, a research psychologist at the Cornell Aeronautical Laboratory, Buffalo, said Perceptrons might be fired to the planets as mechanical space explorers”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This sort of talk no doubt irked other researchers in AI, many of whom were focusing on approaches based on manipulation of symbols with concrete rules that followed from the mathematical laws of logic. Marvin Minsky, founder of the MIT AI Lab, and Seymour Paper were some of the researchers who were skeptical of the hype and in 1969 published their skepticism in the form of rigorous analysis on of the limitations of Perceptrons in a seminal book aptly named &lt;a href=&quot;https://mitpress.mit.edu/books/perceptrons&quot;&gt;Perceptrons&lt;/a&gt;&lt;sup id=&quot;fnref:7&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;. The most widely discussed element of their analysis is the elucidation of the limits of a Perceptron - they could not, for instance, learn the simple boolean function XOR because it is not &lt;strong&gt;linearly separable&lt;/strong&gt;. Though the history here is vague, this publication is widely believed to have helped usher in the first of the &lt;strong&gt;AI Winters&lt;/strong&gt; - a period following a massive wave of hype for AI characterized by disillusionment that causes a freeze to funding and publications.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/35002?token=NfMQ9LV1TFNi0v0QmbwfNTxYgbYjG7kjHqR9DaATySwhqdIE8Xc3Lfrcwa6JA2CAwSvQFYQL7fj_fwFT6o_Zelw&quot; /&gt; 
    &lt;figcaption&gt;Visualization of the limitations of Perceptrons. Finding a linear function on the inputs X,Y to correctly ouput + or - is equivalent to drawing a line on this 2D graph separating all + cases from - cases; clearly, for the third case this is impossible. &lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;h1 id=&quot;the-thaw-of-the-ai-winter&quot;&gt;The Thaw of the AI Winter&lt;/h1&gt;

&lt;p&gt;So, things were not good for neural nets. But why? The idea, after all, was to combine a bunch of simple mathematical neurons to do complicated things, not to use a single one. In other terms, instead of just having one &lt;strong&gt;output layer&lt;/strong&gt;, to send an input to arbitrarily many neurons which are called a &lt;strong&gt;hidden layer&lt;/strong&gt; because their output acts as input to another hidden layer or the output layer of neurons. Only the output layer’s output is ‘seen’ - it is the answer of the neural net - but all the intermediate computations done by the hidden layer(s) can tackle vastly more complicated problems than just a single layer.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34833?token=w5fXrfJQKt_CECpofd0YJUaAvNZEe2Qc0hgwlCj-x-48i8Bs5CtQDe52yns49AzIgK3NnSCwJvcmqQ1kp5mVwB0&quot; alt=&quot;Hidden layers&quot; /&gt; 
    &lt;figcaption&gt;Neural net with two hidden layers &amp;lt;a href=http://cs231n.github.io/neural-networks-1/&amp;gt;(Excellent Source)&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;The reason hidden layers are good, in basic terms, is that the hidden layers can find &lt;strong&gt;features&lt;/strong&gt; within the data and allow following layers to operate on those features rather than the noisy and large raw data. For example, in the very common neural net task of finding human faces in an image, the first hidden layer could take in the raw pixel values and find lines, circles, ovals, and so on within the image. The next layer would receive the position of these lines, circles, ovals, and so on within the image and use those to the location of human faces - much easier! And people, basically, understood this. In fact, until recently machine learning techniques were commonly not applied directly to raw data inputs such as images or audio. Instead, machine learning was done on data after it had passed through &lt;strong&gt;feature extraction&lt;/strong&gt; - that is, to make learning easier machine learning was done on preprocessed data from which more useful features such as angles or shapes had been already extracted.&lt;/p&gt;

&lt;div&gt;&lt;button class=&quot;btn&quot; data-toggle=&quot;collapse&quot; data-target=&quot;#nonlinearwhy&quot;&gt;
Aside: why have non-linear activation functions &amp;raquo;
&lt;/button&gt;&lt;/div&gt;
&lt;blockquote class=&quot;aside&quot;&gt;&lt;p id=&quot;nonlinearwhy&quot; class=&quot;collapse&quot; style=&quot;height: 0px;&quot;&gt;
Earlier, we saw that the weighted sum computed by the Perceptron is usually put through a non-linear activation function. Now we can get around to fully answering an implicit question: why bother? Two reasons: 
1. Without the activation function, the learned functions could only be linear, and most 'interesting' functions are not linear (for instance, logic functions that only output 1 or 0 or classification functions that output the category).
2. Several layers of linear Perceptrons can always be collapsed into only one layer due to the linearity of all the computations - the same cannot be done with non-linear activation functions. So, in intuitive speak a network can massage the data better with activation functions than without.
&lt;/p&gt;&lt;/blockquote&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/35001?token=qG2LYkSR81r2DESqTceIWvJdDBoXVK-PRShf3s-57FZbvr81A9xC9-4x46XNiD33WgEy9Kh3A95i09dYQnHdDrE&quot; alt=&quot;Feature extraction&quot; /&gt; 
    &lt;figcaption&gt;Visualization of traditional handcrafted feature extraction. &lt;a href=&quot;ttp://lear.inrialpes.fr/people/vandeweijer/color_descriptors.html&quot;&gt;(Source)&lt;/a&gt;&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;So, it is important to note Minsky and Paper’s analysis of Perceptrons did not merely show the impossibility of computing XOR with a single Perceptron, but specifically argued that it had to be done with multiple layers of Perceptrons - what we now call multilayer neural nets - and that Rosenblatt’s learning algorithm did not work for multiple layers. And that was the real problem: the simple learning rule previously outlined for the Perceptron does not work for multiple layers. To see why, let’s reiterate how a single layer of Perceptrons would learn compute some function:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;A number of Perceptrons equal to the number of the function’s outputs would be started off with small initial weights (which are just multiples for the function’s inputs)&lt;/li&gt;
  &lt;li&gt;For the inputs of an example in the training set, compute the Perceptrons’ output&lt;/li&gt;
  &lt;li&gt;For each Perceptron, if the output does not match the example’s output, adjust the weights accordingly&lt;/li&gt;
  &lt;li&gt;Go to the next example in the training set and repeat steps 2-4 until the Perceptrons no longer make mistakes&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The reason why this does not work for multiple layers should be intuitively clear: the example only specifies the correct output for the final output layer, so how in the world should we know how to adjust the weights of Perceptrons in layers before that? The answer, despite taking some time to derive, proved to be once again based on age-old Calculus: the chain rule. The key realization was that if the neural net neurons were not quite Perceptrons, but were made to compute the output with an activation function that was still non-linear but also differentiable, as with Adaline, not only could the derivative be used to adjust the weight to minimize error, but the chain rule could also be used to compute the derivative for all the neurons in a prior layer and thus the way to adjust their weights would also be known. Or, more simply: we can use calculus to assign some of the blame for any training set mistakes in the output layer to each neuron in the previous hidden layer, and then we can further split up blame if there is another hidden layer, and so on - we &lt;strong&gt;backpropagate&lt;/strong&gt; the error. And so, we can get can find how much the error changes if we change any weight in the neural net, including those in the hidden layers, and use an optimization technique (for a long time, typically stochastic gradient descent) to find the optimal weights to minimize the error.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimagesmall&quot; src=&quot;https://draftin.com:443/images/34948?token=LF6pwbG4bKjYLDLj4GDemUWKiFy8SQC5tluQgSGnxKxiaoFUlJ9FaYoC_Syh6t4fvzOT8rwz1fnBQ0xInJ_tuO0&quot; alt=&quot;Backprop&quot; /&gt; 
    &lt;figcaption&gt;The basic idea of backpropagation. &lt;a href=&quot;http://devblogs.nvidia.com/parallelforall/inference-next-step-gpu-accelerated-deep-learning/&quot;&gt;(Source)&lt;/a&gt;&lt;/figcaption&gt;    
&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;Backpropagation&lt;/strong&gt; was derived by multiple researchers in the early 60’s and implemented to run on computers much as it is today as early as 1970 by Seppo Linnainmaa&lt;sup id=&quot;fnref:8&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt;, but Paul Werbos was first in the US to propose that it could be used for neural nets after analyzing it in depth in his 1974 PhD Thesis&lt;sup id=&quot;fnref:9&quot;&gt;&lt;a href=&quot;#fn:9&quot; class=&quot;footnote&quot;&gt;9&lt;/a&gt;&lt;/sup&gt;. Interestingly, as with Perceptrons he was loosely inspired by work modeling the human mind, in this case the psychological theories of Freud as &lt;a href=&quot;http://www.die.uchile.cl/ieee-cis/evic2005/files/AD2004Werbosv2.pdf&quot;&gt;he himself recounts&lt;/a&gt;&lt;sup id=&quot;fnref:10&quot;&gt;&lt;a href=&quot;#fn:10&quot; class=&quot;footnote&quot;&gt;10&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“In 1968, I proposed that we somehow imitate Freud’s concept of a backwards flow of credit assignment, flowing back from neuron to neuron … I explained the reverse calculations using a combination of intuition and examples and the ordinary chainrule, though it was also exactly a translation into mathematics of things that Freud had previously proposed in his theory of psychodynamics!”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Despite solving the question of how multilayer neural nets could be trained, and seeing it as such while working on his PhD thesis, Werbos did not publish on the application of backprop to neural nets until 1982 due to the chilling effects of the AI Winter. In fact, Werbos thought the approach would make sense for solving the problems pointed out in &lt;em&gt;Perceptrons&lt;/em&gt;, but the community at large lost any faith in tackling those problem:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Minsky’s book was best known for arguing that (1) we need to use MLPs [multilayer perceptrions, another term for multilayer neural nets] even to represent simple nonlinear functions such as the XOR mapping; and (2) no one on earth had found a viable way to &lt;em&gt;train&lt;/em&gt; MLPs good enough to learn such simple functions. Minsky’s book convinced most of the world that neural networks were a discredited dead-end – the worst kind of heresy. Widrow has stressed that this pessimism, which squashed the early “perceptron” school of AI, should not really be blamed on Minsky. Minsky was merely summarizing the experience of hundreds of sincere researchers who had tried to find good ways to train MLPs, to no avail. There had been islands of hope, such as the algorithm which Rosenblatt called “backpropagation” (not at all the same as what we now call backpropagation!), and Amari’s brief suggestion that we might consider least squares [what is the basis of simple linear regression] as a way to train neural networks (without discussion of how to get the derivatives, and with a warning that he did not expect much from the approach). But the pessimism at that time became terminal. 
In the early 1970s, I did in fact visit Minsky at MIT. I proposed that we do a joint paper showing that MLPs can in fact overcome the earlier problems … But Minsky was not interested(14). In fact, no one at MIT or Harvard or any place I could find was interested at the time.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I certainly cannot say for certain, but it seems that it was because of this lack of academic interest that it was not until more than a decade later, in 1986, that this approach was popularized in &lt;a href=&quot;http://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf&quot;&gt;“Learning representations by back-propagating errors”&lt;/a&gt; by David Rumelhart, Geoffrey Hinton, and Ronald Williams &lt;sup id=&quot;fnref:11&quot;&gt;&lt;a href=&quot;#fn:11&quot; class=&quot;footnote&quot;&gt;11&lt;/a&gt;&lt;/sup&gt;. Despite the numerous discoveries of the method (the paper even explicitly mentions David Parker and Yann LeCun as two people who discovered it beforehand) the 1986 publication stands out for how concisely and clearly the idea is stated. In fact, as a student of Machine Learning it is easy to see that the description in their paper is essentially identical to the way the concept is still explained in textbooks and AI classes. A &lt;a href=&quot;http://www-isl.stanford.edu/~widrow/papers/j199030years.pdf&quot;&gt;retrospective in IEEE&lt;/a&gt;&lt;sup id=&quot;fnref:12&quot;&gt;&lt;a href=&quot;#fn:12&quot; class=&quot;footnote&quot;&gt;12&lt;/a&gt;&lt;/sup&gt; echoes this notion:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Unfortunately, Werbos’s work remained almost unknown in the scientific community. In 1982, Parker rediscovered the technique [39] and in 1985, published a report on it at M.I.T. [40]. Not long after Parker published his findings, Rumelhart, Hinton, and Williams [41], [42] also rediscovered the techniques and, largely as a result of the clear framework within which they presented their ideas, they finally succeeded in making it widely known.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But the three authors went much further than just present this new learning algorithm. In the same year they published the much more in-depth &lt;a href=&quot;ttp://psych.stanford.edu/~jlm/papers/PDP/Volume%201/Chap8_PDP86.pdf&quot;&gt;“Learning internal representations by error propagation”&lt;/a&gt;&lt;sup id=&quot;fnref:13&quot;&gt;&lt;a href=&quot;#fn:13&quot; class=&quot;footnote&quot;&gt;13&lt;/a&gt;&lt;/sup&gt;, which specifically addressed the problems discussed by Minsky in &lt;em&gt;Perceptrons&lt;/em&gt;. Though the idea was conceived by people in the past, it was precisely this formulation in 1986 that made it widely understood how multilayer neural nets could be trained to tackle complex learning problems. And so, neural nets were back! In &lt;a href=&quot;http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning-part-2&quot;&gt;part 2&lt;/a&gt;, we shall see how just a few years later backpropagation and some other tricks discussed in “Learning internal representations by error propagation” were applied to a very significant problem: enabling computers to read human handwriting.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;Christopher D. Manning. (2015). Computational Linguistics and Deep Learning Computational Linguistics, 41(4), 701–707. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;F. Rosenblatt. The perceptron, a perceiving and recognizing automaton Project Para. Cornell Aeronautical Laboratory, 1957. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;W. S. McCulloch and W. Pitts. A logical calculus of the ideas immanent in nervous activity. The bulletin of mathematical biophysics, 5(4):115–133, 1943. &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot;&gt;
      &lt;p&gt;The organization of behavior: A neuropsychological theory. D. O. Hebb. John Wiley And Sons, Inc., New York, 1949 &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot;&gt;
      &lt;p&gt;B. Widrow et al. Adaptive ”Adaline” neuron using chemical ”memistors”. Number Technical Report 1553-2. Stanford Electron. Labs., Stanford, CA, October 1960. &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot;&gt;
      &lt;p&gt;“New Navy Device Learns By Doing”, New York Times, July 8, 1958. &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:7&quot;&gt;
      &lt;p&gt;Perceptrons. An Introduction to Computational Geometry. MARVIN MINSKY and SEYMOUR PAPERT. M.I.T. Press, Cambridge, Mass., 1969. &lt;a href=&quot;#fnref:7&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:8&quot;&gt;
      &lt;p&gt;Linnainmaa,  S. (1970).   The representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors. Master’s thesis, Univ. Helsinki. &lt;a href=&quot;#fnref:8&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:9&quot;&gt;
      &lt;p&gt;P. Werbos. Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences. PhD thesis, Harvard University, Cambridge, MA, 1974. &lt;a href=&quot;#fnref:9&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:10&quot;&gt;
      &lt;p&gt;Werbos, P.J. (2006). Backwards differentiation in AD and neural nets: Past links and new opportunities. In &lt;em&gt;Automatic Differentiation: Applications, Theory, and Implementations,&lt;/em&gt; pages 15-34. Springer. &lt;a href=&quot;#fnref:10&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:11&quot;&gt;
      &lt;p&gt;Rumelhart, D. E., Hinton, G. E., and Williams, R. J. (1986). Learning representations by back-propagating errors. Nature, 323, 533–536. &lt;a href=&quot;#fnref:11&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:12&quot;&gt;
      &lt;p&gt;Widrow, B., &amp;amp; Lehr, M. (1990). 30 years of adaptive neural networks: perceptron, madaline, and backpropagation. Proceedings of the IEEE, 78(9), 1415-1442. &lt;a href=&quot;#fnref:12&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:13&quot;&gt;
      &lt;p&gt;D. E. Rumelhart, G. E. Hinton, and R. J. Williams. 1986. Learning internal representations by error propagation. In Parallel distributed processing: explorations in the microstructure of cognition, vol. 1, David E. Rumelhart, James L. McClelland, and CORPORATE PDP Research Group (Eds.). MIT Press, Cambridge, MA, USA 318-362 &lt;a href=&quot;#fnref:13&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;

    &lt;p&gt;&lt;a href=&quot;/writing/a-brief-history-of-neural-nets-and-deep-learning/&quot;&gt;A 'Brief' History of Neural Nets and Deep Learning, Part 1&lt;/a&gt; was originally published by Andrey Kurenkov at &lt;a href=&quot;&quot;&gt;Andrey Kurenkov's Web World&lt;/a&gt; on December 24, 2015.&lt;/p&gt;
  </content>
</entry>


  

<entry>
  <title type="html"><![CDATA[Movie Recommendations For The Aspiring Eclectic Intellectual]]></title>
  <link rel="alternate" type="text/html" href="/writing/movie-recommendations-for-the-aspiring-eclectic-intellectual/" />
  <id>/writing/movie-recommendations-for-the-aspiring-eclectic-intellectual</id>
  <published>2015-10-22T16:19:34-07:00</published>
  <updated>2015-10-22T16:19:34-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email>andreyvkurenkov@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;&lt;em&gt;Revised from an email I wrote to a friend some years ago.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I should warn you this will get overlong. In my 10 or so years of watching Good movies I have come across many that have imprinted themselves onto my memory - hovering images and sounds that in a curious way make me happy to be alive. What I will now do is try to put all those most striking experiences into a flowing set of paragraphs and hope it all coheres. Perhaps these shall have the same effect for you, perhaps not - nonetheless let’s go!&lt;/p&gt;

&lt;p&gt;Any conversation with me about quality art movies has got to start with Andrei Tarkovsky, the poetically melancholic depths of any Russian’s soul incarnate. Very slow. Very poetic. Beautiful, disturbing, strange, spiritual. An acquired taste, and to some a complete nonsensical bore. &lt;strong&gt;Solaris&lt;/strong&gt;, a trippy 3-hour sci fi meditation on love and human consciousness, is a good starting point as the most accessible of his films. But I prefer his latter yet more poetically inclined works, such as &lt;strong&gt;The Sacrifice&lt;/strong&gt; - a tale of a man averting a nuclear war through a spiritual journey. Better yet is &lt;strong&gt;Stalker&lt;/strong&gt;, a 3-hour meditation on faith and the struggles inside our souls, and one of my favorite films. These movies have characters and stories, but describing them is almost beside the point - Tarkovsky’s work is visual poetry, and can only really be understood as such.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimage&quot; src=&quot;https://draftin.com:443/images/33122?token=7iV9cR_SsFlaUhBUMaA1ig5xTuE344ic99SQ6ElGChkr7zx7bvDTIKyVNc0qro4_AncYv-VBGF6f5oi-24n4yKQ&quot; alt=&quot;Stalker&quot; /&gt;     
&lt;/figure&gt;

&lt;p&gt;Next, Andrei Zvyagintsev, the recent successor to Tarkovsky’s crown - a sort of enlightened monarch who retains many of the customs but changes the underlying frame of mind. I will without reserve recommend three of his films: &lt;strong&gt;The Return&lt;/strong&gt;, &lt;strong&gt;Elena&lt;/strong&gt;, and &lt;strong&gt;Leviathan&lt;/strong&gt;. The first is his first movie, and is as difficult as it is rewarding to watch, the sort of movie that sinks into you, the sort of movie that you have not seen before, the sort of movie that when you realize its subtle story you experience a moment of wonder and appreciation for its elegance. Or, the sort of movie you call pretentious and stop watching midway through, much as with Tarkovsky. &lt;strong&gt;Elena&lt;/strong&gt; is both more and less complicated, a stylish slow neo-noir that many critics amazingly did not comprehend to be a devastating critique of modern Russian society as well as its history. Luckily critics had no such difficulty with &lt;strong&gt;Leviathan&lt;/strong&gt;, a transparent and &lt;a href=&quot;https://www.youtube.com/watch?v=2oo7H25kirk&quot;&gt;devastatingly beautiful&lt;/a&gt; critique of the corruption of modem Russian government and spirituality.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimage&quot; src=&quot;https://draftin.com:443/images/33164?token=g5dWtasZaV7cc9NwSJ2RyPSJU_79js7SZk9Lr1Wi-U9V5JK8reBPidTzQwwdiHU6XfY61OV3ggPcFRMmh9n0S_k&quot; alt=&quot;Leviathan&quot; /&gt;     
&lt;/figure&gt;

&lt;p&gt;Another quite good slow Russian movie is &lt;strong&gt;The Island&lt;/strong&gt;, but lets not get fixated on those. After Tarkovsky, my first GOTO masterclass director has got to be Ingmar Bergman, the director to top every director’s list of favorite directors (or at least Woody Allen’s… and Tarkovsky’s… and Kubrick’s…). His movies are about… many things, the subconscious depths and murks of our half-understood psyches most of all perhaps. Slow, quiet, amazingly talented at creating minimalist black and white scenes. &lt;strong&gt;The Seventh Seal&lt;/strong&gt;, a classic film about a medieval knight who plays chess with Death, is a good starting point. &lt;strong&gt;The Hour of the Wolf&lt;/strong&gt;, a sort of slowly creeping surreal film about guilt, derangement, and ultimately horror is at the other end of the spectrum of accessibility but is supremely good. And this more or less is the range of Bergman’s large body of work - dark explorations of human’s shattered souls and psyches rendered with unbelievably striking black and white imagery.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimage&quot; src=&quot;https://draftin.com:443/images/33166?token=Sq9TWbrnPcO9MCegAOWl9YM92HCe3FreRsHn26-Kfye7NFswz6vPCESgkjvH8sUZI5E-gytfNHgAKacWDDsseMc&quot; alt=&quot;The Seventh Seal&quot; /&gt;     
&lt;/figure&gt;

&lt;p&gt;But all this is so recent, pretty much 60s onwards, what kind of self-respecting movie person would I be if I dont have some directors from the olden days to show some love for? A bad one, clearly. That’s where Friz Lang, the mad genius from the days when sound has yet to ground cinema to dull reality, enters the picture. Have I seen any of his crazy epics besides Metropolis? No, but I can tell you &lt;strong&gt;Metropolis&lt;/strong&gt; is quite the crazy epic and perhaps the first sci-fi film (robots!). It’s hard to beat &lt;a href=&quot;http://www.ebertfest.com/thirteen/metropolis.html&quot;&gt;Ebert&lt;/a&gt; on this one: “Lang’s film is the summit of German Expressionism, with its combination of stylized sets, dramatic camera angles, bold shadows and frankly artificial theatrics.” But! Believe it or not, the much less grand &lt;strong&gt;M&lt;/strong&gt; - a film about the merciless retribution of a city against one who has sinned against it - may be the better film. Either way, you can’t go wrong with Lang.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimage&quot; src=&quot;https://draftin.com:443/images/33168?token=dIfqMhRME5us-_B68taUPNXJZyUeNyvRsztjl9AeLOOZx5-2WNIpKO_NMNL3X8jqJ9WuIhOgMHH4YD0g-U7h3lI&quot; alt=&quot;Metropolis&quot; /&gt;     
&lt;/figure&gt;

&lt;p&gt;And then ofcourse there’s the other director any person who has taken a film history class is overjoyed to bring up in normal conversation (because damn it, the world needs to know your knowledge), Sergei Eisenstein. But &lt;strong&gt;Battleship Potempkin&lt;/strong&gt; really is quite Radical, the prototypical example of the alternative form of cinema that bloomed in the strange days of soviet youth. If you want to get truly crazy, give Vertov’s &lt;strong&gt;Man with a Movie Camera&lt;/strong&gt; a watch - its not just capital R Radical, its all-caps RADICAL, but in the sort of intellectually and theoretically backed way that is actually quite striking and at least it makes sense maybe and does not seem like a student project by a guy who has seen too many artsy short films.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimage&quot; src=&quot;https://draftin.com:443/images/33169?token=6AMiChfeW2UxJZdhflEGkD8uf7FiqEOJM5NT6eBjpiAFNzYkYGNflo6yf3QD-EulMU-3S-s5QXa6rLK9sf4niOs&quot; alt=&quot;Man With A Movie Camera&quot; /&gt;     
&lt;/figure&gt;

&lt;p&gt;Across the pond Chaplin and Keaton are making far less weird masterpieces about this time (&lt;strong&gt;Modern Times&lt;/strong&gt;,&lt;strong&gt;The General&lt;/strong&gt;), but let’s stick with European strangeness, specifically that hailing from Spain. Here Luis Bunuel has managed to hang out with Dali a bit too long and accidentally produces &lt;strong&gt;Un Chien Andalou&lt;/strong&gt;, a surreal movie to surmount all surreal movies. This does seem like a student project by a guy who has seen too many artsy short films, but hey, it was the first, and its got some hella weird imagery. Bunuel then continues to make weird surreal cinema for decades, eventually getting around to laugh-out-loud family favorites such as &lt;strong&gt;The Discrete Charm of the Bourgeoisie&lt;/strong&gt;. Basically, if you are in the mood for surrealism, then this guy can hook you up.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimage&quot; src=&quot;https://draftin.com:443/images/33171?token=XcSoMc2F9qs09dcuN08Q6edZsHiKgcXTml2mJCDsFz5OCvNdgn3LC-kJjzYlOrd3uBeBgmBQN-I5Muy0hyC2UIA&quot; alt=&quot;Un Chien Andalou&quot; /&gt;     
&lt;/figure&gt;

&lt;p&gt;As fun as Bunuel’s surrealism can be, sometimes you just want to stick to the weight and tragedies of the real world. Well then, fine, just go be morose in the reality of post WWII Italy. Yes indeed, Italian Neorealism is where its at. &lt;strong&gt;Umberto D&lt;/strong&gt; and &lt;strong&gt;Bicycle Thieves&lt;/strong&gt; are the ones that I know should be seen, and I cant help but squeeze in a mention of &lt;strong&gt;Ikiru&lt;/strong&gt; by Kurosawa here as well (ah, but you must see Kurosawa! Too many of his movies deserve mention, at the very least the grand truth-mocking treatise that is &lt;strong&gt;Rashomon&lt;/strong&gt;). Still, there is only so much hard real-world reality you can take - luckily Fellini’s comes in later and slowly merges Italian Neorialism with very personal surrealism. Another person more of whose movies I should watch, but at least I can say &lt;strong&gt;8 1/2&lt;/strong&gt; is wholly enjoyable.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimage&quot; src=&quot;https://draftin.com:443/images/33185?token=PIkh2isQSk6RP6MWHBkPmRKOXn6J1WcBu-ZOq4QSSupEhJKjTN9MND9uHsWSHAJQ4t7t_TrNpLcd6pHGUsDWMME&quot; alt=&quot;Bycicle Thieves&quot; /&gt;     
&lt;/figure&gt;

&lt;p&gt;But lets say you want your surrealism with a dose of psychoanalysis and strangely menacing Americana. Two words: David Lynch. Let’s get this out of the way: Lynch’s hair is amazing. Did he start my appreciation for nonconformal hair? It’s possible. &lt;strong&gt;Eraserhead&lt;/strong&gt;, his incredibly weird movie about city and family oppression and fear in the mind of a young artist featuring a weird worm baby and an actual eraserhead, is also notable for crazy hair. But for real, &lt;strong&gt;Mulholland Drive&lt;/strong&gt; is another one of my favorite movies - a story that makes perfect sense in dream logic, the true realization of the promise of surrealism in cinema, a modern film so vivid with color and character your eyes feel drunk. Its predecessor, &lt;strong&gt;Lost Highway&lt;/strong&gt;, is also in that vein and also has Nick Cage, so it’s pretty much a must see. But if the vivid color and subversion of quintessentially American naivette is more exciting to you than Nick Cage, then &lt;strong&gt;Blue Velvet&lt;/strong&gt; is definitely where you will get the most thrills.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimage&quot; src=&quot;https://draftin.com:443/images/33186?token=o0Ce8LgS7xqEflwfFfe_LidlB6nTT8qIUwMiWhDi5374dGpr3mgCEpU5Wisn42j77S4b15rLrTYEmnB4D8BjH8E&quot; alt=&quot;Mulholland Drive&quot; /&gt;     
&lt;/figure&gt;

&lt;p&gt;Speaking of America, it turns out some fine directors lived there. Too many I am aware of, in fact. So let’s get some famous ones out of the way: Kubrick (&lt;strong&gt;Dr. Strangelove&lt;/strong&gt;), Francis Ford Copolla (&lt;strong&gt;Apocalypse Now&lt;/strong&gt;), Scorsese (&lt;strong&gt;Taxi Driver&lt;/strong&gt;), Allen (&lt;strong&gt;Annie Hall&lt;/strong&gt;), the Coens (&lt;strong&gt;Fargo&lt;/strong&gt;), Fincher (&lt;strong&gt;Fight Club&lt;/strong&gt;). Yeah, I know, you’re not impressed. Let’s move on to the hip ones. Darren Aronofsky, a fairly recent addition to the cannon of distinguished American filmmakers. His first movie was the low-budget &lt;strong&gt;Pi&lt;/strong&gt;, a film about a gifted mathematician increasingly going insane in search of the deep fundamental mathematical truth. That’s Aronofsky in a nutshell - people struggling and increasingly coming apart, as shown with unsubtle but very potent vision. In the magnificent &lt;strong&gt;Requirem for a Dream&lt;/strong&gt;, due to drugs, in the overtly ambitious &lt;strong&gt;The Fountain&lt;/strong&gt;, due to death, and so on. Aronofsky’s film pack a strong stylistic punch, and a good counter to that are the naturalistic films of &lt;strong&gt;Richard Linklater&lt;/strong&gt;. If nothing else, consider &lt;strong&gt;Boyhood&lt;/strong&gt; - a film that took 12 years to film yet managed to pack all that time in 2.5 hour movie most considered successful. Ah, this paragraph is getting long, but I’ll sneak in Paul Thomas Anderson and tell you that &lt;strong&gt;There Will Be Blood&lt;/strong&gt; is great and all and enjoying &lt;strong&gt;The Master&lt;/strong&gt; will get you intellectual street cred but if you have not seen &lt;strong&gt;Punch Drunk Love&lt;/strong&gt; you are missing out on a completely original amazing experience.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimage&quot; src=&quot;https://draftin.com:443/images/33187?token=vLdVZwnULxs7ZtMMgZiVWvGm4gnk2LeEpdivEYS-7XM9TbrfiONSBBNpuWna5hZIpRCLqYcwc9mLbzRy0KynS0M&quot; alt=&quot;Punch Drunk Love&quot; /&gt;     
&lt;/figure&gt;

&lt;p&gt;Hmm, about now the next wacky transition is starting to get harder to think up, so I’ll pull the nice trendy post-modernist trick of self-awareness. Speaking of post-modernism (BAM), it’s about time I brought up Charlie Kaufman. He is distinguished on this list for being the only one who is primarily an author of screenplays, yet it is fair to say his work is unmistakably his. &lt;strong&gt;Synecdoche NY&lt;/strong&gt;, &lt;strong&gt;Eternal Sunshine of the Spotless Mind&lt;/strong&gt;, &lt;strong&gt;Adaptation&lt;/strong&gt;, &lt;strong&gt;Being John Malkovich&lt;/strong&gt; - fantastic movies about art, love, and life. They speak for themselves.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimage&quot; src=&quot;https://draftin.com:443/images/33243?token=ra_Hy_oz8XdXfQ2OmIMxeiHYlrraFDoWFPOB75ac8RWwXAamoyV-yU7AKJ7Bm7YF2PV-aKZL4dM6Hdgszfgqp_E&quot; alt=&quot;Synechdoche New York&quot; /&gt;     
&lt;/figure&gt;

&lt;p&gt;Kaufman basically exudes talent. In addition to writing all the above, the people who did direct his films are themselves rockstars of the art film. Spike Jonze (&lt;strong&gt;Adaptation&lt;/strong&gt; and &lt;strong&gt;Being John Malkovich&lt;/strong&gt;) also directed the magnificent &lt;strong&gt;Her&lt;/strong&gt;, a film that managed to understand that science fiction is not solely a vehicle for action or horror, and a host of fantastic short films: &lt;a href=&quot;http://www.youtube.com/watch?v=e-0siK1w3eM&quot;&gt;&lt;strong&gt;Kanye West Meets His Demon&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&quot;http://www.youtube.com/watch?v=6OY1EXZt4ok&quot;&gt;&lt;strong&gt;Robots Can Love Too&lt;/strong&gt;&lt;/a&gt;, and &lt;a href=&quot;http://www.youtube.com/watch?v=5Euj9f3gdyM&quot;&gt;&lt;strong&gt;Damn Arcade Fire Is So Fucking Good&lt;/strong&gt;&lt;/a&gt;. It just so happens that Jonze was also married to Sofia Coppola, whose &lt;strong&gt;Lost in Translation&lt;/strong&gt; is about as good as you can hope from a movie premised about an aged and lonely Bill Murray befriending an existentially wrought Scarlett Johansonn in Japan. Back on topic: Michel Gondry directed the Kaufman written &lt;strong&gt;Eternal Sunshine of the Spotless Mind&lt;/strong&gt;, a movie perhaps unparalleled in its presentation of dreams and how our inner lives are reflected in them, a joy of a movie owing if only for its inventiveness and emotional resonance. He also directed the enjoyably quirky but perhaps forgettable &lt;strong&gt;Science of Sleep&lt;/strong&gt; and a host of awesome Bjork music videos - this may well be my &lt;a href=&quot;http://www.youtube.com/watch?v=4z7NN4n8CTY&quot;&gt;favorite music video ever&lt;/a&gt;.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimage&quot; src=&quot;https://draftin.com:443/images/33189?token=PgQT7iBEszRhPobAfIVpi0MhbFFyXJzPZb6_ccAE3OSgl-QLcoD-zng2LgsK_dNAiMyVVDsdiu07iUFUYaPX17g&quot; alt=&quot;Her&quot; /&gt;     
&lt;/figure&gt;

&lt;p&gt;Finally, George Clooney! George Clooney started his directorial work with &lt;strong&gt;Confessions of a Dangerous Mind&lt;/strong&gt;, yet another awesome movie written by Kaufman. Clooney’s later work is not that artsy but he should get way more cred for how good it is. Speaking of which, &lt;strong&gt;Micheal Clayton&lt;/strong&gt;. Clayton is weird only in how damn realistic it is, how fully it acknowledges the way humans are, how non-indie and not-artsy it is in its exploration of those themes. One of my favorites films - get through to the last scene and sit speechless at the genius of it.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimage&quot; src=&quot;https://draftin.com:443/images/33188?token=QVHSTbQt9CQjDuFB9ksPQMtljyhytFPppxoiXTY4BOu-_AjGPE7yS7AKrfL6y0hJpGRIxht5T7OwXcGTIOh0wfY&quot; alt=&quot;Michael Clayton&quot; /&gt;     
&lt;/figure&gt;

&lt;p&gt;But now the tone is getting too heavy - this can be addressed with some exploding heads. David Cronenberg is a peculiar auteur, the true master of body horror through all the eighties and nineties. Just watch the trailer to &lt;strong&gt;Videodrome&lt;/strong&gt; or &lt;strong&gt;Naked Lunch&lt;/strong&gt;. Just do it. His later work (&lt;strong&gt;Eastern Promises&lt;/strong&gt;,&lt;strong&gt;A History of Violence&lt;/strong&gt;) is strangely normal but still fantastically well made. So if you want to see a TV that has something resembling a vagina, a type writer that has something resembling a vagina, cars that dont have have anything resembling vaginas but are distinctly erotic (I am not making this up), well… Its fair to say you maybe don’t really want to see those things, but the general weirdness of Cronenberg’s early work and its legit thematic underpinnings should be appreciated, as should his basically excellent if more traditional work.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimage&quot; src=&quot;https://draftin.com:443/images/33244?token=i40M6GIXvMVU8g9GXre0s2Sc0nsmSC7ZaA-jjYa5vb868IpeWbBXFl33n1szTAYyCSyUpY5RWrwHM_N7RKASZjo&quot; alt=&quot;Naked Lunch&quot; /&gt;     
&lt;/figure&gt;

&lt;p&gt;Not interested in seeing inanimate manner being quite so animate, or just want to watch some nice classy art movies? Shane Carruth. The director whom I quite literally proselytize to every one I meet, a software engineer turned auteur filmmaker. &lt;strong&gt;Primer&lt;/strong&gt;. A purportedly $7000 movie about the mind fuck of time travel from the perspective of an engineer, and the corrupting power of power. &lt;strong&gt;Upstream Color&lt;/strong&gt;. A hypnotizing movie that merges sci fi and artfulness in a way I have never seen done - I can think of few dialogue-free scenes as striking as found in this movie. In this case a quote from &lt;a href=&quot;http://www.rottentomatoes.com/m/upstream_color/&quot;&gt;RottenTomatoes&lt;/a&gt; feels most appropriate: “As technically brilliant as it is narratively abstract, Upstream Color represents experimental American cinema at its finest – and reaffirms Shane Carruth as a talent to watch.”.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimage&quot; src=&quot;https://draftin.com:443/images/33245?token=kg1Nlhxmbunc_ReJHx6HwqWV30xzh9BOcZNmpspTQ8DqBgWWGkSDvYwmdDIfV1z4CuMTIK4dwTDPZc-pZl0KHPU&quot; alt=&quot;Upstream Color&quot; /&gt;     
&lt;/figure&gt;

&lt;p&gt;So many words, yet so little ground covered. Let’s do a quick sweep of the globe - fast now, over in Japan we forgot to mention Ozu, whose excellent &lt;strong&gt;Tokyo Story&lt;/strong&gt; you will surely love, and the more recent Takeshi Kitano with his existentialist gangster films in the vein of &lt;strong&gt;Sonatine&lt;/strong&gt;, and lastly the counterpoint of Hirokazu Koreeda whose &lt;strong&gt;Nobody Knows&lt;/strong&gt; is the best minimalist theme I can think of. But let’s not linger - over in China there is the distinctly weird yet unquestionably interesting Wong Kar-Wai with bizarre dreams like &lt;strong&gt;Chunkgink Express&lt;/strong&gt; and &lt;strong&gt;Fallen Angels&lt;/strong&gt;, though if you are not into that there is also Johnie To with fantastic Shakespearean gangster tragedies like &lt;strong&gt;The Triad Election&lt;/strong&gt;. Then it just so happens in Korea Park Chan-Wook is both violent and bizarre, most notably in the already-classic &lt;strong&gt;Oldboy&lt;/strong&gt; (and personal favorite blood-dark romantic comedy &lt;strong&gt;Thirst&lt;/strong&gt;), and alongside his work there is as a host of recent fairly normal yet fantastic violent thrillers of which Lee Jeong-beom To’s &lt;strong&gt;The Man From Nowhere&lt;/strong&gt; is surely the best. Not to be all about Asia here, over from Mexico there is Benecio del Toro with the unforgettable WWII fairy tale &lt;strong&gt;Pan’s Labyrith&lt;/strong&gt;, and Alfonso Cuarón has the poignant life tale &lt;strong&gt;Y Tu Mama Tambien&lt;/strong&gt; and the just-please-watch-it-you’ll-be-happy-you-did-masterpiece &lt;strong&gt;Children of Men&lt;/strong&gt;. Let’s mention Britain too, where Richard Ayoade has recently made the excellent coming of age tale &lt;strong&gt;Submarine&lt;/strong&gt; and the somehow yet more delightful adaptation of Dostoevsky &lt;strong&gt;The Double&lt;/strong&gt;. Finally, we wind up in Israel due to the sheer beauty of Ari Folman’s &lt;strong&gt;Waltz with Bashir&lt;/strong&gt; of which you may be convinced with nothing more than the following image.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimage&quot; src=&quot;https://draftin.com:443/images/33248?token=T20B0DzRAvKHdSt9L2sk_5FRkcwsWKN9dOB5KhoBqLbu3SzSPAsRv4NkJIVN8tME3eVg7N7X-W-TJM83GWbHwMY&quot; alt=&quot;Waltz with Bashir&quot; /&gt;     
&lt;/figure&gt;

&lt;p&gt;Tired yet? I’m impressed you made it this far. Listen, I wonder how to close this thing - I have journeyed through most of my memory and mind and found the scattered pieces of film impressions that are clearly somewhat important to me, yet can I be expected to find some sequence of sentences to sum up all this? No, that would hardly be a reasonable expectation. Rather, I shall close on one last filmmaker, perhaps my favorite, and most certainly one not sufficiently recognized as of yet. That filmmaker is Satoshi Kon, and I must admit his work not to be film strictly - as with the above it is animation, anime (speaking of which, surely I can take for granted you have heard of Miyazake and &lt;strong&gt;Princess Mononoke&lt;/strong&gt; and &lt;strong&gt;Spirited Away&lt;/strong&gt;). Yet, his work is about film - &lt;strong&gt;Perfect Blue&lt;/strong&gt; with its obvious Hitchcockian inspiration, &lt;strong&gt;Millenium Actress&lt;/strong&gt; with an overt and beautifully rendered and just so damn wonderful recollection of the history of Japanese cinema, and finally &lt;strong&gt;Paprika&lt;/strong&gt; - a movie about the power of dream that may as well equate cinema itself to that act. Vivid, creative, exuberant, surprising, challenging, comedic, touching - Kon’s work is a testament to the power of film, and the fantastic dreams we may inhabit through them.&lt;/p&gt;

&lt;figure&gt;
    &lt;img class=&quot;postimage&quot; src=&quot;https://draftin.com:443/images/33249?token=IyoXEt59YrNKHsBba9nzrRhsj0BS3Oy4kFsqlkaLT4kbX0YsMleiBE_QB3hNHgTgjFJNrkWF93CcVbtU27r0qF0&quot; alt=&quot;Paprika&quot; /&gt;     
&lt;/figure&gt;

    &lt;p&gt;&lt;a href=&quot;/writing/movie-recommendations-for-the-aspiring-eclectic-intellectual/&quot;&gt;Movie Recommendations For The Aspiring Eclectic Intellectual&lt;/a&gt; was originally published by Andrey Kurenkov at &lt;a href=&quot;&quot;&gt;Andrey Kurenkov's Web World&lt;/a&gt; on October 22, 2015.&lt;/p&gt;
  </content>
</entry>


  

<entry>
  <title type="html"><![CDATA[Exceptional People]]></title>
  <link rel="alternate" type="text/html" href="/writing/exceptional-people/" />
  <id>/writing/exceptional-people</id>
  <published>2015-10-11T16:19:34-07:00</published>
  <updated>2015-10-11T16:19:34-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email>andreyvkurenkov@gmail.com</email>
  </author>
  <content type="html">
    &lt;h3 id=&quot;or-people-disappoint-you-an-essay-poem&quot;&gt;Or, People Disappoint You, an essay-poem&lt;/h3&gt;
&lt;div&gt;&lt;button class=&quot;btn&quot; data-toggle=&quot;collapse&quot; data-target=&quot;#foreword&quot;&gt;
Foreword &amp;raquo;
&lt;/button&gt;&lt;/div&gt;
&lt;blockquote class=&quot;aside&quot;&gt;&lt;p id=&quot;foreword&quot; class=&quot;collapse&quot; style=&quot;height: 0px;&quot;&gt;
As with most things I write about, this has been rolling about in my head for many years. 
It is the sort of thing I keep hitting up against and wondering at, and eventually crystallize some notion of that calls for itself to be solidified in text. In starting to solidify this into text, I realized that it will be short, and comes from a place particularly likely to call upon the typical impactful literary techniques I use whose names I do not remember. So, I figured, if I am to write a short essay with impassioned sections, why not go all the way and give it the form of a poem. I may not be a poet, but by posting these digital pages of text I do inevitably claim the identity of a writer, of some sort. So, here's an essay poem.

PS shout out, similar thoughts were echoed well in &lt;a href=&quot;http://colorfulcortex.co/2015/10/24/the-youre-not-as-cool-in-person-phenomenon/&quot;&gt;'The “You’re Not as Cool in Person” Phenomenon'&lt;/a&gt;.
&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I have seen the shine of exceptional people,&lt;br /&gt;
their radiance of confidence, skill, power,&lt;br /&gt;
their lit up eyes in the midst of inspiration,&lt;br /&gt;
their bright excitement in the flow of creation.&lt;/p&gt;

&lt;p&gt;When? When I have sat with them in cruel extra credit classes,&lt;br /&gt;
and worked with them during brutal nocturnal work slogs,&lt;br /&gt;
and argued with them over specifics in hastily scrawled sketches,&lt;br /&gt;
and drank with them past sundown unfazed by the impending morning.&lt;/p&gt;

&lt;p&gt;Then, I have sensed in them burning hearts,&lt;br /&gt;
or perhaps perpetually caffeinated brains,&lt;br /&gt;
and in those brains always a thought, a plan, an idea,&lt;br /&gt;
and in those hearts always the energy to think, imagine, strive.&lt;/p&gt;

&lt;p&gt;And in me? Often, mired in melancholy, I felt jealousy -&lt;br /&gt;
felt just short of that ascendancy beyond normalcy,&lt;br /&gt;
different but not outstanding, smart but not exceptional,&lt;br /&gt;
the angst of a restless below average overachiever.&lt;/p&gt;

&lt;p&gt;But! Don’t worry. I grew up, slain that silly impulse, &lt;br /&gt;
long since realized the emptiness of numbers,&lt;br /&gt;
pierced the perceived glow of outstanding people,&lt;br /&gt;
and through it saw, simply, friends, peers, people.&lt;/p&gt;

&lt;p&gt;Just people. Impressive people.&lt;br /&gt;
People who have bad days and tough times.&lt;br /&gt;
People who have dark sides and hidden fears.&lt;br /&gt;
People who make mistakes.&lt;br /&gt;
People who make bad jokes.&lt;br /&gt;
People who struggle.&lt;/p&gt;

&lt;p&gt;And at first it was distinctly disappointing to see the death of that ideal, &lt;br /&gt;
the impossibility of escaping difficulty dealing with all of life’s damned dimensions. &lt;br /&gt;
Such a typically tepid truth - us mere mortals incapable of that heroic Herculean halo,&lt;br /&gt;
and left to grow to see humans do not live in fairly tales, as I did with those around me.&lt;/p&gt;

&lt;p&gt;But you know, funny thing - in time I liked them all the more for it.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;/writing/exceptional-people/&quot;&gt;Exceptional People&lt;/a&gt; was originally published by Andrey Kurenkov at &lt;a href=&quot;&quot;&gt;Andrey Kurenkov's Web World&lt;/a&gt; on October 11, 2015.&lt;/p&gt;
  </content>
</entry>


  

<entry>
  <title type="html"><![CDATA[On Employment]]></title>
  <link rel="alternate" type="text/html" href="/writing/on-employment/" />
  <id>/writing/on-employment</id>
  <published>2015-09-24T20:00:00-07:00</published>
  <updated>2015-09-24T20:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email>andreyvkurenkov@gmail.com</email>
  </author>
  <content type="html">
    &lt;h1 id=&quot;the-present&quot;&gt;The Present&lt;/h1&gt;
&lt;p&gt;You know, I am one of the lucky ones. Right from the start, I lucked out - born male, white, and straight, I was endowed with the US social privilege trifecta. For nothing, no effort at all, I got to have it easy in many ways I most likely don’t even perceive. I was lucky, too, with economic privilege - my parents made my childhood easy and stable, and within the span of that childhood managed to move us from the ranks of middle class in Ukraine to the same in the US. Think that’s impressive? Get this: I got through a top tier college without a penny of debt - cue the tears of millions of my recently graduated peers.&lt;/p&gt;

&lt;p&gt;So, big surprise, I ended up getting a degree (well, two) followed by a Software Engineering job which assured my ability to have a very comfortable life. I am 22, and many, too many, in the world cannot even hope for this much. But, insurmountable ethical queasiness about inequality aside, my life is good, right? Right. So then, it’s really a testament to the ingenuity of the human mind and spirit that I am not kicking back and enjoying life, satisfied and content. Oh no, that would make life all too easy and lacking difficult things to write lengthy quasi-essays about. No - in truth, I hope for yet more. Not just a job that pays well, but a job that I find interesting and enjoyable, and not just a job that I find interesting and enjoyable, but a job that I find, crucially, fulfilling. I have no idea what that even means yet, and cannot help but wonder about this drive within me. A comfortable life is nice, but something within me wants for, moreso, a life that feels right - whatever that is.&lt;/p&gt;

&lt;div&gt;&lt;button class=&quot;btn&quot; data-toggle=&quot;collapse&quot; data-target=&quot;#viewdetails&quot;&gt;
An Aside: if you are a coworker of mine - oh, that's awkward, click this &amp;raquo;
&lt;/button&gt;&lt;/div&gt;
&lt;blockquote class=&quot;aside&quot;&gt;&lt;p id=&quot;viewdetails&quot; class=&quot;collapse&quot; style=&quot;height: 0px;&quot;&gt;
Relax! I am not actually having an existential crisis regarding working at Oracle or elsewhere. See, I am doing this personal narrative intro bit, motivating this giant slab of text to get people into it. 
And, if you happen to not be a coworker of mine, how dare you read this?! Kidding. I sure do hope you found that piece of text amusing; obviously it was a calculated move to dispel the largely self-serious tone found here thus far.
&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Fun though it would be to go into how this connects to humans’ general inability to ever feel content, I can’t claim to be quite so profound. No, this drive for fulfilling work is hardly original these days - it is a common sentiment usually boiled down to the &lt;a href=&quot;https://www.youtube.com/watch?v=pMnJLWeo1z8&quot;&gt;Steve Jobs sactioned&lt;/a&gt; phrase “Do What You Love”. This strand of thinking has become so conventionally accepted that Slate ran an impassioned &lt;a href=&quot;http://www.slate.com/articles/technology/technology/2014/01/do_what_you_love_love_what_you_do_an_omnipresent_mantra_that_s_bad_for_work.html&quot;&gt;critique&lt;/a&gt; against it that begins by stating that “There’s little doubt that ‘do what you love’ is now the unofficial work mantra for our time” and goes on to point out to lucky bastards like me that it is in fact “a secret handshake of the privileged and a worldview that disguises its elitism as noble self-betterment.”  The Atlantic, likewise, has &lt;a href=&quot;http://www.theatlantic.com/business/archive/2015/09/gig-economy-doublespeak-new-labor/404779/&quot;&gt;rebuked&lt;/a&gt; the concept with eloquent sick burns:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Today’s knowledge economy is defined by a duplicitous charm in its categorical refusal to see work as labor. Desk workers are everywhere encouraged to “love what you do”: to embody their company’s values, identify with its brand, and then celebrate its accomplishments through internal and external marketing. For these creative workers, it is a badge of honor to never be off the clock.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;First of all, I have a secret handshake!? Second - is this actually true? I’ve already &lt;a href=&quot;http://www.andreykurenkov.com/writing/on-work/&quot;&gt;written&lt;/a&gt; of my fondness for work, so I won’t waste time whining about the articles’ simplistic characterization of me as a privileged workaholic brainwashed by The Man. But, me aside, is this more generally true? With regards to the ‘Millennial’ age group of people who were born sometime between the inception of the NES and that of The Matrix, the group to which I belong, it only takes a quick Google to find that &lt;a href=&quot;http://www.forbes.com/sites/karlmoore/2014/10/02/millennials-work-for-purpose-not-paycheck/&quot;&gt;“Millennials Work For Purpose, Not Paycheck”&lt;/a&gt;. Except, not really. Look up a piece &lt;a href=&quot;http://blogs.wsj.com/atwork/2014/09/10/survey-says-everything-you-know-about-millennials-is-wrong/&quot;&gt;backed by some numbers&lt;/a&gt; rather than fun anecdotes, and you find stuff like this:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Competitive pay is the single biggest contributor to job satisfaction for Millennials and non-Millennials alike, with 68%  and 64% citing it as important or very important, respectively. The second largest factor for both was bonuses and merit-based rewards, at 55% and 56%, respectively.
…
Only one-fifth of each generational group felt that “making a positive difference in the world” had an impact on their satisfaction. And slightly fewer Millennials – 29% versus 31% of other workers – said that achieving work/life balance was a key contributor to their professional happiness. Same thing with “finding personal meaning in work,” where the numbers came out 14% to 17%, in favor of non-Millennials.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So much for that story. The likes of me may make up that 14-17%, but it’s clear Do What You Love is hardly a universal mantra. This is the US, and a proclivity for pragmatism is alive and well.&lt;/p&gt;

&lt;p&gt;Anyway, what fun are percentages? For all I know they are entirely made up, since much like you it’s not like I bothered to go back and check the veracity of the study. In typical human fashion, what made me think about this is not numbers, but people. Specifically, the people I interacted with in college. Specifically, the small rank of people in college that, like me, found the time to work on projects not required by any class, simply because they felt like it. Or rather, specifically, that vast majority of people who were not in that rank - who did not go to hackathons, who did not have repositories full of half-finished side projects or tables covered by half a dozen breadboards, who really just generally enjoyed their major and wanted to get a job in that field.&lt;/p&gt;

&lt;p&gt;Many in this great majority of people were about as lucky as me, but seemed to lack my yearning for yet more beyond a good job; it seems to me most enjoyed programming as a whole, but not so much as to do it in their free time, and they wanted little more out of a job than being payed well to do programming they enjoyed. To me, that’s not Do What You Love, but is more like Do Something You Enjoy. That is what I saw in the majority of CS majors who studied alongside me. And, despite my fabulously sheltered life I am aware many more are not so lucky to think even like that, that many have little choice but to embrace Do What You Can.&lt;/p&gt;

&lt;p&gt;So then, despite the great social, cultural, artistic, and technological transformations of the past century, despite the supposed cultural acceptance of the DWYL idea, despite all that, I am left wondering if our collective cultural view of work is still about the same as ever - a means of trading time and energy for resources necessary for survival and, if lucky, leisure. Many today want the trade to be pleasant and the labor interesting, but still - has much really changed from a century ago?&lt;/p&gt;

&lt;h1 id=&quot;the-past&quot;&gt;The Past&lt;/h1&gt;

&lt;p&gt;Okay, fine, obviously much has changed (in the US, at least). Most good jobs now require at least a high school degree, and by extension there are many more jobs that are interesting and require creativity. More people get to be artists, more people get to be engineers, more people get to be just about everything - except farmers and factory workers. More people have jobs that did not exist a century ago than those two, as the anti-DWYL Atlantic article nicely summarizes:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Over the past 50 years, the main source of employment in the United States has shifted from the manual to the mental—from doing things with one’s hands to delivering a service or a feeling. As Enrico Moretti points out in his 2013 book The New Geography of Jobs, any given American is now statistically more likely to work in a restaurant than a factory.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So yes, a lot has changed. But, that’s just the particulars of how people prepare for work and what it ends up being. What about why they work, what they work for? Well, it’s hard to say what a mere commoner such as myself thought about it back in the day, since no one kept blogs or posted any tweets. So, let us examine the opinions of those few past lucky bastards whose thoughts survived to this day; starting, of course, with John Smith. Turns out, the papa of capitalist economies certainly had a &lt;a href=&quot;http://monthlyreview.org/2006/10/01/the-meaning-of-work-a-marxist-perspective/&quot;&gt;bleak answer&lt;/a&gt; to those questions:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Adam Smith, the great theoretician of the capitalist economy, is much more explicit when, in a different context, he defines work as an activity requiring the worker to give up “his tranquility, his freedom, and his happiness.” Wages, according to Smith, are the reward the laborer receives for his or her sacrifices.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It does not take a sociology or psychology or psychological sociology degree to see that this does not reflect the modern attitude towards work in the US. Yes, for some it may perhaps be accurate, but for great numbers of people (again, lucky people), their work is also their chief metric of success and source of pride. I can nitpick my peers’ zeal for their field all I want, but I think very few would agree they don’t enjoy or take any pleasure and pride in their work. The funny thing is, despite US culture being most encouraging for this sort of work-for-pride thinking it actually follows the thoughts of a certain German who was no big fan of capitalism:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“‘Smith has no inkling whatever that the overcoming of obstacles is in itself a liberating activity—and that, further, the external aims become stripped of the semblance of merely external natural urgencies, and become posited as aims which the individual himself posits—hence as self-realization, objectification of the subject, hence real freedom, whose action is, precisely, labor.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So, is work still seen through the mindset of Smith, or his great nemesis Marx? According to &lt;a href=&quot;http://www.nytimes.com/2015/08/30/opinion/sunday/rethinking-work.html?ref=opinion&quot;&gt;one NY Times Opinion Piece&lt;/a&gt;, Smith is still supreme: “Today, in factories, offices and other workplaces, the details may be different but the overall situation is the same: Work is structured on the assumption that we do it only because we have to. “ And yet, the same paper only two weeks before &lt;a href=&quot;http://www.nytimes.com/2015/08/16/technology/inside-amazon-wrestling-big-ideas-in-a-bruising-workplace.html?ref=technology&quot;&gt;published a scathing piece&lt;/a&gt; discussing how Amazon sought out high achievers and squeezed productivity and innovation out of them like human fruit while promising only the reward of great accomplishments rather than Google-esque utopian work conditions. And so we come to an annoyingly predictable conclusion - the world is grey, and it’s hard to say quite which color is predominant.&lt;/p&gt;

&lt;p&gt;Rather than pretend to have understanding of the ambiguous, let’s explore the larger truth this Amazon story speaks to - the emergence, over the past few decades, of this new subset of human endeavor chiefly defined by writing software, and its peculiarities. Perhaps uniquely outside of art and philosophy, this field is home to droves of big egos who think they can hit it big, or in the words of an entirely unironic TechCrunch editorial, “&lt;a href=&quot;http://techcrunch.com/2012/01/20/do-great-things/&quot;&gt;Do Great Things&lt;/a&gt;”:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“We who work in technology have nurtured an especially rare gift: the opportunity to effect change at an unprecedented scale and rate. Technology, community, and capitalism combine to make Silicon Valley the potential epicenter of vast positive change. We can tackle the world’s biggest problems and take on bold missions like fixing education, re-imagining energy distribution, connecting people, or even democratizing democracy.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The core idea of that article is that with great power comes great responsibility, and those of us with the power of programming are like superheroes capable of fixing the world’s woes. A bit much, obviously - the world’s big problems were built with much effort, and software alone is unlikely to move those glaciers far. This sort of thinking has become so common and exaggerated that it has come to be satirized, most notably by the show Silicon Valley - ironically beloved by many in the Valley.&lt;/p&gt;

&lt;p&gt;Still, to me the more notable subset of weirdos in the comp sci space is the huge army of people who practice the craft out of genuine enjoyment - me among them. How else could a site like GitHub, a sort of programmer social network notable as much for safely storing code as its social features, become a standard in this big space within a few years. And, furthermore, there sprung up a host of websites to enable people such as myself to code in their free time: &lt;a href=&quot;https://projecteuler.net/&quot;&gt;Project Euler&lt;/a&gt;, &lt;a href=&quot;http://www.topcoder.com/&quot;&gt;TopCoder&lt;/a&gt;, &lt;a href=&quot;https://www.hackerrank.com/&quot;&gt;HackerRank&lt;/a&gt;, &lt;a href=&quot;http://devpost.com/&quot;&gt;DevPost&lt;/a&gt;, &lt;a href=&quot;http://hackaday.com/&quot;&gt;Hackaday&lt;/a&gt;, and even more.&lt;/p&gt;

&lt;p&gt;And that’s great! Clearly I am of the perspective that work should not be a sacrifice, but an investment - an investment in a pursuit, an idea, yourself. An investment not to change the world, not to be some hero, but just to do something you want. But, clearly, few are quite as invested in this notion as I am. The intrinsically motivated crowd who uses such sites must be small compared to the many more who just enjoy the work but think of it chiefly as such. So, let’s summarize: by and large, employed work is still largely seen as labor, but compared to the past many more people get to be lucky enough to have the freedom to take the Marxist view of work as a means of finding happiness.&lt;/p&gt;

&lt;h1 id=&quot;the-future&quot;&gt;The Future&lt;/h1&gt;

&lt;p&gt;So, some things have changed, attitude wise, but as Slate and The Atlantic so eloquently pointed out by and large only lucky bastards like me get to benefit from the changes while most still regard work as labor, and not one of love. Fun as it is was to reflect on our present and reminisce about our past, I clearly have to take the next step - ponder our future. Will things change yet more? Yes, of course. So, how?&lt;/p&gt;

&lt;p&gt;The agent of change will clearly be, as before, technology. And that can only mean one thing - robots! Right? Having worked in robotics I have seen many oh so many pieces about the job eradicating potential of that field - most not worth taking seriously. Robots suck at doing anything halfway intelligent, still, period, and the core of problem that causes the fragility of such intelligent robotic systems - a lack of common sense - is not going to be solved any time soon. Why? Here’s a summary &lt;a href=&quot;http://www.syntouchllc.com/Media/Blog/2013-08-27-The-problem-with-robots/&quot;&gt;“The problem with robots: If they only had a brain”&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In the 1960s and 70s, a great wave of enthusiasm for artificial intelligence (AI) in computers based on human thought processes crashed against our sheer ignorance of those processes. Engineers mostly stopped talking about “intelligence” and opted for signal processing algorithms and relational databases that appear to perform intelligently but only within highly scripted tasks - e.g. robots. That is why moving robots from the mindless assembly line into the real world usually produces pitiful, sometimes catastrophic results. If a robot encounters an unfamiliar object or even a familiar one in the wrong orientation, it is likely to proceed extremely cautiously or to damage the object or itself by handling it inappropriately. A human worker that inept would be fired immediately.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And so there are precious few examples of robots out there in the wild, doing things that humans do that also happen to be more complicating than endlessly executing the same repetitive motion in a caged factory. And, as was pointed out relatively few jobs (in the US) are based on physical labor, and it’s even less clear that people would like awkward robots to replace their human counterparts in jobs requiring social interaction. The non-factory robots out there are &lt;a href=&quot;http://www.boston.com/business/technology/gallery/consumerrobots/&quot;&gt;for the most part&lt;/a&gt; in the vein or the Roomba or are more specialized tools meant for hospitals or film sets, and despite &lt;a href=&quot;http://www.rethinkrobotics.com/baxter/&quot;&gt;some&lt;/a&gt; &lt;a href=&quot;https://www.jibo.com/&quot;&gt;interesting&lt;/a&gt; &lt;a href=&quot;http://www.savioke.com/&quot;&gt;efforts&lt;/a&gt; I would stake my measly reputation on the idea that it’ll still be decades before significant amount of US jobs will be threatened with robotic automation.&lt;/p&gt;

&lt;div&gt;&lt;button class=&quot;btn&quot; data-toggle=&quot;collapse&quot; data-target=&quot;#roboticsaside&quot;&gt;
An Aside: more on the state of robotics &amp;raquo;
&lt;/button&gt;&lt;/div&gt;
&lt;blockquote class=&quot;aside&quot;&gt;&lt;p id=&quot;roboticsaside&quot; class=&quot;collapse&quot; style=&quot;height: 0px;&quot;&gt;
I am being a little harsh here. Okay, quite harsh. Robotics as a field has actually been moving incredibly rapidly in the past decade towards intelligent automation that goes beyond the cute little Roomba. The clearest success story is &lt;a href=&quot;https://en.wikipedia.org/wiki/Amazon_Robotics&quot;&gt;Kiva Systems&lt;/a&gt;, which greatly improved the efficiency of warehouses and has led to more ambitious efforts such as those of &lt;a href=&quot;http://fetchrobotics.com/&quot;&gt;Fetch Robotics&lt;/a&gt;. I suspect the next great success stories will come from agriculture, where companies such as &lt;a href=&quot;http://www.precisionhawk.com/&quot;&gt;Precision Hawk&lt;/a&gt; and &lt;a href=&quot;http://www.bluerivert.com/&quot;&gt;Blue River Technology&lt;/a&gt; are paving the way towards data-driven decisions for farmers that could be executed more precisely by steel machinery rather than meaty muscle. And though I called the &lt;a href=&quot;http://www.rethinkrobotics.com/baxter/&quot;&gt;Baxter&lt;/a&gt;, &lt;a href=&quot;https://www.jibo.com/&quot;&gt;Jibo&lt;/a&gt; and &lt;a href=&quot;http://www.savioke.com/&quot;&gt;Savioke&lt;/a&gt; 'interesting', they are hugely promising for starting the push towards smarter cooperative robots in the factory, funner social robots in the home, and more pleasant robotics in the service industry respectively. I just don't expect these efforts to have widespread impact for decades yet, based on their slow start and the difficulty of robotics in general. Oh yes! And there are the &lt;a href=&quot;http://www.google.com/selfdrivingcar/&quot;&gt;self&lt;/a&gt; &lt;a href=&quot;http://www.wired.com/2015/07/crummy-highways-delaying-self-driving-tesla/&quot;&gt;driving&lt;/a&gt; &lt;a href=&quot;http://www.engadget.com/2015/03/25/mercedes-f015-luxury-self-driving-car/&quot;&gt;cars&lt;/a&gt;. Even I am not enough of a skeptic to deny the awesome impact that self driving cars will soon have.
&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;But! That is not to say things are not set to change. Oh, they so are. But, the big bad boy who will bring in about change is not robotics, at least not it alone. Moreso, it’ll be our old economic grandpa, declining costs, our good old friend, increasing computing power, and our new hip friends, Big Data and Machine Learning. With the steady march of &lt;a href=&quot;http://www.webopedia.com/TERM/M/Moores_Law.html&quot;&gt;Moore’s Law&lt;/a&gt; yet unabated, computers have gotten fast enough, and algorithms good enough, that robotics can now figure out such complicated things as how to grasp items or move very complicated arms for arbitrary goals while avoiding collisions - things that used to be basically intractable. And this trend will continue, until decades will have passed, and the long foretold future of robotic automation will quite inevitably get here. But, since that is a while off let’s talk about something else - how the exponential rise of computing power and improvement in algorithms has enabled another, and in the short term more significant advance - the amazing feats accomplished by the field of Machine Learning in the past several years.&lt;/p&gt;

&lt;div&gt;&lt;button class=&quot;btn&quot; data-toggle=&quot;collapse&quot; data-target=&quot;#machinelearning&quot;&gt;
An Aside: one paragraph summary of Machine Learning &amp;raquo;
&lt;/button&gt;&lt;/div&gt;
&lt;blockquote class=&quot;aside&quot;&gt;&lt;p id=&quot;machinelearning&quot; class=&quot;collapse&quot; style=&quot;height: 0px;&quot;&gt;
&lt;a href=&quot;https://www.coursera.org/learn/machine-learning&quot;&gt;Machine Learning (ML)&lt;/a&gt; is really not as fancy as it sounds. Take a bunch of points on a 2D graph and find the nicest line (straight, hyperbolic, whatever you like) to fit through them, and you've got a form of basic machine learning - a general way to get some output from some input, gotten from some set of examples of correct input and output. Do this line fitting trick a bunch, and make the Y of some lines become the X for some other lines, and maybe likewise make the X for some lines the Y for other lines, and you've got a 'neural net'. This is oversimplifying things, of course, but captures the idea at the heart of the field. It is computer scientists' best attempt at equipping computers with humans' greatest strength - pattern detection and generalization of learned things to new situations. This is conceptually incredibly useful, since tasks that are very difficult or impossible to write programs for (say, figuring out whether an image has a cat or a cactus in it) but that we as humans can easily do can suddenly be taught to the computer. Trouble is, really tough tasks like recognizing what people say or what is in an image did not work so well, so ML was very cool but largely not practical for real problems - until recently.
&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;So, what has been going on with ML recently? A LOT. Several key insights, the most significant being to use better computing power with GPUs and a better scaling ML algorithm called Convolutional Neural Nets, has led to massive gains in how well the techniques can be applied to large amounts of data nicely &lt;a href=&quot;https://www.youtube.com/watch?v=n1ViNeWhC24&quot;&gt;summarized&lt;/a&gt; by one of the architect of the movements, Andrew NG. By the way, the seemingly fancy term Deep Learning=GPUs+CNNs. At the same time, this whole Big Data trend came about, and companies like Google and Facebook and many others started applying these research techniques to their Absurd amounts of data. This confluence has led to many amazing research advancements in the past several years and has made the people responsible for these advancements very successful.&lt;/p&gt;

&lt;p&gt;So, how does this relate to jobs again? One word: automation. Or, more correctly, computerisation. Computers have obviously already had a huge impact on how many jobs are done, and relegated many jobs to the past. But until now, they have largely just been excellent tools to be wielded by humans - hugely empowering, but not able to do much without being set in motion by the squishy brain of a human being. And the things we set in motion! Despite just being really fast calculators, computers have been used for so much more than computation - art, science, communication, exploration, and so much. But, without a person at the helm, computers are still left to follow a very rigid set of steps and instructions, and it turns out we just can’t figure out instructions for things humans are really good at, like recognizing speech and finding cute cat pictures on the internet. Until now. Machine Learning is now empowering the hard silicon logic computers to do things that used to be entirely within the domain of squishy human brains - and in some cases, empowering computers to do those things better.&lt;/p&gt;

&lt;p&gt;Please, don’t take my word on it. What do I know, really? Take the word of academics who spent years crafting an excellent &lt;a href=&quot;http://www.oxfordmartin.ox.ac.uk/downloads/academic/The_Future_of_Employment.pdf&quot;&gt;2013 paper from Oxford&lt;/a&gt; that explored this idea in much detail, and ended up finding that 47% could be automated right out.  Really - don’t take my word for it, read it. Or, at least read this excerpt:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Historically, computerisation has largely been conﬁned to manual and cognitive routine tasks involving explicit rule-based activities  (Autor and Dorn, 2013; Goos, et al., 2009). Following recent technological advances, however, computerisation is now spreading to domains
commonly deﬁned as non-routine.
…
Although the extent of these developments remains to be seen, estimates by MGI (2013) suggests that sophisticated algorithms could substitute for approximately 140 million full-time knowledge workers worldwide. Hence, while technological progress throughout economic history has largely been conﬁned to the mechanisation of manual tasks, requiring physical labour, technological progress in the twenty-ﬁrst century can be expected to contribute to a wide
range of cognitive tasks, which, until now, have largely remained a human
domain.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;As the paper later points out, the development of ML will likewise expand the reach of robotics beyond the drudgery or repetitive industrial work:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Mobile robotics provides a means of directly leveraging ML technologies to
aid the computerisation of a growing scope of manual tasks. The continued technological development of robotic hardware is having notable impact upon
employment: over the past decades, industrial robots have taken on the routine tasks of most operatives in manufacturing. Now, however, more advanced
robots are gaining enhanced sensors and manipulators, allowing them to perform non-routine manual tasks.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This sort of talk scares people. And perhaps it should - change is scary. And when thoughts of scary change come about, people who do not habitually read ML and robotics papers start to take notice. A fantastic &lt;a href=&quot;https://www.youtube.com/watch?v=7Pq-S557XQU&amp;amp;app=desktop&quot;&gt;youtube video essay&lt;/a&gt; just on this topic has garners 5 million views, and generated much fanfare on internet communities such as reddit. But, fantastic though it is, it is also wrong. The video covers much of the same content as I have expressed above, quite eloquently, but completely overstates the degree of machine intelligence we can predict at present. Robot baristas, self-driving cars, factories with cooperative robots, news bots - all of that is likely to happen soon, or is happening. But robots capable of writing anything as conceptually complicated as this, or the sort of software that I write for work, or even move with the agility of waiters - these are a long long time off, and perhaps will never fully come to fruition. Like &lt;a href=&quot;http://observer.com/2015/08/stephen-hawking-elon-musk-and-bill-gates-warn-about-artificial-intelligence/&quot;&gt;Elon Musk, Bill Gates, and Stephen Hawking&lt;/a&gt;, the writer makes predictions from current trends that I (as someone who does habitually read ML and robotics papers) find unrealistic, and unreasonable.&lt;/p&gt;

&lt;p&gt;Elon Musk and Bill Gates and Stephen Hawking seem like a pretty impressive bunch, so where do I get the nerve to call them out on being excessively worried about AI? Well, that would take a whole separate 5000 word quasi-essay to go into. So, let instead call on the power of Ethos and present the sentiments &lt;a href=&quot;http://www.theregister.co.uk/2015/03/19/andrew_ng_baidu_ai/&quot;&gt;Andrew Ng&lt;/a&gt;, someone actually leading those revolutionary advances in the field, has expressed:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Those of us on the frontline shipping code, we’re excited by AI, but we don’t see a realistic path for our software to become sentient. There’s a big difference between intelligence and sentience. There could be a race of killer robots in the far future, but I don’t work on not turning AI evil today for the same reason I don’t worry about the problem of overpopulation on the planet Mars.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So, it’s just too early to look that far in the future - it is entirely possible the capabilities of the present surge of AI systems will again plateau, and true cognitive intelligence will not become a reality. This plateau may and likely will be one with millions fewer jobs, and much more futur-y with robots and the like all about, but it will not be a drastic feature where all human endeavor is automated or humans are entirely done away with in favor of machines. There are &lt;a href=&quot;http://slatestarcodex.com/2015/05/22/ai-researchers-on-ai-risk/&quot;&gt;strong&lt;/a&gt; &lt;a href=&quot;http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html&quot;&gt;arguments&lt;/a&gt; for why we should be generally aware of the progress of AI, but they do not make a compelling case that such a future is inevitable.&lt;/p&gt;

&lt;div&gt;&lt;button class=&quot;btn&quot; data-toggle=&quot;collapse&quot; data-target=&quot;#singularity&quot;&gt;
An Aside: for the few of you screaming in your head about The Singularity or Superintelligence right now &amp;raquo;
&lt;/button&gt;&lt;/div&gt;
&lt;blockquote class=&quot;aside&quot;&gt;&lt;p id=&quot;singularity&quot; class=&quot;collapse&quot; style=&quot;height: 0px;&quot;&gt;
I really cannot reasonably get into those book length explorations of the future. Suffice it to say that the presumption of persistent exponential returns with technology is not well supported - fundamental physical or conceptual principles may halt the progress of computational power and make an AI driven utopia unfeasible. I grant you I still have not read either Kurzweil's or Bostom's arugments in full, but I have not been convinced that we should be more than conscious of the possibility at present.
&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;But, millions of jobs is not nothing! And so we finally turn back to the question: how will these economic and technological changes affect attitudes toward work? The answer, or my answer, is predictable: I hope that with diminishing numbers of routine somewhat-creative jobs, work as a whole will increasingly be seen as something that should be interesting, creative, and ultimately fulfilling. And eventually - eventually - the notion of how our economy works may have to be &lt;a href=&quot;https://en.wikipedia.org/wiki/Post-scarcity_economy&quot;&gt;completely revised&lt;/a&gt; to account for the ability of intelligent robots to take care of most human work, and the dreams of Marx finally get realized into some form of actual utopica where people work as a creative and personal pursuit rather than an economic transaction with society. But, in the near future, we can just hope that the dire existential straits immortalized in Office Space will be no more.&lt;/p&gt;

&lt;h1 id=&quot;back-to-the-present&quot;&gt;Back To The Present&lt;/h1&gt;

&lt;p&gt;But all of that is far off, and for all we know our world will be lucky enough to instead get the beautifully dreadful future of Blade Runner. So rather than dread or anticipate the changes of the future, we better worry about our incredibly imperfect present. At the same time, we ought not forget the past, and appreciate how far we have come - people live longer, are happier, and are more educated than in the past. There are still relatively very few people as lucky as me out there, but that’s changing, and as a rule of thumb &lt;a href=&quot;https://www.youtube.com/watch?v=Sm5xF-UYgdg&amp;amp;feature=share&quot;&gt;most things are getting better&lt;/a&gt;. And me? I just finished writing this absurdly long think piece for no real reason beyond feeling like it - so it seems I am doing alright.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;/writing/on-employment/&quot;&gt;On Employment&lt;/a&gt; was originally published by Andrey Kurenkov at &lt;a href=&quot;&quot;&gt;Andrey Kurenkov's Web World&lt;/a&gt; on September 24, 2015.&lt;/p&gt;
  </content>
</entry>


  

<entry>
  <title type="html"><![CDATA[TransitTimes]]></title>
  <link rel="alternate" type="text/html" href="/projects/major_projects/transit-times/" />
  <id>/projects/major_projects/transit-times</id>
  <published>2015-09-17T02:26:22-07:00</published>
  <updated>2015-09-17T02:26:22-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email>andreyvkurenkov@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;I started out the project thinking i’d do something much lower-level, but ended up working mostly on high-level frameworks with an existing beacon devkit. Thanks to (for once) things mostly working as we expected, we completed the vast majority of the project in about a month. Not bad, considering we made an Android app, a Django-based website (with significant frontends and backends), and a Pebble app. The data being in a standard GTFS format certainly helped, since we were bootstrapped by existing Django extensions for that. We did not get top three, but getting 1.5k for the best beacon award is not bad.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;/projects/major_projects/transit-times/&quot;&gt;TransitTimes&lt;/a&gt; was originally published by Andrey Kurenkov at &lt;a href=&quot;&quot;&gt;Andrey Kurenkov's Web World&lt;/a&gt; on September 17, 2015.&lt;/p&gt;
  </content>
</entry>


  

<entry>
  <title type="html"><![CDATA[Personal Site]]></title>
  <link rel="alternate" type="text/html" href="/projects/major_projects/personal-site/" />
  <id>/projects/major_projects/personal-site</id>
  <published>2015-08-10T00:00:00-07:00</published>
  <updated>2015-08-10T00:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email>andreyvkurenkov@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;I may have to do a complete write up on this later, but suffice it to say this site has had quite an oddysey. It started out as a Django project, which I undertook not only to create a portfolio (prior to my job search), but also to get a modicum of experience with web development since I had zilch at that point. The journey of this site from not-quite finished Django thing to beautiful Jekyll blog has &lt;a href=&quot;http://www.andreykurenkov.com/writing/hello-to-andreykurenkov-com/&quot;&gt;already been told&lt;/a&gt;, but the addition of the ‘projects’ section you are now parousing is itself quite the tale. To keep it short:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The site was based on the &lt;a href=&quot;https://mmistakes.github.io/minimal-mistakes/&quot;&gt;Minimal Mistakes&lt;/a&gt; theme with some customization, and I ended up plundering the same designer’s &lt;a href=&quot;https://mmistakes.github.io/skinny-bones-jekyll/&quot;&gt;Skinny Bones&lt;/a&gt; theme for the project page layout - thanks! I also plundered my old Django site design for each project’s layout - never throw out unfinished projects folks.&lt;/li&gt;
  &lt;li&gt;Introducing a whole new category to the site complicated things, and forced me to bite the bullet and &lt;a href=&quot;http://charliepark.org/jekyll-with-plugins/&quot;&gt;start using plugins&lt;/a&gt;. And by using plugins, I mean heavily borrowing from others for things I needed, such as &lt;a href=&quot;http://ajclarkson.co.uk/blog/jekyll-category-post-navigation/&quot;&gt;category based navigation&lt;/a&gt; and &lt;a href=&quot;http://charliepark.org/tags-in-jekyll/&quot;&gt;plugin-based tag pages&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Finally, having bitten that bullet I needed to say to having GitHub build my site from source - plugins are just too dangerous. But, with a &lt;a href=&quot;http://davidensinger.com/2013/04/deploying-jekyll-to-github-pages/&quot;&gt;bit of guidance&lt;/a&gt; that switch was pretty easy.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Next up, custom photo gallery! I highly recommend using this framework for your personal site, the design of it is simply fantastic.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;/projects/major_projects/personal-site/&quot;&gt;Personal Site&lt;/a&gt; was originally published by Andrey Kurenkov at &lt;a href=&quot;&quot;&gt;Andrey Kurenkov's Web World&lt;/a&gt; on August 10, 2015.&lt;/p&gt;
  </content>
</entry>


  

<entry>
  <title type="html"><![CDATA[Hello to andreykurenkov.com!]]></title>
  <link rel="alternate" type="text/html" href="/writing/hello-to-andreykurenkov-com/" />
  <id>/writing/hello-to-andreykurenkov-com</id>
  <published>2015-08-07T18:39:03-07:00</published>
  <updated>2015-08-07T18:39:03-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email>andreyvkurenkov@gmail.com</email>
  </author>
  <content type="html">
    &lt;blockquote&gt;
  &lt;p&gt;“I love writing. I get a kick out of sharing my thoughts with others. The act of transforming ideas into words is an amazingly efficient way to solidify and refine your thoughts about a given topic. “ -Tom Preston (creator of Jekyll), &lt;a href=&quot;http://tom.preston-werner.com/2008/11/17/blogging-like-a-hacker.html&quot;&gt;Blogging Like a Hacker&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;how-this-place-came-into-existence&quot;&gt;How This Place Came Into Existence&lt;/h2&gt;

&lt;p&gt;Hello there. Thanks for visiting my site. How do you like it? Fun fact: the publication date of this post is also the date that &lt;em&gt;andreykurenkov.com&lt;/em&gt; went live on the wild lands of the internet. Fun fact #2: it’s been more than a year since I originally started working on developing such a site. Why do it? For one, because I had not done any web development before that and a lack of knowledge of how to do something clearly makes it all the more worthwhile to do.  And that aside it was already quite worthwhile, partially for the transparently prideful reason of wanting to document my miscellaneous projects in style, but most of all simply to build something that felt like my own space to express myself through (inspired significantly by the magnificent &lt;a href=&quot;http://www.paulgraham.com/&quot;&gt;Paul Graham&lt;/a&gt;). So then, why did it take a year to get finished? Well, like I said, I had not done &lt;strong&gt;any&lt;/strong&gt; web development beforehand, yet had some grand ambitions for the site’s design and reactive behavior. Following the Django tutorial was easy enough, but wrangling HTML and CSS to fullfil my lofty vision proved significantly harder, and having to figure out how to use jQuery was the cherry on top of the technological stack pie.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/writing/images/2015-08-05-hello-to-andreykurenkov-com/website.png&quot;&gt;&lt;img src=&quot;/writing/images/2015-08-05-hello-to-andreykurenkov-com/website.png&quot; class=&quot;postimage&quot; /&gt;&lt;/a&gt;
    &lt;figcaption&gt;A prototype projects portfolio page. Entirely custom HTML and CSS - I was young, and inexperienced...&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;And so I got far in that summer, learned the Django and prototyped a static portfolio page in HTML and CSS, but ultimately stopped at the 80% point and got distracted by other things. And then, as tends to happen, my overabundance of free time ran out as I went back to college and the project hibernated for a good long while. I did get back to it during the bliss of Winter Break, but (as tends to happen) I then only got it to the 95% point (the point at which all major problems are solved and interesting functionality implemented) but lacked the will to do the remaining 5% (the content entry and bothersome debugging part). Meanwhile, I had continued to update the significantly less ambitious &lt;a href=&quot;http://www.lifeofandrey.wordpress.com&quot;&gt;lifeofandrey.wordpress.com&lt;/a&gt;, also begun the summer before on a whim but steadily maintained. And so although the Django site never mde it to anything beyong being served by a debug server, the Wordpress blog steadily filled with content, and my fondness for producing this content likewise increased. Now, fast forward past my senior year of college and some months thereafter - I once again found myself with plenty of free time and a desire for a more personal web existence. All it took was a glance over one Facebook post that mentioned Jekyll, and my work on this site began anew.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;https://github.com/andreykurenkov/minimal-mistakes/commits/master&quot;&gt;&lt;img src=&quot;/writing/images/2015-08-05-hello-to-andreykurenkov-com/commits.png&quot; class=&quot;postimage&quot; /&gt;&lt;/a&gt;
    &lt;figcaption&gt;Commits logs do not lie.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;why-jekyll&quot;&gt;Why Jekyll&lt;/h2&gt;

&lt;p&gt;Jekyll is a tool for generating static websites (a bunch of HTML files and other files lacking code) from a bunch of templates and associated YAML files. Software engineers explaining why they ported their blog to it from a service such as Wordpress.com &lt;a href=&quot;http://ocramius.github.io/blog/moving-my-blog-to-jekyll/&quot;&gt;is&lt;/a&gt; &lt;a href=&quot;http://hadihariri.com/2013/12/24/migrating-from-wordpress-to-jekyll/&quot;&gt;practically&lt;/a&gt; &lt;a href=&quot;http://www.girliemac.com/blog/2013/12/27/wordpress-to-jekyll/&quot;&gt;a&lt;/a&gt; &lt;a href=&quot;http://jbeckwith.com/2013/07/17/wordpress-to-jekyll/&quot;&gt;genre&lt;/a&gt; &lt;a href=&quot;http://damien.krotkine.com/2011/04/30/migrating-to-jekyll.html&quot;&gt;nowdays&lt;/a&gt;, so let me summarize: it’s easy, it’s fully yours to customize, static content means it’s fast, and hosting could not be simpler thanks to &lt;a href=&quot;http://jekyllrb.com/docs/github-pages/&quot;&gt;GitHub Pages support&lt;/a&gt;. One of the major hurdles I did not clear with my Django effort was figuring out how to actually put my website on the internet on my own custom domain, which I had &lt;a href=&quot;/old.html&quot;&gt;already done&lt;/a&gt; on GitHub Pages and knew to be &lt;a href=&quot;http://davidensinger.com/2013/03/setting-the-dns-for-github-pages-on-namecheap/&quot;&gt;super simple&lt;/a&gt;. The moment that cemented my confidence in using Jekyll was finding the &lt;a href=&quot;http://mmistakes.github.io/minimal-mistakes/theme-setup/&quot;&gt;magnificent Minimal Mistakes theme&lt;/a&gt;. It was truly the best of both the wordpress and Django worlds: an off-the-shelf great looking theme that I could endlessly tinker with to my heart’s content. And tinkering with it has proven to be nothing but fun, with most major lacking Wordpress features a &lt;a href=&quot;http://www.minddust.com/post/tags-and-categories-on-github-pages/&quot;&gt;Google&lt;/a&gt; [Search][http://realjenius.com/2012/11/03/jekyll-series-list/] away. That the simplicity of the tool requires ingenuity to implement some fancier ideas only makes it all the more fun.&lt;/p&gt;

&lt;h2 id=&quot;todo&quot;&gt;TODO&lt;/h2&gt;
&lt;p&gt;I know you must be very impressed by the mighty feat of this site’s creation, but the truth is that I have taken the lazy road in posting this today - it’s not even finished yet! Much more is to come&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Create projects category to replace work in nav bar and be distinct from writing&lt;/p&gt;

    &lt;p&gt;Basically, fulfill my original ambition with the Django site. The more involved layout with images
will not be trivial, but should be entirely doable.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Create custom Photography pages instead of linking to 500px&lt;/p&gt;

    &lt;p&gt;Though 500px is a fine site I quite enjoy browsing, it’s not fun to just link to it instead of 
hosting the photographs myself. Luckily, a neat hidden little feature of Lightroom is static 
html gallery generator&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Eventually transform the site into my own distinct theme.&lt;/p&gt;

    &lt;p&gt;Because my efforts in life seems perpetually aimed at becoming my own ideal role model, I suppose.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;you-can-do-it-too&quot;&gt;You Can Do It Too!&lt;/h2&gt;

&lt;p&gt;Yes! Even people with zero programming or wev dev experience can quite easily create their own www.myname.com site using Jekyll. The quite from &lt;a href=&quot;http://mmistakes.github.io/minimal-mistakes/theme-setup/&quot;&gt;Minimal Mistakes&lt;/a&gt; is excellent,  but &lt;a href=&quot;http://jekyllbootstrap.com/usage/jekyll-quick-start.html&quot;&gt;Jekyll Bootstrap makes it even easier&lt;/a&gt;. It’s really great fun, so if you actuall read all the above text and are now tempted to walk the same path - by all means, do!&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;/writing/hello-to-andreykurenkov-com/&quot;&gt;Hello to andreykurenkov.com!&lt;/a&gt; was originally published by Andrey Kurenkov at &lt;a href=&quot;&quot;&gt;Andrey Kurenkov's Web World&lt;/a&gt; on August 07, 2015.&lt;/p&gt;
  </content>
</entry>


  

<entry>
  <title type="html"><![CDATA[On Work]]></title>
  <link rel="alternate" type="text/html" href="/writing/on-work/" />
  <id>/writing/on-work</id>
  <published>2015-07-24T02:26:22-07:00</published>
  <updated>2015-07-24T02:26:22-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email>andreyvkurenkov@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;Or, why I relish work.&lt;/p&gt;

&lt;p&gt;A few months ago, completely overloaded with work in the lead up to my graduation (TAing, research, senior design, 4 or so other classes, working on a solar car, various projects…), I started writing a blog post: “This time I’ve really done it. After years of walking ever closer to the edge of too-much-work by simultaneously increasing my number of commitments and their difficulty, I came close to falling over that edge and stared down the spiraling flaming abyss of burn out. And I still am looking down at that abyss, overly brazen despite having just figured out my precarious position.”&lt;/p&gt;

&lt;p&gt;That was all I ever wrote of that blog post. I did not end up falling into that spiraling pit, with some difficulty and a few failures, and enjoyed the expected post graduation period of slovenly laziness. I even took a proper, if short, vacation. And then I boarded my flight to the Bay Area and spent the next month tediously completing my move here. And now I am back in what could be called a routine, and again feel as I did a few months ago: relentlessly restless to do things. In the excess of free time I now have working full time, I feel eager to: socialize more, read more, watch more, write more (score!), exercise more, photograph more, cook more, hack more, and learn much much more (Chinese, driving, data science, etc.). The items on the list are somewhat different, but the drive is the same: to do a lot, to use my time productively.&lt;/p&gt;

&lt;p&gt;Why? Why this drive for doing a lot. Simple: because I feel like it. Because I want to do these things. I wanted to get two majors, so I did. I wanted to TA, to do research, to work on a solar car, to compete in hackathons, so I did. I wanted, and want, to do these things because I find them challenging, rewarding, interesting. I want to do these things because they allow me to affect the world, to grow, to be creative, to express myself and to better understand what I want to express. And now I want to write, to photograph, to appreciate art, to meet new people and spend time with old friends, to exercise, to keep working on technical projects in my free time - all for roughly the same reasons.&lt;/p&gt;

&lt;p&gt;Which is great, and all, but not to say I don’t enjoy completely unproductive activities so hugely enabled by the internet - browsing reddit, for instance. Work requires energy and time (and so does socializing, and appreciating art), and this energy needs to be replenished. So overindulging in work, as with anything, is unhealthy; the term workaholic has a negative connotation, and rightfully so. When I wrote the quote above, I was acutely aware that I had gone too far, taken on too much, and my life was out of balance. Even given my proclivity for taking on a lot, the period was tiring and stressful, and acknowledging that was in part what drove to start writing this blog post those few months ago. Questioning this habit of mine, whether it is overkill, is wise; should I be more relaxed, less eager - different?&lt;/p&gt;

&lt;p&gt;No, not really. I am not a workaholic, in the sense that doing work is not the basis for my self worth, and I never was. Prudent though it was to consider the notion, as of writing this I find the truth to still simply be that I take great joy in being eclectic, and doing many things, even if it is not easy, perhaps especially because it is not easy.&lt;/p&gt;

&lt;p&gt;But, what of work-work? The office work, the job work. Well, that’s new. And that is also what drove me to revive this blog post so long past its inception. But, my time is spent, so for now I leave you with the promise of a soon to be follow-up post tentatively titled &lt;strong&gt;On Employment&lt;/strong&gt;.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;/writing/on-work/&quot;&gt;On Work&lt;/a&gt; was originally published by Andrey Kurenkov at &lt;a href=&quot;&quot;&gt;Andrey Kurenkov's Web World&lt;/a&gt; on July 24, 2015.&lt;/p&gt;
  </content>
</entry>


  

<entry>
  <title type="html"><![CDATA[Why I Consume Soylent]]></title>
  <link rel="alternate" type="text/html" href="/writing/why-i-consume-soylent/" />
  <id>/writing/why-i-consume-soylent</id>
  <published>2015-07-12T01:02:07-07:00</published>
  <updated>2015-07-12T01:02:07-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email>andreyvkurenkov@gmail.com</email>
  </author>
  <content type="html">
    &lt;figure&gt;
    &lt;a href=&quot;https://lifeofandrey.files.wordpress.com/2015/07/soylentpour1.jpg&quot;&gt;&lt;img src=&quot;/writing/images/2015-07-12-why-i-consume-soylent/soylentpour1.jpg&quot; alt=&quot;What this is all about&quot; caption=&quot;What this is all about&quot; class=&quot;postimage&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;For a week now, I’ve been consuming half my calories in the form of &lt;a href=&quot;https://en.wikipedia.org/wiki/Soylent_(drink)&quot;&gt;Soylent&lt;/a&gt;. Instead of eating a normal breakfast and lunch, I drink the liquidy non-food and perhaps have a coffee to spice things up. This is peculiar, admittedly, but to my surprise very few people I talk to have seemed to agree with the benefits of this regime; more often, they expressed little but disdain and mockery towards it. I don’t mind, but think their dismissal of it implies a lack of understanding, which of course is a most common and unfortunate condition for us humans. So, I will clarify - this is why I consume Soylent:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;It is convenient&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;I resent the notion that I am hard wired to enjoy food. With few exceptions, I enjoy food in a purely physical manner, without any degree of emotional or social gratification (in contrast sex, which the astute reader may note is another hard wired pleasure, most definitely does gratify in those ways). I understand that most people do not have this relationship with food, but I do. And that means that I often regard eating as a chore - necessary, but not really fulfilling, or not as fulfilling as getting something done, as talking to someone cool, as many things. That’s why I am thin - my diet is not particularly healthy, but filled with periods of fasting in which hunger or prudence are not sufficiently compelling reasons to get, much less make, and consume food.
This is not healthy, obviously - the effect, that is, and not the cause (let’s not get into a whole discussion of hedonism right now, though). And so, having finished college and filled myself with the intent to forge a yet more fulfilling and balanced life, I seek to correct this imbalance. And so given my preference for activities not involving making or even sometimes eating food, Soylent makes perfect sense. I spend a few minutes preparing it at night, let it cool in the fridge, and have my breakfast and lunch set for the next two days. Convenient.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;It is healthy&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;When I was in college, a typical breakfast was a sandwich, or some yogurt, or nothing at all. My lunches were likewise at best sandwiches, and for dinner if I got ambitious I would throw some pasta and vegetables in a pan. Hardly a balanced diet, nor a consistent one. Soylent is simple - it has everything that’s recommended for you, in basically the right proportions. I could never achieve that with normal food, even if I tried. There are not yet scientific studies showing consistent consumption of it does not make the body accept the included nutrition, true, but all indications I could find suggest liquid intake of the nutrients &lt;a href=&quot;http://www.washingtonpost.com/lifestyle/wellness/pros-and-cons-of-soylent/2014/09/16/09411d3c-386b-11e4-8601-97ba88884ffd_story.html&quot; target=&quot;_blank&quot;&gt;will work just fine&lt;/a&gt;. Consuming it also make management of calorie intake incredibly simple, bowel nonsense nonexistent, and poisoning impossible (unless you have enemies, in which case poisoning is actually much easier - I’ll take the risk). And, in not giving up eating normal food entirely, I am still retaining variety and flexibility likely best had for a good diet.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;It is affordable&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;Simple. Let’s pick a subscription, let’s say for 14 bags - $130. That’s 28 days of breakfast and lunch, but let’s up that to 32.5 to include weekends and other occasions. As you can yourself confirm, $130/32.5=$4. That’s $4 for a day’s breakfast and lunch, not including the large amounts of time saved. A totally rice-based diet may compare to this, yes, but just about any typical diet would cost me much more. And in the end of the day, I like to spend my money frivolously on other things.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;It makes me appreciate food more&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;Soylent tastes alright. It’s sort of like pancake batter, but just mildly sweet - I actually quite like it. But even after only a week, the thought of getting a sandwich for lunch makes me excited. That excitement is new, grown out of lack of indulgence in tasty foods so easy for me as a well-off American (and perhaps easier as a not well-off American).
Also: I now intend to learn to cook actual meals for my dinners. Admittedly, I mostly like this plan for the sake of its own utility, but the greater appreciation for solid food with non pancake-batter taste certainly helps.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;It prepares me for life in space&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;Because who knows where I will be in 40 years…&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

    &lt;p&gt;&lt;a href=&quot;/writing/why-i-consume-soylent/&quot;&gt;Why I Consume Soylent&lt;/a&gt; was originally published by Andrey Kurenkov at &lt;a href=&quot;&quot;&gt;Andrey Kurenkov's Web World&lt;/a&gt; on July 12, 2015.&lt;/p&gt;
  </content>
</entry>


  

<entry>
  <title type="html"><![CDATA[On The Successes of The Last of Us, and The Failures of Bioshock Infinite]]></title>
  <link rel="alternate" type="text/html" href="/writing/on-the-successes-of-the-last-of-us-and-the-failures-of-bioshock-infinite/" />
  <id>/writing/on-the-successes-of-the-last-of-us-and-the-failures-of-bioshock-infinite</id>
  <published>2015-06-23T01:37:52-07:00</published>
  <updated>2015-06-23T01:37:52-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email>andreyvkurenkov@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;“I just finished The Last of Us, and have enough exciting developed thoughts on it to want to write them down. Once the semester starts again I probably won’t have time for these sorts of things, but I will keep indulging myself while I can. Maybe I’ll get on a proper blogging site eventually, if only to hyperlink.” -Facebook Note, January 3 2014&lt;/p&gt;

&lt;p&gt;The Last of Us and Bioshock Infinite, two AAA games aka games with astounding production values and traditional game design that have you play an antihero that shoots and kills hundreds of people and sort-of-people. Also, both games explicitly and noticeably aspiring to be Serious Art. Mainstream reviewers gave both games reviews full of put-it-on-the-box quotes followed by numbers that averaged up to Great-Metacritic-averages, and both will no doubt got their own special Game of the Year Edition. But these days there lurk critics, in the corners of the internet, that write blog posts with no numbers attached and, for instance, point out that it is very hard to make anything resembling a serious story when the main character killing hundreds of people is a requirement (&lt;a href=&quot;http://www.magicalwasteland.com/mw/2012/5/1/dumbness-in-games-or-the-animal-as-a-system.html&quot; target=&quot;_blank&quot;&gt;This one&lt;/a&gt; is great, you should read it, and even moreso &lt;a href=&quot;http://www.grantland.com/story/_/id/8157257/line-explores-reasons-why-play-shooter-games&quot; target=&quot;_blank&quot;&gt;this one&lt;/a&gt;.). These critics have written a large volume of analysis, with much of it quite nonplussed by the traditional slaughter-based gameplay loops of these games; it can roughly be summarized as “:/”, with Bioshock Infinite getting an &lt;a href=&quot;http://www.actionbutton.net/?p=3006&quot; target=&quot;_blank&quot;&gt;especially&lt;/a&gt; &lt;a href=&quot;http://www.youtube.com/watch?v=GJ2cSKBFBDQ&quot; target=&quot;_blank&quot;&gt;large&lt;/a&gt; &lt;a href=&quot;http://leighalexander.net/bioshock-infinite-now-is-the-best-time/&quot; target=&quot;_blank&quot;&gt;amount&lt;/a&gt; of &lt;a href=&quot;http://www.snakelinksonic.com/2013/04/theres-subtlety-then-theres-cowardice.html&quot; target=&quot;_blank&quot;&gt;negative&lt;/a&gt; &lt;a href=&quot;http://tevisthompson.com/on-videogame-reviews/&quot; target=&quot;_blank&quot;&gt;criticism&lt;/a&gt; and The Last of Us &lt;a href=&quot;http://normallyrascal.wordpress.com/2013/12/02/the-ladder-of-us/&quot; target=&quot;_blank&quot;&gt;getting&lt;/a&gt; its &lt;a href=&quot;http://www.quartertothree.com/fp/2013/06/12/the-last-of-us-has-real-heart-but-not-much-else/&quot; target=&quot;_blank&quot;&gt;own&lt;/a&gt; &lt;a href=&quot;http://www.youtube.com/watch?v=bAzqDgKYfiM&quot; target=&quot;_blank&quot;&gt;respectable&lt;/a&gt; &lt;a href=&quot;http://www.grantland.com/story/_/id/9366466/tom-bissell-naughty-dog-latest-game-last-us&quot; target=&quot;_blank&quot;&gt;share&lt;/a&gt;. Besides the fact that such writing even exists and has an audience, I want to tell you why I mostly agree with the criticism of Bioshock Infinite and mostly disagree with the criticism of The Last of Us.&lt;/p&gt;

&lt;p&gt;Both games are accused of having rote gameplay that is disconnected from their Serious Art narrative. And indeed, Bioshock Infinite is a sad simplified shadow of the gameplay of Bioshock that has faceless meaningless soldiers instead of the fantastically personified splicers, half-hearted materialize-this-or-that options instead of a rich group of interacting systems, and a boringly linear course made artificially more exciting with ridiculous skylines instead of rich and rewarding exploration. Worse yet, with few exception the mechanics feel utterly disconnected from the narrative with not even an attempt to connect them, and the rehashed scattered recordings trick does more to hurt the storytelling than to improve it. The few choices that are there feel thrown in and meaningless, and aside from some enemy variety the fighting is largely monotonous.&lt;/p&gt;

&lt;p&gt;Though the gameplay of The Last of Us can similarly be lampooned as nothing more than the stealth/shooting mechanics from Uncharted 2 with some crafting on the side, it deserves more credit than that. There are many reasons for this, but most of all because it does something unique among games involving the murder of hundreds of people - it is designed not to to create the typical power trip pleasure, but rather an almost opposite feeling to that. In any of the numerous times you are faced with too many enemies to kill with &lt;a href=&quot;http://www.youtube.com/watch?v=kbLOokeC3VU&quot; target=&quot;_blank&quot;&gt;too few bullets&lt;/a&gt;, and in any of the numerous times you are suddenly spotted and all hell breaks loose and you have to run back to find some cover before you are dead, the best word for the feeling of the combat is “desperate.” The crafting mechanics here are perhaps the best use of the idea I have seen, in that they are crucial - getting by without the things you craft would be a nightmare, and diligent and thorough scavenging is encouraged not by some artificial scoring system by the sheer need for the items you can make. The weapon upgrades here, unlike in Bioshock, make a significant difference, a crucial difference. Even the melee is a success of simple but effective design that involves the player just enough in each brutal execution by making a badly timed blow badly fail. All of this, for a game clearly inspired by The Road and about survival at its most extreme, is fantastic.&lt;/p&gt;

&lt;p&gt;And so one game trots out a watered-down mix of old tropes having nothing to do with the games artistic intentions and the other game thrives on a smartly tuned and subtly different combat mechanics totally appropriate for its narrative. This difference in coherence and confidence is also reflected in the narrative of both games. Bioshock Infinite has been rightfully called out in most serious writing about the game for bringing up the issues of racism and jingoism in America’s past only to say nothing meaningful about those issues and instead forget about them in favor of weird half-coherent science fiction towards the game’s ending. Although I think it’s possible to interpret the game in a way that ties all the game’s subplot coherently, this does not excuse the game from being horrible about presenting such an interpretation elegantly and rather seeming confused about what, if anything, it wants to say about the ideologies and out-there science fiction that make up its story. That there are now many writers that do not ignore all these flaws is a great thing for the medium even if it is a bad thing for Bioshock Infinite as Serious Art.&lt;/p&gt;

&lt;p&gt;Not so with The Last of Us. Although it should be recognized as still having more in common with 28 Days Later than The Road, I was struck with how many things worth praising are subtly in the game. The story and characters themselves, which are surprisingly understated and rich. In fact, it is influenced by and successfully learns from the narrative achievements of the original Bioshock - much moreso than Infinite. Though there is a larger story, it is told with more self contained episodes with very distinct settings and arcs that all add up to a bigger understanding of this world. This place-as-story design is made all the better by having the characters actually interact and comment on their sorroundings, which all the more grounds the reality of the game’s world. And there are so many small interactions between the characters, such as quick exchanges as simple as “be careful” or the other character enabling you to progress, that serve to make their relationship real (again, another thing Bioshock Infinite has but does not do nearly as well). All of this, within the gameplay and not the masterfully crafted cutscenes. And because of that, I disagree with the seemingly many that think the gameplay is just as divorced from the narrative as it is in Bioshock or other AAA games. Traditional though it is, the gameplay here does reinforce the narrative, and moreso than the vast majority of big-budget games. Disregarding all of this, the game is worth playing only for its ending - goddamn, that ending.&lt;/p&gt;

&lt;p&gt;Don’t get me wrong, both games are great and worth playing. However, Bioshock Infinite seriously fails in its naked ambition to be taken seriously, and The Last of Us does not. The latter still has major flaws, most notably that it has large portions of gameplay that do not move the narrative at all. Still, I was surprised to find myself having a very novel experience with its completely unoriginal mechanics and think it succeeds as a game striving to have a serious narrative. You should play it.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;/writing/on-the-successes-of-the-last-of-us-and-the-failures-of-bioshock-infinite/&quot;&gt;On The Successes of The Last of Us, and The Failures of Bioshock Infinite&lt;/a&gt; was originally published by Andrey Kurenkov at &lt;a href=&quot;&quot;&gt;Andrey Kurenkov's Web World&lt;/a&gt; on June 23, 2015.&lt;/p&gt;
  </content>
</entry>


  

<entry>
  <title type="html"><![CDATA[Some More Thoughts on Being]]></title>
  <link rel="alternate" type="text/html" href="/writing/some-more-thoughts-on-being/" />
  <id>/writing/some-more-thoughts-on-being</id>
  <published>2015-06-21T01:04:48-07:00</published>
  <updated>2015-06-21T01:04:48-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email>andreyvkurenkov@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;It has been more than 4 months since I &lt;a href=&quot;https://lifeofandrey.wordpress.com/2015/02/15/some-thoughts-on-being/&quot; target=&quot;_blank&quot;&gt;lectured the world&lt;/a&gt; on my lofty principles, so it would seem unlikely I should have much to add. But, it is now clear those thoughts were suited to that time, a time of overwork and discipline and grand ambitions in the lead up to my graduation from college. Now, that time is past, and I am now defining the next era of my life on the opposite coast of the US . Many of my ambitions did not pan out, and the road to graduation and subsequent transition were hardly smooth; in short, I have gone through some things and thought of some more principles I have grown to try to abide by.&lt;/p&gt;

&lt;p&gt;Again, all things to strive for, some realistic and some less so.&lt;/p&gt;

&lt;h2 id=&quot;be-cool&quot;&gt;Be Cool&lt;/h2&gt;

&lt;p&gt;As in, don’t care too much. Or, more eloquently stated, &lt;a href=&quot;http://markmanson.net/not-giving-a-fuck#.hwpgi0:hQr2&quot; target=&quot;_blank&quot;&gt;don’t give too many fucks&lt;/a&gt;. Be careful with feelings, as has been covered, but particularly careful about feeling worried and concerned. The article linked explains why we should do so in quite good detail, and &lt;a href=&quot;http://waitbutwhy.com/2014/06/taming-mammoth-let-peoples-opinions-run-life.html&quot; target=&quot;_blank&quot;&gt;this one&lt;/a&gt; quite nicely explores the stupid reasons for our failure to do so, so read them first. Done? I hope you feel enlightened. My contribution here shall just be to tell you how I came to agree with those finely written essays, my view of their topic.&lt;/p&gt;

&lt;p&gt;When I was in middle school, a recent immigrant to the US, I was introverted and socially anxious enough to routinely worry about such simple interactions as getting lunch, and simple acts of awkwardness impacted me greatly. Typical, I know, but I hardly saw it as such at the time. But, in dealing with this problem I eventually realized several things: a) I mostly do not know the people I interact with, and likely will not interact with them again b) Most people around me don’t really care about my existence, and if something does call it to their attention they will soon forget c) I should not care about most peoples’ existence, for it does not affect my own. So I realized my worrying was, for the most part, silly, and that made it gradually yet greatly subside.&lt;/p&gt;

&lt;p&gt;But, my life was hardly full of measured calm from then on. In High School, I was once again irrationally worried, this time about getting good grades. Dissatisfied with low As, devastated by Cs. This continued to college, where I became histrionically concerned over not acing some tests in my first semester. But then, I easily got straight As in that semester. And so soon I realized: a) A single grade does not determine my final grade b) My final grade barely affects my GPA c) A 0.02 variance in my GPA barely affects anything at all. So I mostly stopped worrying about grades, and got mostly As and some Bs and spent my time much more wisely than I would have had I gotten straight As in college.&lt;/p&gt;

&lt;p&gt;The truth is, very few problems in my life have been worth taking seriously - they were pretty much meaningless, not worth fretting over. Of course, our feeble human minds work relatively and not absolutely, so I felt the worry and stress over these things all the same. But, I learned to stop taking these feelings seriously, which made me get over them soon enough. And even if the problem is serious, as they can be, even in my easy life - why freak out over it? At its core, this is simple, as all these principles are: accept what you cannot change, change the rest for the best.&lt;/p&gt;

&lt;h2 id=&quot;beempathetic&quot;&gt;Be Empathetic&lt;/h2&gt;

&lt;p&gt;As in, keep in mind you are not special, every single other human has an inner life too. Because of the way each of us is a little mind trapped in a physical cage allowing only indirect and grossly physical communication, it can be hard to fathom that in this world there are more than 7 billion other people who think and feel and worry and try and wonder constantly, just as you do. Each of these people had led a life with as many memories, incidents, relationships, and just - as much living, as you. Well, more or less. Just think about that. This is mindbogglingly complex to fathom, so practicality dictates we interact with most people through simple representation of their inner life, basic versions sufficient for the situation. And that works, and that makes sense. But, it is still important to remember that these conceptions are nothing more than mental cardboard cut outs of real people, and no person is actually that simple, ever. The ethical and practical aspects aside, remembering this makes existence all that more wondrous.&lt;/p&gt;

&lt;p&gt;But, likewise, it is important to remember that people interacting with you have no access to you inner life, and have no obligation to work to understand it, just as you do not have an obligation to work to understand theirs. In every challenge and failure we face, we have a deep understanding of our struggle, of ourselves. And yet, we must understand that others do not, and their response reflects that. Basically: people are not psychic, so don’t expect them to be, and don’t expect them to try to be. We should expect those close to us to understand us somewhat, perhaps, but feeling it unfair for others not to understand or care for your inner narrative in times of challenge and crisis is a vestige of childhood we must all abandon to become reliable individuals.&lt;/p&gt;

&lt;h2 id=&quot;beintrospective&quot;&gt;Be Introspective&lt;/h2&gt;

&lt;p&gt;As in, just take time to think about your life. Try to get some consistent thoughts on being of your own. Reflection can be difficult, it takes work, and humbleness, and discipline. But, in life everything is a matter of balance, and in that we must be capable of detecting imbalance. Everyone knows open-loop control just does not work well. Stated less obliquely, everyone knows a problem has to be recognized before it can be fixed. Such as, for example, the problem of worrying irrationally. Oh yes - it seems almost all these principles are in their core just a twist on introspection.
So just do it.&lt;/p&gt;

&lt;h2 id=&quot;beauthentic&quot;&gt;Be Authentic&lt;/h2&gt;

&lt;p&gt;As in, be yourself, seriously. Or, more specifically, work to be yourself. Obviously, practicality or etiquette or ethics often call for truth to be withheld, or replaced. But, so do confusion, convention, convenience, and so many more crutches. Forget ethics, being dishonest on account of these things is just lame, is as Holden Caulfield so often noted ‘phony.’ Being lame is often easier and safer, true, but also unambitious, boring, disappointing. And that makes for depressing lives, devoid of Truth and Beauty and Passion and Discovery - safe, but sad. So, work to avoid it, to surpass the easy decisions, the easy thoughts, the easy interactions that are hollow and false. If you are reading this, chances are you can afford the effort.&lt;/p&gt;

&lt;h2 id=&quot;be-wary-of-complexity&quot;&gt;Be Wary of Complexity&lt;/h2&gt;

&lt;p&gt;As in, stop lying to yourself, usually things actually do not have to be so very complicated. Though I express these thoughts on being in part because I think they are non-obvious and took me a lot of time to discover and internalize, the truth is the most striking realization is that the most important lessons in my life were taught to me as a child. Just be yourself, don’t worry about things you cannot change, take each failure as a learning opportunity, forgive but not forget, be kind to people, etc. These things are simple, and they seem True and Good, and yet how few of us seem to manage to actually follow them. But, I also write these thoughts on being because I think that with enough confidence and resolution it is possible to cut through the haze of self delusion and confusion and find some things to believe in, and commit to, and abide by, and eventually live a life free of existential dread and absurdist confusion.&lt;/p&gt;

&lt;h2 id=&quot;be-wary-ofself-pity&quot;&gt;Be Wary of Self Pity&lt;/h2&gt;

&lt;p&gt;As in, be wary of self pity disguised as misery. In regards to worrying about grades, I eventually started to wonder: if I know that in getting a bad grade I can do nothing about it but work harder and do better next time, why sense is there to feeling bad about it, to beating myself up over it? There really was no sense to it, but I felt compelled to do it, why? I came to think the reason is this: I sought to absolve myself of the failure, to prove my ‘innocence’ and related lack of justification for said failure by feeling pain over it and punishing myself for it - I really did care, I did not deserve it, it’s not fair. But, again, that’s nonsense - what I should do is move on and do better.  This plays into a bigger principle:&lt;/p&gt;

&lt;h2 id=&quot;we-are-all-tiny-specks-in-this-universe-and-the-universedoes-not-even-begin-to-care-about-us-and-it-is-unfair-and-our-lives-are-unfair---deal-with-it&quot;&gt;We Are All Tiny Specks In This Universe, and the Universe Does Not Even Begin to Care About Us, and it is Unfair, and Our Lives are Unfair - Deal With it&lt;/h2&gt;

&lt;p&gt;Again, a children’s lesson - the world ain’t fair. Any and all indignation about the fact is not going to change it, and is a waste of time and energy. Instead, we must learn to appreciate it all as it is - kind of fucked up, certainly not ideal, but on the whole quite worthwhile.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;/writing/some-more-thoughts-on-being/&quot;&gt;Some More Thoughts on Being&lt;/a&gt; was originally published by Andrey Kurenkov at &lt;a href=&quot;&quot;&gt;Andrey Kurenkov's Web World&lt;/a&gt; on June 21, 2015.&lt;/p&gt;
  </content>
</entry>


  

<entry>
  <title type="html"><![CDATA[On How Utterly Fantastic "Brothers: A Tale of Two Sons" Is]]></title>
  <link rel="alternate" type="text/html" href="/writing/on-how-utterly-fantastic-brothers-a-tale-of-two-sons-is/" />
  <id>/writing/on-how-utterly-fantastic-brothers-a-tale-of-two-sons-is</id>
  <published>2015-06-08T16:05:08-07:00</published>
  <updated>2015-06-08T16:05:08-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email>andreyvkurenkov@gmail.com</email>
  </author>
  <content type="html">
    &lt;figure&gt;
    &lt;img class=&quot;postimage&quot; src=&quot;/writing/images/2015-06-08-on-how-utterly-fantastic-brothers-a-tale-of-two-sons-is/brothers_gameinformer_01_big.jpg&quot; alt=&quot;http://www.brothersthegame.com/downloads&quot; /&gt;     
&lt;/figure&gt;

&lt;p&gt;Brothers is a game made by a movie director - Josef Fares . It’s nonconformity, courage, and beauty all derive significantly in part because of this esoteric source of creativity, as &lt;a href=&quot;http://www.polygon.com/features/2013/10/27/4864230/brothers-starbreeze-josef-fares&quot;&gt;the Polygon has greatly covered&lt;/a&gt;. Go read about it - the piece is well written, interesting, and makes playing the game all the more enjoyable. Josef Fares and Starbreeze have done something truly impressive, and should be commended for realizing a vision without regard for stale video game traditions. As is said in the article, ‘“If you want to make something that stands out and is memorable, you can’t do what everyone else is doing,” Engdal says. “It may seem obvious when stated like that, but still — most companies these days do the same thing over and over again because of some perceived sense of safety.”’&lt;/p&gt;

&lt;p&gt;Where to start? The game is set up early as being about the journey of two brothers across a medieval fantasy land to get a cure for their ailing father. The art direction needs to be praised, the music is appropriately elegant, and whoever handled creating the ground textures should get a raise. But what first really struck me was how the FEEL of a fairy tale Journey permeated this game. This is a Journey that stands among those of Jack (the climber and the Samurai), Frodo, and whoever had the courage to go after the fountain of life. It cannot be emphasized enough how much the sheer feeling of going on an exciting journey permeates this game. So many games feel empty in comparison, are a mechanical exercise to get through the next checkpoint or destination, with barely any soul or passion within them. Brothers had me jumping on noticeably protruding rocks on walls, shimmying on precarious ledges, handing and moving along slight fringes, and many such completely routine video game devices - but in this game as I started doing those acts I was excited, I felt like this was the start of an adventure instead of the same old typical progression towards the next level.&lt;/p&gt;

&lt;p&gt;Next, immersion. This game has no HUD or health, and it does not need them. The environmental puzzles are made to be simple and natural, quite logically embedded in the environment, so progression was almost constant and frustration almost nonexistent. This game has about 15 seconds of tutorial, as long as is required. The controls are simple, and often simply do the natural thing - keep running towards a platform to jump towards, twist the stick to turn the lever, etc. There are no points. Instead of points there are people, and places, and things to do - if you see person playing with a cat you can go over and pet it, if you see a person playing the lute you can go over and listen or mess with it slightly, if you see a fountain with fish in it you can enter and freshen up. This is what being in a world is all about. Unsurprisingly the Fares has named the designer of Ico as someone he’d like to meet, and the minimalism and design clarity here are on equal grounds with that groundbreaking game.&lt;/p&gt;

&lt;p&gt;Now, the mechanics. By having a single “interact” button and designing the game around that, the game fights against a strong bias of games for mechanistic design. By that I mean the “feel” of a platformer, a shooter, even a puzzle game - those all about the fine tuning of those specific mechanics, and the vast majority of games are designed to be enjoyable through mastering of the mechanics and variations on them over a long stretch of gameplay. Brothers is among recent games, like Gone Home, Dear Esther, The Stanley Parable, The Novelist, and Kentucky Route Zero that lack this emphasis on the joy of the game being primarily in the mechanics, in the raw input-output experience of it. This first struck me as I was carefully avoiding piles of bones while sneaking up on a troll facing the other way to steal a key conspicuously hung on his belt - unlike so many games where just sneaking would be made into a routine mechanic, in this game the act was done once and felt good due to the narrative and emotional meaning of it rather than its mechanical execution. These game are finally creating more balance and experimentation in the medium by having plain mechanics and emphasizing the pleasures of exploration, choice, discovery, and interaction. Considering the market is flooded with shooters, platformers, and puzzle games (even of the indie variety), I am a big fan of this trend.&lt;/p&gt;

&lt;p&gt;However, Brothers does employ game mechanics in a very important way. It frustratingly requiring both brothers to be controlled simultaneously with only the player’s one rather limited brain and two analogue sticks, which of course grows to be strangely natural over the course of the game. Much as with the very successful Papers, Please, the design of Brothers embeds much of the meaning of the game directly in the gameplay. I will avoid spoiling the ending, but it is sufficient to say that when you get to it the game has a brilliant conclusion in large part due to the mechanics of the game. Furthermore, it also allows for a fairly unique sense of enjoyment with the game when you feel your control of the two character is truly synchronized. This strongly reminded me of the concept of “flow”, and how other well designed games &lt;a href=&quot;http://www.theatlantic.com/technology/archive/2012/03/a-portrait-of-the-artist-as-a-game-studio/254494/&quot;&gt;such as Flower and Journey&lt;/a&gt; elicit it strongly.&lt;/p&gt;

&lt;p&gt;There are so many other things that are good in this game, and that are finally becoming more common in video games since the ongoing indie surge that has been happening at least since Braid and Limbo . Cutscenes are used sparingly, and correctly. The game as whole is short, which is to say the right length so no mechanics are tired out or pointless nonsense repetetive gamepaly is introduced. It is not sentimental, or childish, or simplistic (though whatever puzzles are in it are very intentionally simple). Forget specifics, the game as a whole is just uniquely beautiful. Play it, as soon as you can.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;https://lifeofandrey.files.wordpress.com/2015/06/brothers02_06_big.jpg&quot;&gt;&lt;img class=&quot;postimage&quot; src=&quot;/writing/images/2015-06-08-on-how-utterly-fantastic-brothers-a-tale-of-two-sons-is/brothers02_06_big.jpg&quot; alt=&quot;http://www.brothersthegame.com/downloads&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

    &lt;p&gt;&lt;a href=&quot;/writing/on-how-utterly-fantastic-brothers-a-tale-of-two-sons-is/&quot;&gt;On How Utterly Fantastic &quot;Brothers: A Tale of Two Sons&quot; Is&lt;/a&gt; was originally published by Andrey Kurenkov at &lt;a href=&quot;&quot;&gt;Andrey Kurenkov's Web World&lt;/a&gt; on June 08, 2015.&lt;/p&gt;
  </content>
</entry>


  

<entry>
  <title type="html"><![CDATA[AgriBot]]></title>
  <link rel="alternate" type="text/html" href="/projects/team_projects/mapping-sprayer/" />
  <id>/projects/team_projects/mapping-sprayer</id>
  <published>2015-05-02T00:00:00-07:00</published>
  <updated>2015-05-02T00:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email>andreyvkurenkov@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;Wow, what a senior design project. Getting a roughly 30k robot rover and being tasked with putting roughy 5k of electronics and sensors on top of it. And the software! To make a self driving, autonomous mapping robot that precisely sprayed plants and gathered data with the possibility of remote control and monitoring. Seriously, what a project.&lt;/p&gt;

&lt;p&gt;What a project - a serious enough one to the point of not being able to finish, apparently. A lot was working on that Jetson TK1, intense ROS-based SLAM code with Kinect 2 and SLAM input, navigation of the robot, and so much more (the technical docs and presentation have all the juicy details) - but as happens so often we did not pull it all together in time. Still, we were close, and for a project of such ambition that means something.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;/projects/team_projects/mapping-sprayer/&quot;&gt;AgriBot&lt;/a&gt; was originally published by Andrey Kurenkov at &lt;a href=&quot;&quot;&gt;Andrey Kurenkov's Web World&lt;/a&gt; on May 02, 2015.&lt;/p&gt;
  </content>
</entry>


  

<entry>
  <title type="html"><![CDATA[Teaching Robots Skill Constraints]]></title>
  <link rel="alternate" type="text/html" href="/projects/research/teaching-constrained-skills/" />
  <id>/projects/research/teaching-constrained-skills</id>
  <published>2015-05-01T00:00:00-07:00</published>
  <updated>2015-05-01T00:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email>andreyvkurenkov@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;Basically, with a lot of work, particularly leading up to the paper submission. I decided to do a year long project with the ambition of being published before leaving for my summer internship with EPFL, and tentatively planned out the next year over the summer. The fall is then much of the exploration on what the research will be and the implementation of what would be needed took place, and in the final semester at Tech I actually finished the software, ran the study, and wrote the paper.&lt;/p&gt;

&lt;p&gt;My work on this project counted both for completing the Research Option at Georgia Tech and for my CS Senior Research project, and correctly so - deciding on a research direction, implementing the vast majority of the necessary software, and (most of all) running a study and completing the paper all pushed me to work extremely hard despite at times being unsure the project could be completed on time and most definitely being unsure it could lead to a publication. It must be admitted that conceptually, or in terms of algorithms, the paper is not that impressive. Still, I still think it touched on several important topics that could be exploerd to a much deeper depth. And, it got published, so it seems I am not entirely wrong!&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;/projects/research/teaching-constrained-skills/&quot;&gt;Teaching Robots Skill Constraints&lt;/a&gt; was originally published by Andrey Kurenkov at &lt;a href=&quot;&quot;&gt;Andrey Kurenkov's Web World&lt;/a&gt; on May 01, 2015.&lt;/p&gt;
  </content>
</entry>


  

<entry>
  <title type="html"><![CDATA[GT Solar Racing]]></title>
  <link rel="alternate" type="text/html" href="/projects/team_projects/solarracing/" />
  <id>/projects/team_projects/solarracing</id>
  <published>2015-05-01T00:00:00-07:00</published>
  <updated>2015-05-01T00:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email>andreyvkurenkov@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;To work on the same team for four years, all during school, can you imagine? So many late nights, team dinners, missed deadlines. My involvement went up and down, and was varied - helping out the MechE people, debugging circuits, discussing design - but for the most part I did embedded programming, and ended up being software lead for two years (more or less). No one on the team can claim to have been great at meeting deadlines or not overcomplicating things, but in the end we did built a (very suboptimal) solar racing car. How did we get there? Very messily, and having made many mistakes. But, there is no doubt some of the most valuable experience I got at Tech was from working on the team - how do engineers learn to actually do anything if they don’t participate in such things in schools? Who knows.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;/projects/team_projects/solarracing/&quot;&gt;GT Solar Racing&lt;/a&gt; was originally published by Andrey Kurenkov at &lt;a href=&quot;&quot;&gt;Andrey Kurenkov's Web World&lt;/a&gt; on May 01, 2015.&lt;/p&gt;
  </content>
</entry>


  

<entry>
  <title type="html"><![CDATA[MiniRoboMe]]></title>
  <link rel="alternate" type="text/html" href="/projects/hacks/MiniRoboMe/" />
  <id>/projects/hacks/MiniRoboMe</id>
  <published>2015-04-23T00:00:00-07:00</published>
  <updated>2015-04-23T00:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email>andreyvkurenkov@gmail.com</email>
  </author>
  <content type="html">
    &lt;p&gt;By senior year of college, I had a Pololu 3Pi robot I had won at a Robotics and Perception class and an Android to Arduino bridge I had won at a hackathon. I was itching to use them both, and the idea was obvious - make the robot remotely controllable with an Android device using the Arduino ADK. And that’s exactly what I did, despite the massive levels of overwork that research and senior design in concert with TAin and multiple over classes brought to me. The details are all in the report, though sadly no video evidence of this working exists - soon, though. In the meantime, i’ll leave you with some wisdom: never forget to connect your grounds!&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;/projects/hacks/MiniRoboMe/&quot;&gt;MiniRoboMe&lt;/a&gt; was originally published by Andrey Kurenkov at &lt;a href=&quot;&quot;&gt;Andrey Kurenkov's Web World&lt;/a&gt; on April 23, 2015.&lt;/p&gt;
  </content>
</entry>

</feed>
